## 消息队列

把消息队列比作是一个存放消息的容器，当我们需要使用消息的时候可以取出消息供自己使用。消息队列是分布式系统中重要的组件，使用消息队列主要是为了通过异步处理提高系统性能和削峰、降低系统耦合性。

![img](https://upload-images.jianshu.io/upload_images/2509688-311483f18a8d228e?imageMogr2/auto-orient/strip|imageView2/2/w/910)

### 为什么使用消息队列

#### 	异步处理提高性能（削峰 降低响应时间）

> 在不使用消息队列服务器的时候，用户的请求数据直接写入数据库，在高并发的情况下数据库压力剧增，使得响应速度变慢。但是在使用消息队列之后，用户的请求数据发送给消息队列之后立即 返回，再由消息队列的消费者进程从消息队列中获取数据，异步写入数据库。由于消息队列服务器处理速度快于数据库（消息队列也比数据库有更好的伸缩性），因此响应速度得到大幅改善。

> **削峰作用的功能**——即**通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。**

> **但是，需要修改业务，无法保证是否一定写入成功，需要后续的消息提醒** 

#### 	降低系统耦合

> ![img](https://upload-images.jianshu.io/upload_images/2509688-f3bddbdea97bb30c?imageMogr2/auto-orient/strip|imageView2/2/w/790)
>
> **消息队列使利用发布-订阅模式工作，消息发送者（生产者）发布消息，一个或多个消息接受者（消费者）订阅消息。** 从上图可以看到**消息发送者（生产者）和消息接受者（消费者）之间没有直接耦合**，消息发送者将消息发送至分布式消息队列即结束对消息的处理，消息接受者从分布式消息队列获取该消息后进行后续处理，并不需要知道该消息从何而来。**对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计**。

> 另外为了避免消息队列服务器宕机造成消息丢失，会将**成功发送到消息队列的消息存储在消息生产者服务器上**，等消息真正被消费者服务器处理后才删除消息。在消息队列服务器**宕机后**，生产者服务器会**选择分布式消息队列服务器集群中的其他服务器**发布消息。

### 使用MQ后带来的问题

#### 	系统可用性降低

> 需要额外考虑消息丢失的问题，以及MQ挂掉

#### 	系统复杂度提升

> 需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！

#### 	一致性问题

> 消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!



## JMQ

![img](http://img.mp.itc.cn/upload/20160830/2f6615760d134464a1321497b7925897_th.jpeg)

包括服务端 客户端 管理端 存储通过JFS和HBase

![img](http://dl2.iteye.com/upload/attachment/0122/2698/9a5c4783-c8cc-3903-8a67-ad9aafd90878.png)

### 服务端

> 服务端提供了配置信息分发、重试消息管理和消息存储与分发这三大类功能。每个服务端实例都具备这三类功能的服务能力，但是在实际部署上这三类功能对应三个不同的集群，对应每一个实例功能不叠加。在测试环境和库房等资源有限的环境下，这三类功能由同一个服务端实例提供服务。

#### 配置信息分发

> 负责客户端参数变更时与消息分配的服务端实例变更时通知客户端。

#### 重试消息管理

> 主要用于对业务系统临时处理不了的消息进行存放，然后再按照一定的策略投递给客户端处理。可以提供错误原因、错误处理次数等查询。

#### 消息存储与分发

> 接收生产者投递的消息，把消息存放在本地磁盘上，消费者从该服务上拉取消息进行消费。

### 客户端

> 提供了JAVA语言的SDK和支持HTTP协议的proxy，非JAVA语言通过proxy接入。

### 管理端

> 提供了JAVA语言的SDK和支持HTTP协议的proxy，非JAVA语言通过proxy接入。

### 特点

#### 数据可靠性

> 针对公司的业务特点，消息服务主要应用于订单、支付、物流等环节。服务端采用**MASTER-SLAVE**结构，消息在正常情况下会同时存放两份，其中一份会强制持久化到磁盘，磁盘做**RAID-5**。默认情况下客户端采用同步发送，每条消息到达服务端MASTER后会强制刷入磁盘同时并行推送一份到SLAVE上，SLAVE写入文件系统后不等待强制刷盘就反馈给MASTER。根据不同的场景为了提高服务的可用性，普通级别的消息SLAVE断开后，该组服务可以正常使用，当SLAVE连接上后又会自动切换为保存两份。当然对数据可靠级别高的消息是强制要求数据必须写两份才算成功的。

##### RAID-5

###### 原理

> RAID5和[RAID4](https://baike.baidu.com/item/RAID4)一样，数据以块为单位分布到各个硬盘上。RAID 5不对数据进行备份，而是把数据和与其相对应的[奇偶校验](https://baike.baidu.com/item/奇偶校验)信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。当RAID5的一个磁盘数据损坏后，利用剩下的数据和相应的[奇偶校验](https://baike.baidu.com/item/奇偶校验)信息去恢复被损坏的数据。

###### 读写

> 用简单的语言来表示，至少使用3块硬盘（也可以更多）组建RAID5[磁盘阵列](https://baike.baidu.com/item/磁盘阵列)，当有数据写入硬盘的时候，按照1块硬盘的方式就是直接写入这块硬盘的[磁道](https://baike.baidu.com/item/磁道)，如果是RAID5的话这次数据写入会根据算法分成3部分，然后写入这3块硬盘，写入的同时还会在这3块硬盘上写入校验信息，当读取写入的数据的时候会分别从3块硬盘上读取数据内容，再通过检验信息进行校验。当其中有1块硬盘出现损坏的时候,就从另外2块硬盘上[存储](https://baike.baidu.com/item/存储)的数据可以计算出第3块硬盘的数据内容。也就是说raid5这种存储方式只允许有一块硬盘出现故障，出现故障时需要尽快更换。当更换[故障](https://baike.baidu.com/item/故障)硬盘后，在故障期间写入的数据会进行重新校验。 如果在未解决[故障](https://baike.baidu.com/item/故障)又坏1块，那就是灾难性的了。

#### 服务高可用

> 每类消息一般都会分配3组及以上的服务组，每组服务包括一个MASTER和一个SLAVE，当然如果有需要也可以挂载多个SLAVE。
>
> 客户端发送消息时，如果其中一组出现故障会重试发送给其他的组。
>
> 虽然MASTER-SLAVE支re持切换，提高服务的可用性，但是在实际生产中MASTER出现故障时会优先采用通过其他服务组自动接替生产服务的方式，本组服务只提供从SLAVE读取的方式，而不是让SLAVE接替MASTER的写入，避免临界状态下丢失消息。

### JMQ架构

> JMQ的消息放在topic这样的逻辑概念中。P表示生产者，C表示消费者
>
> ![image-20200619094829793](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619094829793.png)

> 每个topic对应了多个分片（绿色部分）每个分片都是两台物理机（一主一从），而每个分片也可能存放多个topic主题
>
> ![image-20200619094923885](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619094923885.png)

> ![image-20200619095050882](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619095050882.png)
>
> 每个主题映射到分片上时，每个分片都会有一个队列的概念。每个topic都有一个固定的队列数
>
> 消息最终存在在journal中

![image-20200619095543543](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619095543543.png)

JMQ消费

### 发送生产方面

#### 	如何提高发送量？

> 1 有足够多的服务器容量（网络和存储）
>
> 2 足够大的压力（可以采用多线程的形式进行发送）
>
> 3 可以支撑发送量的性能

#### 	如何保障发送性能

> 1 设置合理的超时时间
>
> 2 合适的重试和降级策略（发送失败后 置入另一个发送队列）

### 消费方面

> ![image-20200619102138152](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619102138152.png)
>
> 1 线程x向分片请求拉取
>
> 2 抢占队列 返回消息集合
>
> 3 返回的消息 通过onMessage方法进行获取 处理
>
> 4 客户端将消费成功与否的命令返回给队列
>
> 5 释放队列 确认位置

#### 影响消费速度的三个因素

> ​	1 消费时 onMessage（List<Message> msgs）的执行时间
>
> ​	2 threadx的线程数量 线程越多 处理能力越强
>
> ​	3 服务端队列数量越多 阻塞程度越轻 消费性能越好

> **开启并行消费后，一个队列可以被多个消费线程消费**
>
> ![image-20200619105530681](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619105530681.png)
>
> ![image-20200619110014964](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619110014964.png)

### JMQ消费-容灾

> ![image-20200619110902488](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619110902488.png)
>
> 每个分片两台物理机，中从结构，所有的数据都存放在主节点上，从节点只是作为备份作用
>
> 当从节点失效后，主节点变为**只读**，客户端无法写入后，感知到节点失效
>
> 主节点失效后，无法写入。挤压的消息由于已经备份到从节点上，所有的消息拉取，由从节点来负责

### JMQ防重

> 由于在broker的成功反馈消息有可能中断，导致客户端启用重试机制，从而导致broker上两条或多条相同的消息
>
> ![image-20200619111419213](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619111419213.png)
>
> 由于client可能已经成功处理了请求，但确认消息由于网络的因素，导致无法成功被broker接收。queue此时仍然被锁定，所以在超时后，queue会自动进行解锁，消息会重复进行推送
>
> ![image-20200619111530418](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619111530418.png)

### JMQ重试

> 由于listener中的onMessage方法进行消息的接收和处理，但存在消息错误，无法处理的情况。此时，会再次调用两次onMessage方法，进行重试。如果三次都无法正确处理，即使再度重试，也无法正确的处理。所以，将这样的消息存放到mysql中，将队列中位置后移，避免影响后续的消息处理
>
> ![image-20200619112438546](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619112438546.png)
>
> 重试的逻辑
>
> ![image-20200619113109269](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619113109269.png)

## JIMDB

基于redis的分布式缓存与高速键值存储服务。

### 解决redis的问题

#### 	redis完全依赖内存，内存往往不够实用

> 引入RAM + SSD两级存储，在内存中存储热点数据，冷数据被自动交换到磁盘，解决内存不足的问题

#### 	redis启动需要将所有数据加载到内存，启动慢

> 启动时并不把所有数据加载入内存，而是在运行时根据需要加载，解决启动速度慢的问题

#### 	内存总量不断突破，不断进行扩容

> 因为引入了二级存储，存储容量通常比较大，所以不需要频繁的扩容了。

### 遇到的问题

#### 	内存不足

> 虽然Redis对于每一个命令处理之前都会检查内存占用情况，当超过配置的最大内存时会按照配置的淘汰策略部分key，但是这并不能满足我们的需求，因此我们需要在发现内存不足时按照一定的策略淘汰一部分内存中key（dirty key不会被淘汰），以释放宝贵的内存资源。
>
> 内存占用率>85%时采用随机淘汰策略，随机淘汰部分key直到内存占用率降到75%以下。
>
> 内存占用率>75%时采用LRU淘汰策略，这里参考了Redis的淘汰思路，采用随机采样然后按照LRU淘汰。
>
> 不过这两种淘汰策略都可能耗时比较长，如果直接放在原来Redis检查内存占用的地方，势必会影响单次请求的延时，所以我们将上述的淘汰策略放在定时任务中处理，同时原Redis的内存占用检查我们采用快速检查方案，即内存占用率>90%时，随机淘汰几个key。

#### 	磁盘内存数据交换

> Redis查找一个key，首先会在内存中查找，只有在内存中找不到才会在磁盘中查找，如果仍然没有找到，则表明这个key不存在，如果在磁盘中找到了，会将这对KV添加到Redis的字典以加载到内存。
>
> Redis修改一个key后，我们将这个key标记为**dirty key**，即将key的副本**添加到**专门用于保存dirty key的字典**dirty dict中**，为了节约空间，我们只存储了这个key（value为NULL）。我们在定时任务中**周期性执行flush dirty key to disk任务**，这个任务会将存储在dirty dict中的key写入磁盘，写磁盘时，我们需要对key的value进行**序列化编码成二进制流**，当dirty dict中的key都同步到磁盘上后，清空dirty dict。

#### 	过期key的存储

> 当一个key设置了过期时间但只存储在磁盘上，如果这个key已经过期，但是仍然占用磁盘空间，造成磁盘空间的浪费，因此我们需要**定期扫描磁盘上**存储的设置了过期时间的key，如果发现超时，即时删除以释放磁盘空间。
>
> 我们将所有设置了过期时间的key再单独存储一份{ key，expiretime }，上文中提到的key的存储格式中的第一个字节就派上用处了，我们约定”0”表示正常的KV，”1”表示设置过期时间的key，其中只存储过期时间，这样我们直接扫描前缀为”1”的key就可以快速判断其是否已经超时。

### 集群拓扑

> 最内层蓝色矩形代表一个jimdb实例 多个实例构成了一个集群
>
> 一份业务数据会被分成多个部分，称之为扇即shard 或 分片
>
> 一份业务数据也会有多个副本 即途中圆角虚线矩形部分（图中有两个分组）
>
> ![image-20200619161138416](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619161138416.png)
>
> 每个分片会有一个实例提供读写服务，成为master
>
> 其他实例提供制度服务 称之为slave

### 主从复制

![image-20200619164217433](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619164217433.png)

#### **增量复制**

> 主节点除了写入自己内存以外，还需要将自己接收到的命令写入环形缓冲区。并且记录下命令的偏移量。缓冲区会异步将数据写入从节点，从节点会定时向主节点上报自己的偏移量。如果偏移量不相同，则再次发送没有发送的数据

#### **全量复制**

> 发生在从节点刚连接到主节点，此时主节点会fork一个子进程，子进程将内存快照写入一个rdb文件，发送给rdb。slave节点收到后，将文件解析为数据加载。

#### 写入过快

> 如果写入过快，速度高于主从复制的速度，则环形缓冲区很快会被占满，且新命令会覆盖旧命令，注重之间无法完成增量复制，只能触发全量复制

#### 最终一致性而非强一致性

> 由于是异步写入从节点，所以数据无法保证强一致性。

#### hashtag

> 目的是为了让同一个key分布到同一个分片上 尤其是针对一些多key命令
>
> 在多实例的环境下，像是smove（将某个实例从一个集合移动到另一集合），无法保证原子操作。可能会导致（类似于删除失败）两个集合中都有该元素。所以需要将所有的相同的key分布在同一实例上。

#### 集群高可用

> 哨兵机制 
>
> 监控实例的存活 大多数哨兵认为实例死亡 则认为实例失效（哨兵部署在与实例同一机房的不同机架上）
>
> ![image-20200619165322240](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619165322240.png)

### 最佳实践

#### 	大key问题

> 可能会导致阻塞

> 拆分key

#### 	热key（一个key频繁被请求的）

> CPU过高
>
> 无法扩容
>
> 带宽问题
>
> 热写

> **本地缓存**（把热key放在本地缓存中，所有的读在本地读取 不再发送请求）
>
> **多副本扛读**（增加从节点 每个从节点分担一部分压力）提供异构的设计 可以在某一个实例上增加副本
>
> **保持空闲连接**

#### 	客户端高可用

> 读策略（设置更好的读取策略 从特定副本上读取）
>
> 自动摘流量（服务端判断一个实例的死亡 需要20-40s 但这个时间段 客户端不清楚服务端状况 所以需要客户端摘流量 ）当一个副本的读请求三次失败 会切换到另一个副本上 将原副本摘掉

#### 	连接池配置

> 一般需要压测来配置
>
> ![image-20200619171948474](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619171948474.png)

#### 	超时

> 时间组成：数据相应时间，链接创建时间，等待空闲时间。无法精确控制超时
>
> 秒杀或流量突增的场景，不合理的池配置会导致链接风暴（流量突增，导致cpu响应变慢，此时出现超时，会进一步导致创建连接，从而恶性循环）**需要保证一定的最小空闲连接**
>
> 过短的超时时间配置，在大流量情况下可能导致链接风暴（超时时间设置较短，很容易被判别为超时）
>
> 写命令超时重试，需要考虑命令是否是幂等的（写命令超时，无法判断是否成功写入已经成功了，此时重复操作应该要舍弃）

### 存在的问题

> 单副本可以做到实例的自动恢复，但是不能恢复数据
>
> 主从切换时，可能会丢失少量数据
>
> 内存可能会写满（会先淘汰过期key 后丢弃新的写入）

## JSF

杰夫，**京东服务框架**

### 适用场景

> 适合于分布式架构下，服务与服务之间的同步调用，数据量小（单个请求小于20K）并发大的场景；

### 设计原则

> 1.接口**参数**尽量用**简单的类型**，比如基础类型Integer、Boolean等，如使用自定义类型也请保证此类型的结构尽量简单、嵌套层数尽量少，这样会减少序列化时的消耗；
>
> 2.传输的**数据尽量少**，大数据会占用更多有限的带宽；
>
> 3.保证每次**RPC调用的原子性**，尽量减少在一个事务过程中发起的RPC调用，检查RPC调用的返回值或异常；
>
> 4.保证关键接口的**幂等性**；
>
> 5.制定服务等级协议（SLA），估算线上并发量，考虑每个请求的大小以及服务器带宽，压测单个服务在单位时间内的处理能力，计算需要部署的服务实例数；

### 设计架构

> ![image-20200619143909459](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619143909459.png)
>
> Index Service: 索引服务，提供注册中心地址列表；
>
> 注册中心：提供服务注册、订阅，服务上下线；配置下发、状态读取（如client所拥有的地址列表），为了容灾多实例部署；
>
> Monitor Service：收集所有客户端所上传的性能统计数据；
>
> Web管理端：服务管理界面，可以在此配置权重、路由规则等；



### PRC

> 远程过程调用，一个节点请求另一个节点提供的服务
>
> ![image-20200619141430436](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619141430436.png)
>
> 在微服务的设计中，一个服务A如果访问另一个Module下的服务B，可以采用HTTP REST传输数据，并在两个服务之间进行序列化和反序列化操作，服务B把执行结果返回过来。
>
> ![img](https://upload-images.jianshu.io/upload_images/7632302-19ad38cdd9a4b3ec.png?imageMogr2/auto-orient/strip|imageView2/2/w/723/format/webp)

#### 要解决的问题

> 1. **解决分布式系统中，服务之间的调用问题。**
> 2. **远程调用时，要能够像本地调用一样方便，让调用者感知不到远程调用的逻辑。**	

#### 	Call ID映射

> 本地调用，函数的调用是通过函数指针指定，
>
> 在远程调用则需要建立Call ID和和函数的映射

#### 	序列化和反序列化

> 本地调用，参数是压栈后弹栈赋值给参数。
>
> 远程调用，需要把参数转成字节流，服务端拿到后，再将其装变为自己能够读取的格式

#### 	网络传输

> 所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用**TCP**协议，但其实**UDP**也可以，而gRPC干脆就用了**HTTP2**。Java的Netty也属于这层的东西。

![](https://images2018.cnblogs.com/blog/905730/201806/905730-20180620204401594-1632180240.png)

#### RPC和RestHttp调用的区别

> **Resthttp调用**：中文描述表述性状态传递（是指某个瞬间状态的资源数据的快照，包括资源数据的内容、表述格式(XML、JSON)等信息。）
>
> **RPC**：远程过程调用，它可以实现客户端像调用本地服务(方法)一样调用服务器的服务(方法)。而 RPC 可以基于 TCP/UDP，也可以基于 HTTP 协议进行传输的
>
> **rest**多使用于组件之间的通信
> **RPC**多用于同一组件中，各个不同模块之间的通信
>
> **rest**面向资源
> **RPC**面向方法 需要知道服务端具体的类，具体方法
>
> **RPC**引入了服务注册中心，所以客户端无需拿到服务端的ip和端口，在这个层面上进行了一定程度的解耦。



## 微服务与SOA架构

### 微服务

> 通常跟微服务相对的是单体应用，即将所有功能都打包成在一个独立单元的应用程序。

### SOA

> 面向服务的架构
>
> SOA是一种粗粒度、**松耦合**服务架构，服务之间通过简单、精确定义接口进行通讯，不涉及底层编程接口和通讯模型。

> 所谓**松耦合**（没有强制绑定到特定的实现上）的好处有两点
>
> 一点是它的灵活性
>
> 另一点是，当组成整个应用程序的每个服务的内部结构和实现逐渐地发生改变时，它能够继续存在。

### 对比

> | 功能     | SOA                  | 微服务                       |
> | -------- | -------------------- | ---------------------------- |
> | 组件大小 | 大块业务逻辑         | 单独任务或小块业务逻辑       |
> | 耦合     | 通常松耦合           | 总是松耦合                   |
> | 公司架构 | 任何类型             | 小型、专注于功能交叉团队     |
> | 管理     | 着重中央管理         | 着重分散管理                 |
> | 目标     | 确保应用能够交互操作 | 执行新功能、快速拓展开发团队 |
>
> 微服务架构一般来说，每个独立的小服务就有自己的持久化业务数据。每个微服务只能访问自己的数据库，而无权访问其他服务的数据。

## 高并发环境（接口的降级和熔断）

### 降级

**降级意味着相比降级之前功能表现得不完美**

> 当系统出现问题时，有一个备选的方案可以马上进行切换
>
> > 例如，接口的功能是实时预测未来一个月某个商品的采购数量，突然间依赖的上游系统出现问题了，那么我们的接口就完全不可用了吗？显然这是不应该的，这时我接口就可以**降级**，返回昨天实时计算出来的结果，虽然准确性可能差一点，但系统能够正常运转

#### 	自动降级

> 系统自动检测到问题时，自动切换

#### 	手动降级

> 系统监测到问题报警，人为的进行切换

#### 	降级的时机

> **超时降级**	调用服务时超时返回了默认值或其他处理方法
>
> **失败次数降级**	服务可用率下降时降级
>
> **限流**	限流同样是一种降级的方法
>
> **故障降级**	依赖的外系统发生故障时降级
>
> **拒绝服务降级**	

### 熔断

> **遇到危险了，必须马上停掉**
>
> > 假设一个接口部署了10台机器（分布式），突然某一台机器的接口调用情况正确率降到90%，那么这台机器肯定出现问题了，这个时候就需要熔断这台机器，把这台机器从整个集群中摘掉，从而保证用户的请求100%的正确
>
> > 一个系统中有很多功能，这些功能有些是核心功能，有些是非核心功能，那么在一些大促中，我们可能熔断掉一些非核心功能，从而保证核心功能的流转（登录和注册，登录属于核心，注册是属于非核心）

#### 	熔断的时机

> 系统攻击熔断	当某个服务遭遇流量攻击时，可以熔断这个服务
>
> 涉及核心功能运行时的熔断	下单和评论功能，关键时刻可以熔断评论功能

**两者的目的都是为了维护系统的可用性和稳定性**

**在设计熔断和降级时，需要考虑熔断算法，恢复机制，报警**

**但是不同在于：降级是牺牲部分功能的（可以用手机号注册，邮箱不可以）但是熔断是放弃全部的功能（注册模块完全不可用）**



### 实现降级和熔断的手段

#### 1 服务码+配置中心

> 调用所有的服务，都传入必参数服务码和开关，默认关闭。当触发某种条件时可打开开关，或者通过配置中心手动推送开关新的值，从而保护系统不被单个服务压垮

```python

func  DowngradeAndFuse (ctx context.Context){
    //业务码
    bizValue := ctx.Value("bizCode")
    //熔断降级标识
    flag := ctx.Value("flag")
   
    if bizValue == "指定业务" && flag {
       //降级或者熔断
       return
    }
}
```

#### 2 Hystrix

##### 	采用的手段

> 1. 资源隔离（线程池和信号量两种手段的隔离）
> 2. 限流
> 3. 降级
> 4. 熔断（断路器）

##### 	设计方式

> 1. 使用命令模式将所有对外部服务（或依赖关系）的调用包装在HystrixCommand或HystrixObservableCommand对象中，并将该对象放在单独的线程中执行
> 2. 每一个依赖都有自己对应的线程池或者信号量，线程池耗尽时，拒绝请求
> 3. **维护**请求的各种**状态**（成功，失败，超时的次数）
> 4. 当**错误率到达一定阈值时，进行熔断**，过一定的时间后又**恢复**
> 5. 提供降级，失败，成功，熔断后的**回调逻辑**
> 6. 实时的监控指标和配置信息的修改

### 限流

> 有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询（评论的最后几页），因此需有一种手段来限制这些场景的并发/请求量，即限流。

> 目的是通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（**定向到错误页**或告知资源没有了）、**排队或等待**（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如**商品详情页库存默认有货**）

#### 	限流算法

##### 		令牌桶

> 系统按照恒定的时间间隔1/QPS向桶内加入Token。新请求到达时，会各自拿走一个token，如果没有token可拿，就进行阻塞或者拒绝服务。

![img](https://img-blog.csdn.net/20160423213519927)

> 想法来源于计算机网络中的拥塞控制。
>
> 传送到令牌桶的数据包需要消耗令牌。不同大小的数据包，消耗的令牌数量不一样。
>
> 令牌桶这种控制机制基于令牌桶中是否存在令牌来指示什么时候可以发送流量。令牌桶中的每一个令牌都代表一个字节。如果令牌桶中存在令牌，则允许发送流量；而如果令牌桶中不存在令牌，则不允许发送流量。因此，如果突发门限被合理地配置并且令牌桶中有足够的令牌，那么流量就可以以峰值速率发送。

##### 		漏桶

> 请求进入漏桶内，漏桶以一定速度出水（交给接口进行处理）请求进入速率过大会溢出，拒绝请求。

##### 		计数器

> 通过原子操作的AtomicLong进行限制流量的计数。

```java
try {
if(atomic.incrementAndGet() > 限流数) {
//拒绝请求
    }
//处理请求
} finally {
    atomic.decrementAndGet();
}
```

##### 		基于Redis

> 设置访问接口的时间间隔 **每一个用户对此服务接口的访问就把键值加1，在60秒内当键值增加到10的时候，就禁止访问服务接口**

## 生成全局唯一objectid

使用12个字节用来表示objectId 其中4bytes时间 3bytes机器码 2bytes进程pid 3字节自增码（随机生成）？



## Dozer的使用

> Dozer是Java Bean到Java Bean映射器，它以递归方式将数据从一个对象复制到另一个对象。通常，这些Java Bean将具有不同的复杂类型。
>
> Dozer支持简单属性映射，复杂类型映射，双向映射，隐式显式映射以及递归映射。这包括映射还需要在元素级别进行映射的集合属性。





## RPC远程调用



## springMVC中的ModelAndView

> 使用ModelAndView类用来存储处理完后的结果数据，以及显示该数据的视图。从名字上看ModelAndView中的Model代表模型，View代表视图，这个名字就很好地解释了该类的作用。业务处理器调用模型层处理完用户请求后，把**结果数据存储在该类的model属性中**，把要返回的**视图信息存储在该类的view属性**中，然后让该ModelAndView返回该Spring MVC框架。框架通过调用配置文件中定义的视图解析器，对该对象进行解析，最后把结果数据显示在指定的页面上。 

### 	方法

> #### 	添加模型数据addObject方法
>
> #### 	设置视图 setViewName

### 	作用

#### 		设置转向的地址

```java
ModelAndView view = new ModelAndView("path:student");//通过构造的方式	
```

```java
public void setViewName(String viewName){...}//通过setViewName的方法
```

#### 		将控制器方法中处理的结果数据传递到结果页面

> 也就是把在结果页面上需要的数据放到ModelAndView对象中即可）
>
> 其作用类似于request对象的setAttribute方法的作用，用来在一个请求过程中传递处理的数据。

```java
public ModelAndView addObject(String attributeName, Object attributeValue){...}
public ModelAndView addObject(Object attributeValue){...}
```





# MySQL

## 范式

> #### 第一范式 原子性
>
> > 数据库中的每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性
>
> #### 第二范式 完全依赖主键
>
> > 数据库的每个实例或行必须可以被唯一的区分，即表中要有一列属性可以将实体完全区分，这个属性就是主键，即每一个属性完全依赖于主键
> >
> > 完全依赖概念：即非主属性不能依赖于主键的部分属性，必须依赖于主键的所有属性。
>
> #### 第三范式 不存在函数依赖
>
> > 属性不依赖与其他非主属性，也就是说，如果存在非主属性对于码的传递函数依赖，则不符合第三范式

## 数据类型

### char与varchar

> varchar是**变长**字符串 比定长类型更省空间
>
> 用1-2个额外字节存储字符串长度
>
> 超出设置长度部分 会截断 因为变长存取慢 省空间

> char是**定长** 更具定义的字符串长度分配足够空间
>
> 超出设置长度部分 会截断 因为定长存取快 可能浪费空间

> 经常变更的列 使用char比使用varchar好 不容易产生碎片
>
> 非常短的列 char比varchar存储上更有效率
>
> 使用时 只分配需要的空间 更长的列在排序时会消耗更多的内存

### timestamp和datetime

> 尽量使用timestamp 其空间效率高于datetime

## group by的实现原理

> mysql中group by实现方式有三种，**松散索引**，**紧凑索引**，**临时文件**（文件排序）。

> 对于group by引用的多个字段，需满足于所建立索引的**最左前缀索引**，否则进行group by操作时，无法利用索引。在利用索引时，group by可根据索引，即可对数据分组，此时完全不用去访问表的数据值（索引健对应的数据）。这种实现方式就是利用**松散索引**。
>
> 松散索引的执行计划为**using index for group by**。

> 当group by引用的字段**无法构成所建索引的最左前缀索引时**，也就是说group by不能利用索引时。如何**where语句（如果有的话）弥补了这种差距**，比如：group by引用的字段为（c2，c3），而索引为（c1，c2，c3）。此时如果**where语句限定了c1=a（某一个值）**，那么此时mysql的执行过程为先根据where语句进行一次选择，对选出来的结果集，可以利用索引。这种方式，从整体上来说，group by并没有利用索引，但是从过程来说，在选出的结果中利用了索引，这种方式就是**紧凑索引**。
>
> mysql的执行计划为**using where,use index**

> 如果mysql如论如何都不能利用索引时，此时mysql将读取所有的数据**建立临时表**，对文件进行排序，完成分组操作。

## in 和 exists的区别

> **exist适合 子查询中表数据大于外查询表中数据的业务场景**
>
> **in:适合外部表数据大于子查询的表数据的业务场景**
>
> **in 是把外表和内表作hash 连接，而exists是对外表作loop循环，每次loop循环再对内表进行查询。一直以来认为exists比in效率高的说法是不准确的**

> exist： 先执行外部查询语句，然后在执行子查询，子查询中它每次都会去执行数据库的查询，执行次数等于外查询的数据数量。

> in:  先查询 in()子查询的数据(1次)，并且将数据放进内存里(不需要多次查询),然后外部查询的表再根据查询的结果进行查询过滤,最后返回结果

## Innodb引擎 MyISAM引擎

> Innodb支持**行锁 表锁**
>
> MyISAM支持**表锁**

> Innodb支持**事务**
>
> MyISAM不支持**事务**

> Innodb对于 增删改更快
>
> MyISAM对于查找更快

> Innodb索引是**聚簇索引**
>
> MyISAM是**非聚簇索引**

> Innodb主键索引的叶子节点存储**行数据** 主键索引非常高效
>
> MyISAM索引叶子节点存储的**行数据地址** 需要再寻址一次才能得到数据



## 聚集索引 非聚集索引

> *聚簇索引中 主键索引页节点保存所有的数据 辅助索引叶节点则是主键的值（可以通过覆盖索引 避免回表）*
>
> *非聚簇索引中 主键索引和辅助键索引叶节点都是数据的地址*

![img](https://img2018.cnblogs.com/i-beta/1464190/201911/1464190-20191106151527647-152458631.png)

### 聚簇索引

> **聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分；**

> **我们日常工作中，根据实际情况自行添加的索引都是辅助索引，辅助索引就是一个为了需找主键索引的二级索引，现在找到主键索引再通过主键索引找数据；**

#### 优点

> 1.数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快
>
> 2.聚簇索引对于主键的排序查找和范围查找速度非常快

#### 缺点

> 1.插入速度严重依赖于插入顺序，按照主键的**顺序插入**是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个**自增的ID列为主键**
> 2.**更新主键的代价很高**，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。
> 3.二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。

#### 查询过程

> InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上，若使用"where id = 14"这样的条件查找主键，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。若对Name列进行条件搜索，则需要两个步骤：第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。第二步使用主键在主索引B+树种再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。

### 非聚簇索引

> 使用B+Tree作为索引结构，叶节点的**data域存放的是数据记录的地址**
>
> 主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，这两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。



## 索引的数据结构

### B+树索引

> #### n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。
>
> 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
>
> 所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
>
> B+ 树中，数据对象的插入和删除仅在叶节点上进行。
>
> B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。

### 哈希索引

> 将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。

## 索引的使用

### 最左匹配原则

> 组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，在查询的where中 a,b,d的顺序可以任意调整。索引的顺序和建立有关，和where中顺序无关。

> =可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式

> like 需要 左侧保证无通配符 whn%



## 创建索引原则

> 2）较频繁作为查询条件的字段才去创建索引
>
> 3）更新频繁字段不适合创建索引
>
> 4）若是不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低)
>
> 5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。
>
> 6）定义有外键的数据列一定要建立索引。
>
> 7）对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。
>
> 8）对于定义为text、image和bit的数据类型的列不要建立索引。

## 索引的下推和覆盖

> > 索引的下推
> >
> > ​	可以在索引遍历过程中，**对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表字数**。
>
> ```mysql
> select * from tuser 
> where name like '张 %' and age=10 and ismale=1;
> ```
>
> 该语句在搜索索引树的时候，只能匹配到名字第一个字是‘张’的记录（即记录ID3）接下来是怎么处理的呢？当然就是从ID3开始，逐个回表，到主键索引上找出相应的记录，再比对age和ismale这两个字段的值是否符合。
>
> 索引下推优化后，可以在索引遍历过程中，**对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表字数**。
>
> ![img](https://upload-images.jianshu.io/upload_images/6271376-e4e98a8af8fc9ca8.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1142/format/webp)
>
> ![](https://upload-images.jianshu.io/upload_images/6271376-53f9161adfddeb10.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1142/format/webp)
>
> > 索引的覆盖
> >
> > ​	只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快。
> >
> > explain的输出结果Extra字段为Using index时，能够触发索引覆盖。

## B树B+树的比较

> - 在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。
> - B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。

### 使用B树好处

> B树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近根节点的地方将会大大提高**热点数据**的查询效率。这种特性使得B树在特定数据重复多次查询的场景中更加高效。

### 使用B+树的好处

> 由于B+树的内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。



## 事务四大特性ACID

> **原子性**： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
> **一致性**： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
> **隔离性**： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
> **持久性**： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

## 脏读 幻读 不可重复读

> **脏读(Drity Read)**：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。（读取到另一个事务没有提交的数据）
> **不可重复读**(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。（同一事务中 两次读取结果不一）
> **幻读(Phantom Read)**:在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。（）

## 事务隔离级别

| 隔离级别         | 脏读 | 不可重复读 | 幻影读 |
| ---------------- | ---- | ---------- | ------ |
| READ-UNCOMMITTED | √    | √          | √      |
| READ-COMMITTED   | ×    | √          | √      |
| REPEATABLE-READ  | ×    | ×          | √      |
| SERIALIZABLE     | ×    | ×          | ×      |

> READ-UNCOMMITTED**(读取未提交)**： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
> READ-COMMITTED**(读取已提交)**： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。（基于查询加共享锁，查询结束后释放锁 ）
> REPEATABLE-READ**(可重复读)**： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
> SERIALIZABLE**(可串行化)**： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

## MVCC简介

> MVCC多版本并发控制(Multi-Version Concurrency Control)是MySQL中**基于乐观锁理论实现隔离级别**的方式，用于实现读已提交和可重复读取隔离级别。
>
> 这项技术使得InnoDB的事务隔离级别下执行一致性读操作有了保证，换言之，就是**为了查询一些正在被另一个事务更新的行**，并且可以看到它们被更新之前的值。这是一个可以用来增强并发性的强大的技术，因为这样的一来的话查询就**不用等待另一个事务释放锁**。
>
> 核心是在每一行隐藏了两个字段，用于表示版本号。
>
> - **SELECT**
>   - **读取创建版本小于或等于当前事务版本号，并且删除版本为空或大于当前事务版本号的记录。这样可以保证在读取之前记录是存在的。**
> - **INSERT**
>   - **将当前事务的版本号保存至行的创建版本号**
> - **UPDATE**
>   - **新插入一行，并以当前事务的版本号作为新行的创建版本号，同时将原记录行的删除版本号设置为当前事务版本号**
>   - **修改的时候一定不是快照读，而是当前读。**
> - **DELETE**
>   - **将当前事务的版本号保存至行的删除版本号**
> - 只有普通的SELECT才是快照读，其它诸如UPDATE、删除都是当前读。
> - 修改的时候一定不是快照读，而是当前读。

## 各种隔离级别的实现 使用的协议（一致性读+锁）

> **一致性读**：InnoDB用多版本来提供查询数据库在**某个时间点的快照**。一致性读不会给它所访问的表加任何形式的锁，因此其它事务可以同时并发的修改它们。
>
> 可重复读：
>
> ​	如果隔离级别是REPEATABLE READ，那么在同一个事务中的所有一致性读都读的是事务中第一个这样的读读到的快照；
>
> 读已提交：
>
> ​	如果是READ COMMITTED，那么一个事务中的每一个一致性读都会读到它自己刷新的快照版本。
>
> 幻读：
>
> ​	利用Gap Locks间隙锁和Next-Key可以阻止其它事务在锁定区间内插入数据，因此解决了幻读问题

##### 通过MVCC实现一致性非锁定读，这就有保证在同一个事务中多次读取相同的数据返回的结果是一样的，解决了不可重复读的问题

##### 利用Gap Locks和Next-Key可以阻止其它事务在锁定区间内插入数据，因此解决了幻读问题



## 隔离级别与锁的关系

> 在**Read Uncommitted**级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突
>
> 在**Read Committed**级别下，读操作需要加**共享锁**，但是在**语句执行完**以后释放共享锁；
>
> 在**Repeatable Read**级别下，读操作需要加**共享锁**，但是在事务提交之前并不释放共享锁，也就是必须等待**事务执行完毕**以后才释放共享锁。
>
> **SERIALIZABLE** 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。



## 锁的粒度分数据库锁有哪些？

> MyISAM和InnoDB存储引擎使用的锁：
>
> **MyISAM采用表级锁(table-level locking)。**
> **InnoDB**支持行级锁(row-level locking)和表级锁，**默认为行级锁**
>
> **行级锁** 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。
>
> 特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
>
> **表级锁** 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。
>
> 特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。
>
> **页级锁** 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。
>
> 特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

## InnoDB存储引擎的锁的算法有三种

> **Record lock：单个行记录上的锁**
> **Gap lock：间隙锁，锁定一个范围，不包括记录本身**
> **Next-key lock：record+gap 锁定一个范围，包含记录本身**

> innodb对于行的查询使用next-key lock
> Next-locking keying为了解决Phantom Problem**幻读**问题
> 当查询的索引含有唯一属性时，将next-key lock降级为record key
> Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内
> 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1
>
> for update时，锁的使用是基于索引的，如果查询的字段不是索引键那么将退化为表锁

## 视图

### 什么是视图

> 视图（view）是一种虚拟存在的表，是一个逻辑表，本身并不包含数据。作为一个select语句保存在数据字典中的。
>
> 通过视图，可以展现基表的部分数据；视图数据来自定义视图的查询中使用的表，使用视图动态生成。

### 视图优点

> 1）简单：使用视图的用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。
>
> 2）安全：使用视图的用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单的实现。
>
> 3）数据独立：一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响。



# 并发编程

## 并发与并行

> **并发**：多个任务在同一个 CPU 核上，按细分的时间片轮流(交替)执行，从逻辑上来看那些任务是同时执行。
> **并行**：单位时间内，多个处理器或多核处理器同时处理多个任务，是真正意义上的“同时进行”。
> **串行**：有n个任务，由一个线程按顺序执行。由于任务、方法都在一个线程执行所以不存在线程不安全情况，也就不存在临界区的问题。

## 进程与线程

### 定义

> 进程
>
> 一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程

> 线程
>
> 进程中的一个执行任务（控制单元），负责当前进程中程序的执行。一个进程至少有一个线程，一个进程可以运行多个线程，多个线程可共享数据。

## 进程线程区别

> **根本区别**：进程是操作系统**资源分配的基本单位**，而线程是处理器**任务调度和执行的基本单位**
>
> **资源开销**：每个**进程都有独立的代码和数据空间**（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，**每个线程都有自己独立的运行栈和程序计数器**（PC），线程之间切换的开销小。
>
> **包含关系**：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。
>
> **内存分配**：同一进程的**线程共享本进程的地址空间和资源**，而进程之间的地址空间和资源是相互独立的
>
> **影响关系**：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以**多进程要比多线程健壮**。
>
> **执行过程**：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

## 死锁的必要条件

> **互斥条件**：线程(进程)对于所分配到的资源具有排它性，即一个资源只能被一个线程(进程)占用，直到被该线程(进程)释放
> **请求与保持条件**：一个线程(进程)因请求被占用资源而发生阻塞时，对已获得的资源保持不放。
> **不剥夺条件**：线程(进程)已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
> **循环等待条件**：当发生死锁时，所等待的线程(进程)必定会形成一个环路（类似于死循环），造成永久阻塞

## 避免死锁

### **破坏请求与保持条件**

> 一次性**申请所有**的资源。

### **破坏不剥夺条件**

> 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以**主动释放**它占有的资源。

### **破坏循环等待条件**

> 靠按序申请资源来预防。按**某一顺序**申请资源，释放资源则反序释放。破坏循环等待条件。

## 为什么不能直接调用run方法

> new 一个 Thread，线程进入了新建状态。调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。
>
> 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。
>
> 总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。

## 线程生命周期

![线程的基本状态](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxNy8xMi8xNS8xNjA1OWNjOTFlZThlZmIz?x-oss-process=image/format,png)

## <u>线程同步的方式</u>

#### object的wait notify 

> 需要阻塞
>
> JVM会为一个使用内部锁（synchronized）的对象维护两个集合，**Entry Set**和**Wait Set**
>
> 对于Entry Set：如果线程A已经持有了对象锁，此时如果有其他线程也想获得该对象锁的话，它只能进入Entry Set，并且处于线程的BLOCKED状态。
>
> 对于Wait Set：如果线程A调用了wait()方法，那么线程A会释放该对象的锁，进入到Wait Set，并且处于线程的WAITING状态。
>
> 某个线程B想要获得对象锁，一般情况下有两个先决条件，一是对象锁已经被释放了（如曾经持有锁的前任线程A执行完了synchronized代码块或者调用了wait()方法等等），二是线程B已处于RUNNABLE状态。
>
> 对于Entry Set中的线程，当对象锁被释放的时候，JVM会唤醒处于Entry Set中的某一个线程，这个线程的状态就从BLOCKED转变为RUNNABLE。
>
> 对于Wait Set中的线程，当对象的notify()方法被调用时，JVM会唤醒处于Wait Set中的某一个线程，这个线程的状态就从WAITING转变为RUNNABLE；或者当notifyAll()方法被调用时，Wait Set中的全部线程会转变为RUNNABLE状态。所有Wait Set中被唤醒的线程会被转移到Entry Set中。

```java
	static class A extends Thread {
        public void run() {
            while (true) {
                synchronized (lockA){
                    System.out.print("A");
                    lockA.notify();
                    try {
                        lockA.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        }
    }
```

> 此处交替输出AB所以使用一个锁来限制



#### 简单的显式lock的方式 和信号量方式类似

```java
	static Lock lock = new ReentrantLock();
    static Integer i = new Integer(3);

    static class A extends Thread {
        public void run() {
            while (true) {
                lock.lock();
                while (i % 3 == 0) {
                    System.out.print("a");
                    i++;
                }
                lock.unlock();
            }
        }
    }
```



#### condition的await和signal

```java
	static Lock lock = new ReentrantLock();
    static Condition a=lock.newCondition();
    static Condition b=lock.newCondition();
    static Condition c=lock.newCondition();
```

> 通过lock来创建不同的condition 每个condition类似于对应某个输出
>
> await对应wait  signal对应notify signalAll对应notifyAll

```java
	static class A extends Thread {
        public void run() {
            while (true) {
                lock.lock();
                while (i % 3 != 0) {
                    try {
                        a.await();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                i++;
                System.out.print("a");
                b.signal();
                lock.unlock();
            }
        }
    }
```

##### condition原理 

*（AQS维护blocked condition维护一个waiting的FIFO队列）*

> 我们知道Lock的本质是AQS，AQS自己维护的队列是当前等待资源的队列，AQS会在资源被释放后，依次唤醒队列中从前到后的所有节点，使他们对应的线程恢复执行，直到队列为空。而Condition自己也维护了一个队列，该队列的作用是维护一个等待signal信号的队列。但是，两个队列的作用不同的，事实上，每个线程也仅仅会同时存在以上两个队列中的一个，流程是这样的：
>
> \1. 线程1调用reentrantLock.lock时，尝试获取锁。如果成功，则返回，从AQS的队列中移除线程；否则阻塞，保持在AQS的等待队列中。
> \2. 线程1调用await方法被调用时，对应操作是被加入到Condition的等待队列中，等待signal信号；同时释放锁。
> \3. 锁被释放后，会唤醒AQS队列中的头结点，所以线程2会获取到锁。
> \4. 线程2调用signal方法，这个时候Condition的等待队列中只有线程1一个节点，于是它被取出来，并被加入到AQS的等待队列中。注意，这个时候，线程1 并没有被唤醒，只是被加入AQS等待队列。
> \5. signal方法执行完毕，线程2调用unLock()方法，释放锁。这个时候因为AQS中只有线程1，于是，线程1被唤醒，线程1恢复执行。
> 所以：
> 发送signal信号只是将Condition队列中的线程加到AQS的等待队列中。只有到发送signal信号的线程调用reentrantLock.unlock()释放锁后，这些线程才会被唤醒。
>
> 可以看到，整个协作过程是靠结点在AQS的等待队列和Condition的等待队列中来回移动实现的，Condition作为一个条件类，很好的自己维护了一个等待信号的队列，并在适时的时候将结点加入到AQS的等待队列中来实现的唤醒操作。

#### Semaphore信号量

> 类似于同步信号量的形式，更加方便操作

```java
	static Semaphore a=new Semaphore(1);
    static Semaphore b=new Semaphore(0);
    static class A extends Thread{
        public void run(){
            while(true) {
                try {
                    a.acquire();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.print("a");
                b.release();
            }
        }
    }
    static class B extends Thread{
        public void run(){
            while(true) {

                try {
                    sleep(100);
                    b.acquire();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("b");
                a.release();
            }
        }
    }
    static class C extends Thread{
        public void run(){
            while(true) {
                try {
                    sleep(100);
                    b.acquire();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("c");
                a.release();
            }
        }
    }
```

> 交替输出AB 或 AC

## 如何暂停线程的运行

> （1）线程体中调用了 **yield 方法**让出了对 cpu 的占用权利（由运行态转到就绪态）
>
> （2）线程体中调用了 sleep 方法使线程进入睡眠状态
>
> （3）线程由于 IO 操作受到阻塞
>
> （4）另外一个更高优先级线程出现
>
> （5）在支持时间片的系统中，该线程的时间片用完

## 如何停止一个正在运行的线程

> 1. 使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。
> 2. 使用**stop方法**强行终止，但是不推荐这个方法，因为stop和suspend及resume一样都是过期作废的方法。
> 3. 使用**interrupt方法**中断线程。

## sleep和wait的区别

> 类的不同：sleep() 是 Thread线程类的静态方法，wait() 是 Object类的方法。
>
> 是否释放锁：sleep() 不释放锁；wait() 释放锁。且wait要结合锁使用
>
> 用途不同：Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。
>
> 用法不同：wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用wait(long timeout)超时后线程会自动苏醒。

## 如何实现多线程之间的通讯和协作？

### 通信协作

> 一.syncrhoized加锁的线程的**Object类**的wait()/notify()/notifyAll()
>
> 二.ReentrantLock类加锁的线程的**Condition类的**await()/signal()/signalAll()

### 直接数据交换

> 三.通过**管道**进行线程间通信：1）字节流；2）字符流

## 进程通信的方式

| 通信方法               | 无法介于内核态与用户态的原因         |
| ---------------------- | ------------------------------------ |
| 管道（不包括命名管道） | 局限于父子进程间的通信。             |
| 消息队列               | 在硬、软中断中无法无阻塞地接收数据。 |
| 信号量                 | 无法介于内核态和用户态使用。         |
| 共享内存               | 需要信号量辅助，而信号量又无法使用。 |

## Synchronized底层实现原理

> 一个线程也执行同步代码块，首先要获取锁，而获取锁的过程就是monitorenter ，在执行完代码块之后，要释放锁，释放锁就是执行monitorexit指令。

## Synchronized可重入的原理

> 重入锁是指一个线程获取到该锁之后，该线程可以继续获得该锁。底层原理维护一个计数器，当线程获取该锁时，计数器加一，再次获得该锁时继续加一，释放锁时，计数器减一，当计数器值为0时，表明该锁未被任何线程所持有，其它线程可以竞争获取锁。

## Synchronized加锁的范围

>  **锁定某一特定对象**
>
> 加在非静态方法 或 synchronized(this)
>
> **锁定某个类的所有对象**
>
> 夹在静态方法 或 synchronized(A.class) （如双重检验单例）



## Synchronized和Reentrantlock的区别

### Api层面

> synchronized可以修饰方法 代码块 对象 基于原语 必须显示的进行加锁 隐式的进行解锁 是否成功获得锁并不知道
>
> reentrantlock修饰代码块 基于API 显示的进行加锁 释放 只能修饰代码块，必须显式的进行加锁解锁。

### 等待可中断

> 使用synchronized。如果Thread1不释放，Thread2将一直等待，不能被中断
>
> 使用ReentrantLock。如果Thread1不释放，Thread2等待了很长时间以后，可以中断等待，转而去做别的事情。

### 公平锁

> synchronized的锁是非公平锁，ReentrantLock默认情况下也是非公平锁，但可以通过带布尔值的构造函数要求使用公平锁。

### 绑定多个条件

> ReentrantLock可以同时绑定多个Condition对象，只需多次调用newCondition方法即可。
>
> synchronized中，锁对象的wait和notify() 或notifyAll()方法可以实现一个隐含的条件。但如果要和多于一个的条件关联的时候就不得不额外添加一个锁。

### 相同点

> 都是可重入的。可重入值的是同一个线程多次试图获取它所占的锁，请求会成功。当释放的时候，直到冲入次数清零，锁才释放。

## volatile作用

>  volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。
>
> **防止指令重排序**
>
> **线程可见性**

### ps 原子类如何保证原子性

> 通过volatile和自选保证数据的原子性

## 双重检验volatile单例中的作用

> 防止指令重排，可能会出现半初始化的对象被单例使用

## AQS

> AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。

### 核心思想

> **AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。**
>
> **![AQS原理图](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8xMS8yNS8xNmVhMDQ3Njc4NGNkMzJi?x-oss-process=image/format,png)**

### **AQS 对资源的共享方式**

> **独占**：只有一个线程能执行，如ReentrantLock。
>
> **共享**：多个线程可同时执行，如Semaphore/CountDownLatch

### 可重入的实现

> **1在线程获取锁的时候，如果已经获取锁的线程是当前线程的话则直接再次获取成功**
>
> **2由于锁会被获取n次，那么只有锁在被释放同样的n次之后，该锁才算是完全释放成功**。

## ConcurrentHashMap

### HashMap线程不安全

> 1.7以前使用头插法 会导致桶内形成循环链表在 扩容时可能导致插入的数据丢失
>
> 1.8后改进了头插法 但可能在多线程环境下 遇见相同hash值的数据插入 导致数据丢失

### Hashtable线程安全但效率低下

> Hashtable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下Hashtable的效率非常低下。因为当一个线程访问Hashtable的同步方法时，其他线程访问Hashtable的同步方法时，可能会进入阻塞或轮询状态。

### ConcurrentHashMap原理

> 在1.7之前 concurrentHashMap使用的是分段锁，可以满足分段数量的并发度
>
> ConcurrentHashMap 定位一个元素的过程需要进行两次Hash操作，第一次 Hash 定位到 Segment，第二次 Hash 定位到元素所在的链表的头部，因此，这一种结构的带来的副作用是 Hash 的过程要比普通的 HashMap 要长，但是带来的好处是写操作的时候可以只对元素所在的 Segment 进行操作即可，不会影响到其他的 Segment。其中分段锁的实现是通过**自旋**的方式实现的。
>
> ![img](https://images2018.cnblogs.com/blog/1202638/201808/1202638-20180814213921035-778397290.png)

> 1.8中抛弃了分段锁的概念。而是启用了一种全新的方式实现，利用 **CAS 算法**以及**synchronized**。底层依然由“数组”+链表+红黑树的方式思想
>
> 锁的粒度就是HashEntry（首节点）。put时先扩容，如果没有出现hash碰撞则采用CAS自旋的方式进行插入。如果出现了hash冲突，则对这个链表或红黑树的头节点进行加synchronized锁

### 1.7 1.8版本对比

> 其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树,相对而言，总结如下思考
>
> 1. JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点）
> 2. JDK1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了
> 3. JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档

## <u>ThreadLocal软引用</u>

> **强引用**：只有当没有引用指向该对象才会进行gc
>
> **软引用**：只有在堆空间满后才会在gc时回收
>
> **软引用**：被gc时会就会被回收u
>
> ThreadLocal作为线程私有属性 thread中会有一个强引用指向threadlocal对象
>
> threadlocal的本质是thread本身维护一个map，其中键为弱引用的threadlocak 值为object
>
> 之所以使用软引用是防止在thread对象的强引用消除后，仍有key指针指向threadlocal导致空间无法回收
>
> 但是即使使用了弱引用后，仍有可能需要remove来消除这条记录

> - 

## ThreadLocal内存泄漏问题

> ThreadLocalMap 中使用的 key 为 ThreadLocal 的**弱引用**,而 value 是**强引用**。所以，**如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。**这样一来，ThreadLocalMap 中就会**出现key为null的Entry**。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法

## 为什么ThreadLocalMap中Entry的key的引用是弱引用

> 在方法中新建一个ThreadLocal对象，就有一个强引用指向它，在调用set（）后，线程的ThreadLocalMap对象里的Entry对象又有一个引用 k 指向它。如果后面这个引用 k 是强引用就会使方法执行完，栈帧中的强引用销毁了，对象还不能回收，造成严重的内存泄露。

## 阻塞队列BlockingQueue

> 阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。
>
> 这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。

### JDK7提供的阻塞队列

> ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。
>
> LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。
>
> PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。
>
> DelayQueue：一个使用优先级队列实现的无界阻塞队列。
>
> SynchronousQueue：一个不存储元素的阻塞队列。
>
> LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
>
> LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。
>
> **阻塞队列中加锁基本通过reentrantlock实现**

## 线程池

> 提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。

### 常见的线程池静态工厂方法

> （1）**newSingleThreadExecutor**：创建一个**单线程**的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个**新的线程来替代它**。此线程池保证所有任务的**执行顺序按照任务的提交顺序**执行。
>
> （2）**newFixedThreadPool**：创建**固定大小的线程池**。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。**如果希望在服务器上使用线程池，建议使用 newFixedThreadPool方法来创建线程池，这样能获得更好的性能。**
>
> （3） **newCachedThreadPool**：创建一个可缓存的线程池。如果**线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲**（60 秒不执行任务）**的线程**，**当任务数增加时，此线程池又可以智能的添加新线程来处理任务。**此线程池不会对线程池大小做限制，**线程池大小完全依赖于操作系统**（或者说 JVM）能够创建的最大线程大小。
>
> （4）**newScheduledThreadPool**：创建一个**大小无限的线程池**。此线程池支持定时以及周期性执行任务的需求。

### 优点

> **降低资源消耗**：重用存在的线程，减少对象创建销毁的开销。
>
> **提高响应速度**。可**有效的控制最大并发线程数**，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
>
> **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行**统一的分配，调优和监控**。
>
> **附加功能**：提供定时执行、定期执行、单线程、并发数控制等功能。

### 核心参数

> ​	**corePoolSize核心线程池大小**
>
> ​	当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，也会通过创建一个新线程来执行该任务，直到已创建的线程数大于或等于corePoolSize时

> ​	**maximumPoolSize线程池最大大小**
>
> ​	线程池所允许的最大线程个数。当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。**无界队列此参数无效**

> ​	**keepAliveTime线程存活保持时间**
>
> ​	当线程池中线程数大于核心线程数时，线程的空闲时间如果超过线程存活时间，那么这个线程就会被销毁，直到线程池中的线程数小于等于核心线程数。

> ​	**workQueue任务队列**
>
> ​	用于传输和保存等待执行任务的阻塞队列

> ​	**threadFactory线程工厂**
>
> ​	用于创建新线程。threadFactory创建的线程也是采用new Thread()方式

> ​	**handler线程饱和策略**
>
> ​	当线程池和队列都满了，再加入线程会执行此策略

### <u>为什么使用阻塞队列</u>

> 1 使用队列可以限制线程无限制的创建，避免因为内存占用导致的oom问题
>
> 2 阻塞队列可以保证任务队列中没有任务时阻塞获取任务的线程，使得线程进入wait状态，释放cpu资源。当队列中有任务时才唤醒对应线程从队列中取出消息进行执行。

### <u>如何关闭一个线程池</u>

> shutdownnow
>
> shutdown

### <u>如何确定一个线程池的参数 设置是合理的</u>

#### CPU密集型任务

> 尽量使用较小的线程池，一般为CPU核心数+1。 因为CPU密集型任务使得CPU使用率很高，若开过多的线程数，会造成CPU过度切换。

#### IO密集型任务

> 可以使用稍大的线程池，一般为2*CPU核心数。 IO密集型任务CPU使用率并不高，因此可以让CPU在等待IO的时候有其他线程去处理别的任务，充分利用CPU时间。

#### 混合型任务

> 可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。 只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。

### <u>Java中的线程池</u>

![](https://upload-images.jianshu.io/upload_images/6024478-9e47d2796c8ab1aa.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

#### newCachedThreadPool

> 用来创建一个可以无限扩大的线程池，适用于负载较轻的场景，执行短期异步任务。（可以使得任务快速得到执行，因为任务时间执行短，可以很快结束，也不会造成cpu过度切换）
>
> **可能会因为创建线程过多导致oom**

#### newFixedThreadPool

> 创建一个固定大小的线程池，因为采用无界的阻塞队列，所以实际线程数量永远不会变化，适用于负载较重的场景，对当前线程数量进行限制。（保证线程数可控，不会造成线程过多，导致系统负载更为严重）
>
> **可能因为等待队列中过长导致oom**

#### newScheduledThreadPool

> 适用于执行延时或者周期性任务。

#### newSingleThreadExecutor

> 创建一个单线程的线程池，适用于需要保证顺序执行各个任务。
>
> **可能因为等待队列中过长导致oom**

### <u>线程池中使用的阻塞工作队列</u>

#### LinkedBlockingQueue

> 三种构造函数
>
> > ​	LinkedBlockingQueue() 无参构造函数，链表长度为Integer.MAX_VALUE
> >
> > ​	LinkedBlockingQueue(int capacity) 指定capacity长度
> >
> > ​	LinkedBlockingQueue(Collection c) 不指定长度，即默认长度为Integer.MAX_VALUE，提供初始化元素
>
> 特点：
>
> > ​	链表节点由Node对象组成，每个Node有item变量用于存储元素，next变量指向下一个节点
> >
> > 执行put的时候，将元素放到链表尾部节点；take的时候从头部取元素
> >
> > 两种操作分别有一个锁putLock, takeLock,互不影响,可以同时进行

#### ArrayBlockingQueue

> 三种构造函数
>
> > ​	ArrayBlockingQueue(int capacity) 指定长度
> >
> > ​	ArrayBlockingQueue(int capacity, boolean fair) 指定长度，及指定是否使用FIFO顺序进出队列
> >
> > ​	ArrayBlockingQueue(int capacity, boolean fair, Collection c) 指定长度，进行队列顺序，初始元素
>
> 特点：
>
> > ​	ArrayBlockingQueue必须指定初始化长度，如果线程池使用该队列，指定长度大了浪费内存，长度小队列并发性不高，在数组满的时候，put操作只能阻塞等待，或者返回false
> >
> > ArrayBlockingQueue 只定义了一个Lock，put和take使用同一锁，不能同时进行

#### SynchronousQueue

> 内部并没有数据缓存空间
>
> 队列头元素是第一个排队要插入数据的**线程**，而不是要交换的数据。数据是在配对的生产者和消费者线程之间直接传递的，并不会将数据缓冲数据到队列中。
>
> 线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。

![](https://upload-images.jianshu.io/upload_images/16015500-8bf4856f92829bdc.png?imageMogr2/auto-orient/strip|imageView2/2/w/948/format/webp)

### <u>**饱和策略**</u>

> > - ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。**抛出异常拒绝**
> > - ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。**增加队列容量运行**
> > - ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。**直接丢弃**
> > - ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。**丢弃等待最久的**

![图解线程池实现原理](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8xMS8yNS8xNmVhMDQ3NjEyOTVlNzY2?x-oss-process=image/format,png)

## 原子操作类

> 原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。
>
> 处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。在 Java 中可以通过锁和循环 CAS 的方式来实现原子操作。

> i++的本质是三步操作 **并非是原子操作**
> 1 从内存中将i的值读取到cpu寄存器中
> 2 将i的值+1
> 3 将修改后的i的值 写入内存

> java.util.concurrent 这个包里面提供了一组原子类。其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由 JVM 从等待队列中选择另一个线程进入，这只是一种逻辑上的理解。
>
> AtomicInteger 类主要**利用 CAS** (compare and swap) + **volatile** 和 **native 方法**来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。
>
> CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是**用来拿到“原来的值”的内存地址**，返回值是 valueOffset。另外 **value 是一个volatile变量**，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。



# Linux

## linux体系结构

![linux体系结构](https://img-blog.csdnimg.cn/20200229173922281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RoaW5rV29u,size_16,color_FFFFFF,t_70)

> **用户空间**(User Space) ：用户空间又包括用户的应用程序(User Applications)、C 库(C Library) 。
>
> **内核空间**(Kernel Space) ：内核空间又包括**系统调用接口**(System Call Interface)、**内核**(Kernel)、**平台架构相关的代码**(Architecture-Dependent Kernel Code) 。

## 用户态 内核态

![](https://img-blog.csdn.net/20180721092710523?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5ODIzNjI3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> **用户态**：用户态即上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源，包括CPU资源、存储资源、I/O资源等。
>
> **内核态**：内核从本质上看是一种软件——控制计算机的硬件资源，并提供上层应用程序运行的环境。
>
> Linux操作系统中主要采用了**0和3两个特权级**，分别对应的就是**内核态**和**用户态**。用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。如果要执行文件操作、网络数据发送等操作必须**通过write、send等系统调用**，这些系统调用会调用内核的代码。进程会切换到Ring0，然后进入3G-4G中的内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到Ring3，回到用户态。这样，**用户态的程序就不能随意操作内核地址空间**，具有一定的安全保护作用。这说的保护模式是指通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程地址空间中的数据。
>
> 为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口：即**系统调用**。

## 用户态到内核态的转移

> **系统调用**：在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从用户态切换到内核态的过程。比如C函数库中的内存分配函数malloc()，它具体是使用**sbrk()系统调用**来分配内存，当malloc调用sbrk()的时候就涉及一次从用户态到内核态的切换，类似的函数还有printf()，调用的是**wirte()系统调用**来输出字符串，等等。
>
> **异常**： 当CPU正在执行运行在用户态的程序时，突然发生某些**预先不可知的异常事件**，这个时候就会触发从当前用户态执行的进程转向内核态执行相关的**异常事件**，典型的如缺页异常。
>
> **硬件中断**: 硬件中断是由与系统相连的外设(比如网卡 硬盘 键盘等)**自动产生**的. 每个设备或设备集都有他自己的IRQ(中断请求), 基于IRQ, CPU可以将相应的请求分发到相应的硬件驱动上(注: 硬件驱动通常是内核中的一个子程序, 而不是一个独立的进程). 比如当网卡受到一个数据包的时候, 就会发出一个中断.**硬件中断可以直接中断CPU.** 它会引起内核中相关代码被触发. 对于那些需要花费时间去处理的进程, 中断代码本身也可以被其他的硬件中断中断.对于时钟中断, 内核调度代码会将当前正在运行的代码挂起, 从而让其他代码来运行. 它的存在时为了让调度代码(或称为调度器)可以调度多任务.

## 硬中断和软中断

### 软中断

> 软中断的处理类似于硬中断. 但是软中断仅仅由**当前运行的进程产生**.通常软中断是对一些I/O的请求.软中断仅与内核相联系, 而内核主要负责对需要运行的任何其他进程进行调度.软中断**不会直接中断CPU**, 也只有**当前正在运行的代码(或进程)才会产生软中断**. 软中断是一种需要内核为正在运行的进程**去做一些事情**(通常为I/O)的请求.

### 两者区别

> 硬件中断是由**外设**引发的, 软中断是执行**中断指令**产生的.
> 硬件中断的中断号是由**中断控制器提供**的, 软中断的中断号由**指令直接指出**, 无需使用中断控制器.
> 硬件中断是**可屏蔽的**, 软中断**不可屏蔽**.
> 硬件中断处理程序要确保它能**快速地完成任务**, 这样程序执行时才不会等待较长时间, 称为**上半部.**
> 软中断处理硬中断未完成的工作, 是一种**推后执行**的机制, 属于**下半部.**

## 硬链接 软链接

> ### **硬链接**
>
> 由于 Linux 下的文件是通过索引节点(inode)来识别文件，硬链接可以认为是一个**指针**，指向**文件索引节点的指针**，系统并**不为它重新分配 inode** 。每添加一个一个硬链接，文件的链接数就加 1 。
>
> 不足：1）不可以在不同文件系统的文件间建立链接；2）只有超级用户才可以为目录创建硬链接。

> ### 软链接
>
> 软链接克服了硬链接的不足，**没有任何文件系统的限制**，任何用户可以创建指向目录的符号链接。因而现在更为广泛使用，它具有更大的灵活性，甚至可以**跨越不同机器、不同网络**对文件进行链接。
>
> 不足：因为**链接文件包含有原文件的路径信息**，所以当原文件从一个目录下移到其他目录中，再访问链接文件，系统就找不到了，而硬链接就没有这个缺陷，你想怎么移就怎么移；还有它要系统分配额外的空间用于建立新的索引节点和保存原文件的路径。

## 虚拟内存 驻留内存 共享内存

![t1](http://www.bo56.com/wp-content/uploads/2013/08/t1.png)

> **虚拟内存**是操作系统内核为了对进程地址空间进行管理（process address space management）而精心设计的一个**逻辑意义上的内存空间概念**。我们程序中的指针其实都是这个虚拟内存空间中的地址。
>
> 凡是程序运行过程中可能需要用到的指令或者数据都必须在虚拟内存空间中。既然说虚拟内存是一个逻辑意义上（假象的）的内存空间，为了能够让程序在物理机器上运行，那么必须有一套机制可以让这些假象的虚拟内存空间映射到物理内存空间（实实在在的RAM内存条上的空间）。这其实就是操作系统中**页映射表**（page table）所做的事情了。内核会为系统中每一个进程维护一份相互独立的页映射表。。页映射表的基本原理是将程序运行过程中需要访问的一段虚拟内存空间通过页映射表映射到一段物理内存空间上，这样CPU访问对应虚拟内存地址的时候就可以通过这种查找页映射表的机制访问物理内存上的某个对应的地址。**“页（page）”是虚拟内存空间向物理内存空间映射的基本单元。**（上方两个矩形区域都是虚拟内存）

> **驻留内存**，顾名思义是指那些被映射到进程虚拟内存空间的物理内存。上图1中，在系统物理内存空间中被着色的部分都是驻留内存。比如，A1、A2、A3和A4是进程A的驻留内存；B1、B2和B3是进程B的驻留内存。进程的**驻留内存就是进程实实在在占用的物理内存**。一般我们所讲的进程占用了多少内存，其实就是说的占用了多少驻留内存而不是多少虚拟内存。

> **共享内存**，表示的是进程占用的共享内存大小。在上图1中我们看到进程A虚拟内存空间中的A4和进程B虚拟内存空间中的B3都映射到了物理内存空间的A4/B3部分。为什么会出现这样的情况呢？其实我们写的程序会依赖于很多外部的**动态库**（.so），比如libc.so、libld.so等等。这些动态库在内存中仅仅会保存/映射一份，如果某个进程运行时需要这个动态库，那么动态加载器会将这块内存映射到对应进程的虚拟内存空间中。多个进展之间通过共享内存的方式相互通信也会出现这样的情况。这么一来，就会出现不同进程的虚拟内存空间会映射到相同的物理内存空间。这部分物理内存空间其实是被多个进程所共享的，所以我们将他们称为共享内存，用SHR来表示。某个进程占用的内存除了和别的进程共享的内存之外就是自己的独占内存了。所以要计算进程独占内存的大小只要用RES的值减去SHR值即可。

## linux命令

```
netstat -ntlp   //查看当前所有tcp端口·
```

```
netstat -ntulp |grep 80   //查看所有80端口使用情况·
```

```
netstat -an | grep 3306   //查看所有3306端口使用情况·
```

```
netstat  -lanp	//查看一台服务器上面哪些服务及端口
```

## 进程 线程 协程

> ![](https://upload-images.jianshu.io/upload_images/4933701-4dfd867ca99f40d7.png?imageMogr2/auto-orient/strip|imageView2/2/w/646/format/webp)
>
> 进程：进程是系统进行**资源分配和调度的一个独立单位**。每个进程都有自己的**独立内存空间**，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以**上下文进程间的切换开销**（栈、寄存器、虚拟内存、文件句柄等）**比较大**，但相对比较**稳定安全**。
>
> ![](https://upload-images.jianshu.io/upload_images/4933701-167191f7722edd23.png?imageMogr2/auto-orient/strip|imageView2/2/w/653/format/webp)
>
> 线程：线程是进程的一个实体,是**CPU调度和分派的基本单位**,它是比进程更小的能**独立运行的基本单位**.线程自己基本上**不拥有系统资源**,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要**通过共享内存**，上下文切换很快，**资源开销较少**，但相比进程不够稳定**容易丢失数据**。
>
> ![](https://upload-images.jianshu.io/upload_images/4933701-4a7846c5d7c1290c.png?imageMogr2/auto-orient/strip|imageView2/2/w/646/format/webp)
>
> 协程：是一种比线程更加轻量级的存在，正如一个进程可以拥有多个线程一样，**一个线程可以拥有多个协程**。
> 协程不是被操作系统内核所管理的，而是完全由程序所控制，也就是在**用户态执行**。这样带来的好处是**性能大幅度的提升**，因为不会像线程切换那样消耗资源。
> 协程不是进程也不是线程，而是一个**特殊的函数**，这个函数可以在某个地方**挂起**，并且可以重新在挂起处外继续运行。但是有一点必须明确的是，一个线程的多个协程的运行是**串行**的。一个线程内协程却绝对是串行的，无论CPU有多少个核。毕竟协程虽然是一个特殊的函数，一个线程内可以运行多个函数，但这些函数都是**串行运行**的。当一个协程运行时，其它协程必须**挂起**。



## <u>进程通信的方式</u>

### 管道

> 通常指无名管道
>
> 1. 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。
> 2. 它只能用于具有亲缘关系的进程之间的通信（也是**父子进程或者兄弟进程**之间）。
> 3. 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

### 命名管道

> 也称FIFO 是一种文件类型
>
> 1. FIFO可以在**无关的进程**之间交换数据，与无名管道不同。
> 2. FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。

### 消息队列

> 是消息的链接表，存放在内核中
>
> 1. 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。
> 2. 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。
> 3. 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。

### 信号量

> 它是一个计数器。信号量用于实现进程间的**互斥与同步**，而不是用于存储进程间通信数据
>
> 1. 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。
> 2. 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。
> 3. 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。
> 4. 支持信号量组。

### 共享内存

> 指两个或多个进程共享一个给定的存储区。
>
> 1. 共享内存是最快的一种 IPC，因为进程是直接对内存进行存取。
> 2. 因为多个进程可以同时操作，所以需要进行同步。
> 3. 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。

#### **总结**

> 1.管道：速度慢，容量有限，只有父子进程能通讯   
>
> 2.FIFO：任何进程间都能通讯，但速度慢   
>
> 3.消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题   
>
> 4.信号量：不能传递复杂消息，只能用来同步   
>
> 5.共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存

## 死锁的四个必要条件

> **互斥条件**：一个资源每次只能被一个进程使用，即在一段时间内某 资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。
>
> **请求与保持条件**：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源 已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。
>
> **不可剥夺条件**:进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能 由获得该资源的进程自己来释放（只能是主动释放)。
>
> **循环等待条件**: 若干进程间形成首尾相接循环等待资源的关系



# 网络

## DNS解析过程

![img](https://img-blog.csdn.net/20171211190812796?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbTBfMzc4MTI1MTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

> 1 先查询浏览器本地缓存 如果命中直接访问
> 2 查询本地操作系统的存储 如没有 查询host文件中是否对于域名和ip做了绑定
> \3.  如果至此还没有命中域名，才会真正的请求本地域名服务器（LDNS）来解析这个域名，这台服务器一般在你的城市的某个角落，距离你不会很远，并且这台服务器的性能都很好，一般都会缓存域名解析结果，大约80%的域名解析到这里就完成了。
>
> \4. 如果LDNS仍然没有命中，就直接跳到Root Server 域名服务器请求解析
>
> \5. 根域名服务器返回给LDNS一个所查询域的主域名服务器（gTLD Server，国际顶尖域名服务器，如.com .cn .org等）地址
>
> \6. 此时LDNS再发送请求给上一步返回的gTLD
>
> \7. 接受请求的gTLD查找并返回这个域名对应的Name Server的地址，这个Name Server就是网站注册的域名服务器
>
> \8. Name Server根据映射关系表找到目标ip，返回给LDNS
>
> \9. LDNS缓存这个域名和对应的ip
>
> \10. LDNS把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束

## 一个HTTP请求详细过程

### 域名解析

> **DNS域名解析过程**
>
> 如果在hosts文件中也没有找到对应的条目，浏览器就会发起一个**DNS的系统调用**，就会向本地配置的首选DNS服务器（一般是电信运营商提供的，也可以使用像Google提供的DNS服务器）发起域名解析请求（通过的是UDP协议向DNS的53端口发起请求，这个请求是递归的请求，也就是运营商的DNS服务器必须得提供给我们该域名的IP地址），运营商的DNS服务器首**先查找自身的缓存，找到对应的条目，且没有过期，则解析成功**。如果没有找到对应的条目，则有运营商的DNS代我们的浏览器发起迭代DNS解析请求，它首先是会**找根域的DNS的IP地址**（这个DNS服务器都内置13台根域的DNS的IP地址），找打根域的DNS地址，就会向其发起请求（请问www.cnblogs.com这个域名的IP地址是多少啊？），根域发现这是一个顶级域**com域的一个域名**，于是就告诉运营商的DNS我不知道这个域名的IP地址，但是我知道com域的IP地址，你去找它去，于是运营商的DNS就得到了com域的IP地址，又**向com域的IP地址发起了请求**（请问www.cnblogs.com这个域名的IP地址是多少?）,com域这台服务器告诉运营商的DNS我不知道www.cnblogs.com这个域名的IP地址，但是我知道cnblogs.com这个域的DNS地址，你去找它去，于是运营商的DNS又向cnblogs.com这个域名的DNS地址（这个一般就是由域名注册商提供的，像万网，新网等）发起请求（请问www.cnblogs.com这个域名的IP地址是多少？），这个时候cnblogs.com域的DNS服务器一查，诶，果真在我这里，于是就把找到的结果发送给运营商的DNS服务器，这个时候运营商的DNS服务器就拿到了www.cnblogs.com这个域名对应的IP地址，并返回给Windows系统内核，内核又把结果返回给浏览器，终于浏览器拿到了www.cnblogs.com 对应的IP地址，该进行一步的动作了。
>
> **本地运营商DNS服务器--》根域DNS服务器--》（从根服务器向下）直到找到对应域名对应IP--》交给运营商服务器，进行返回浏览器**

### 与服务器建立连接

#### 三次握手

> **三次握手**
>
> 第一次握手：建立连接时，[客户端](http://baike.baidu.com/view/930.htm)发送[syn](http://baike.baidu.com/view/488528.htm)包（syn=j）到[服务器](http://baike.baidu.com/view/899.htm)，并进入[SYN_SENT](http://baike.baidu.com/view/840439.htm)状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers），表示建立连接。即主机A发送位码为syn＝1，随机产生seq number=1234567的数据包到服务器，主机B由SYN=1知道，A要求建立联机；
>
> 第二次握手：[服务器](http://baike.baidu.com/view/899.htm)收到[syn](http://baike.baidu.com/view/488528.htm)包，必须确认客户的SYN（[ack](http://baike.baidu.com/view/204040.htm)=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入[SYN_RECV](http://baike.baidu.com/view/1520054.htm)状态；即主机B收到请求后要确认联机信息，向A发送ack number=(主机A的seq+1)，syn=1，ack=1，随机产生seq=7654321的包；
>
> 第三次握手：[客户端](http://baike.baidu.com/view/930.htm)收到[服务](http://baike.baidu.com/view/133203.htm)器的SYN+ACK包，向[服务器](http://baike.baidu.com/view/899.htm)发送确认包ACK([ack](http://baike.baidu.com/view/204040.htm)=k+1），此包发送完毕，客户端和服务器进入[ESTABLISHED](http://baike.baidu.com/view/1137549.htm)（TCP连接成功）状态，完成三次握手，表示响应。即主机A收到后检查ack number是否正确，即第一次发送的seq number+1，以及位码ack是否为1，若正确，主机A会再发送ack number=(主机B的seq+1)，ack=1，主机B收到后确认seq值与ack=1则连接建立成功。
>
> #### **如果第三次确认没有收到？**
>
> 如果第三次的确认包没有收到，服务器会不停的重试并等待一定的时间后放弃这个未完成的连接，这段时间叫做SYN timeout，这段时间大约30秒-2分钟左右。当前线程会暂时的不可用。因此也有可能会导致DDos攻击
>
> #### 第三次握手时能否传递数据
>
> TCP协议建立连接的三次握手过程中的**第三次握手允许携带数据**。

##### 为什么需要三次握手

> 为了防止**已失效的连接请求报文段突然又传送到了服务端，因而产生错误。**

> “已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个**连接请求报文段**并没有丢失，而是在某个网络结点**长时间的滞留了**，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，**server的很多资源就白白浪费掉了**。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”

#### 四次挥手

![img](https://img2018.cnblogs.com/blog/1703075/201907/1703075-20190717131606589-451665711.png)

> **四次挥手**
>
> 第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入**FIN_WAIT_1**状态；这表示主机1没有数据要发送给主机2了；
>
> 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入**FIN_WAIT_2**状态；主机2告诉主机1，我“同意”你的关闭请求；
>
> 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入**LAST_ACK**状态；
>
> 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入**TIME_WAIT**状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。

##### 	time_wait状态

> #### **time_wait状态是什么**
>
> 在TCP连接中四次挥手关闭连接时，主动关闭连接的一方（上图中时Client）会在发送最后一条ACK报文后维持一段时长2MSL（MSL指的是数据包在网络中的最大生存时间）的等待时间后才会真正关闭连接到CLOSED状态，该时间段内主动关闭方的状态为TIME_WAIT。
>
> #### **为什么需要time_wait**
>
> **为实现TCP连接的可靠释放**
> 若主动断开连接方（上图中Client）最后一次ACK报文丢失了，会触发被动方（上图中Server）的超时重传机制，Server再次向Client发送FIN+ACK报文，如果Client在发送完最后一次ACK后立即断开连接（没有TIME_WAIT状态），则Server会收到RST=1的报文响应，表示连接建立异常，而此时并非异常，只是正常的关闭连接过程，进而导致Server端不能正常关闭连接。因此，Client必须维护2MSL的等待时间，确保在Server端第二次发送的FIN+ACK被Client正常接收，收到后Client立即发送ACK给Server，并重新启动2MSL计时器。（因为极端情况涉及两次报文传输（Client向Server的ACK，Server向Client的FIN+ACK），所以等待时间为2MSL）
>
> **为使旧的重复数据包在网络中因过期而消失**
> 可能存在一些数据包在传输过程中出现异常而导致严重推迟，而在它到来之前发送方已经重发了该报文，并完成其任务。如果在被推迟的报文未抵达前接收方断开了连接，随后又建立了一个与之前相同IP、Port的连接，而之前被推迟的报文在这时恰好到达，而此时此新连接非彼连接，从而会发生数据错乱，进而导致无法预知的情况。因此必须维持一段等待时间，使迟到的报文在网络中完全消失，并且在等待时间内，因为连接并未关闭，所以不能建立相同四元组的新连接，就不会出现数据错乱。
>
> #### 服务端主动结束从而进入time_wait状态的危害
>
> 大量的文件描述符占据，导致无法接入新的连接
>
> 因为端口（可能是80）还被之前处于TIME_WAIT的连接占用着，如果TIME_WAIT状态维持60秒，60秒服务器都起不来
>
> #### 如何解决time_wait
>
> **tcp_tw_recycle**：顾名思义就是回收TIME_WAIT连接。但是当多个客户端通过NAT方式联网，对服务端而言客户端等同于一个，所以可能存在时间戳差异导致时间戳错乱。
> **tcp_tw_reuse**：顾名思义就是复用TIME_WAIT连接。当创建新连接的时候，如果可能的话会考虑复用相应的TIME_WAIT连接。
>
> **在服务端打开keepAlive，让客户端主动关闭连接。**

### 发起HTTP请求

#### HTTP请求报文

> 一个HTTP请求报文由**请求行**（request line）、**请求头部**（header）、**空行**和**请求数据**4个部分组成

> **请求行**分为三个部分：**请求方法**、**请求地址**和**协议版本**
>
> HTTP/1.1 定义的**请求方法**有8种：GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE。
> 最常的两种GET和POST，如果是RESTful接口的话一般会用到GET、POST、DELETE、PUT。
>
> **请求地址**
> URL:统一资源定位符，是一种自愿位置的抽象唯一识别方法。
> 组成：<协议>：//<主机>：<端口>/<路径>
>
> **协议版本**的格式为：HTTP/主版本号.次版本号，常用的有HTTP/1.0和HTTP/1.1

> **请求头部**
> 请求头部为请求报文添加了一些附加信息，由“名/值”对组成，每行一对，名和值之间使用冒号分隔。
>
> > ​		8、Accept
> >
> > 　　告诉WEB服务器自己接受什么介质类型，*/* 表示任何类型，type/* 表示该类型下的所有子类型，type/sub-type。
> >
> > 　　9、Accept-Charset
> >
> > 　　浏览器告诉服务器自己能接收的字符集。
> >
> > 　　10、Accept-Encoding
> >
> > 　　浏览器申明自己接收的编码方法，通常指定压缩方法，是否支持压缩，支持什么压缩方法（gzip，deflate）。
> >
> > 　　11、Accept-Language
> >
> > 　　浏览器申明自己接收的语言。语言跟字符集的区别：中文是语言，中文有多种字符集，比如big5，gb2312，gbk等等。
> >
> > 　　12、**Authorization**
> >
> > 　　当客户端接收到来自WEB服务器的 WWW-Authenticate 响应时，用该头部来回应自己的身份验证信息给WEB服务器。
> >
> > 　　13、If-Match
> >
> > 　　如果对象的 ETag 没有改变，其实也就意味著对象没有改变，才执行请求的动作，获取文档。
> >
> > 　　14、If-None-Match
> >
> > 　　如果对象的 ETag 改变了，其实也就意味著对象也改变了，才执行请求的动作，获取文档。
> >
> > 　　15、If-Modified-Since
> >
> > 　　如果请求的对象在该头部指定的时间之后修改了，才执行请求的动作（比如返回对象），否则返回代码304，告诉浏览器该对象没有修改。例如：If-Modified-Since：Thu, 10 Apr 2008 09:14:42 GMT
> >
> > 　　16、If-Unmodified-Since
> >
> > 　　如果请求的对象在该头部指定的时间之后没修改过，才执行请求的动作（比如返回对象）。
> >
> > 　　17、If-Range
> >
> > 　　浏览器告诉 WEB 服务器，如果我请求的对象没有改变，就把我缺少的部分给我，如果对象改变了，就把整个对象给我。浏览器通过发送请求对象的ETag 或者自己所知道的最后修改时间给 WEB 服务器，让其判断对象是否改变了。总是跟 Range 头部一起使用。
> >
> > 　　18、Range
> >
> > 　　浏览器（比如 Flashget 多线程下载时）告诉 WEB 服务器自己想取对象的哪部分。例如：Range: bytes=1173546
> >
> > 　　19、Proxy-Authenticate
> >
> > 　　代理服务器响应浏览器，要求其提供代理身份验证信息。
> >
> > 　　20、Proxy-Authorization
> >
> > 　　浏览器响应代理服务器的身份验证请求，提供自己的身份信息。
> >
> > 　　21、**Host**
> >
> > 　　客户端指定自己想访问的WEB服务器的域名/IP 地址和端口号。如Host：rss.sina.com.cn
> >
> > 　　22、Referer
> >
> > 　　浏览器向WEB 服务器表明自己是从哪个网页URL获得点击当前请求中的网址/URL，例如：Referer：http://www.ecdoer.com/
> >
> > 　　23、User-Agent
> >
> > 　　浏览器表明自己的身份（是哪种浏览器）。例如：User-Agent：Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN;rv:1.8.1.14) Gecko/20080404 Firefox/2.0.0.14

> **请求数据**
> 可选部分，比如GET请求就没有请求数据。

### 服务器响应HTTP请求，浏览器得到html代码

> 接收到HTTP请求之后，就轮到负载均衡登场了，它位于网站的最前端，把短时间内较高的访问量分摊到不同机器上处理。负载均衡方案有软件、硬件两种

#### HTTP响应报文

> HTTP响应报文主要由**状态行**、**响应头部**、**空行**以及**响应数据**组成。

> **状态行**
> 由3部分组成，分别为：协议版本，状态码，状态码描述。
>
> **协议版本**的格式为：HTTP/主版本号.次版本号，常用的有HTTP/1.0和HTTP/1.1
>
> **状态码**描述是对状态码的简单描述1xx：指示信息–表示请求已接收，继续处理。
> 2xx：成功–表示请求已被成功接收、理解、接受。
> 3xx：重定向–要完成请求必须进行更进一步的操作。
> 4xx：客户端错误–请求有语法错误或请求无法实现。
> 5xx：服务器端错误–服务器未能实现合法的请求。

> **响应头部**
>
> | Access-Control-Allow-Origin | 指定哪些网站可以跨域资源共享                                 | Access-Control-Allow-Origin:*                        |
> | --------------------------- | ------------------------------------------------------------ | :--------------------------------------------------- |
> | Accept-Patch                | 指定服务器所支持的文档补丁格式                               | Accept-Patch:text/exa,ple;charset=utf-8              |
> | Accept-Ranges               | 服务器支持的内容范围                                         | Accept-Ranges:bytes                                  |
> | Age                         | 响应对象在代理缓存中存在的时间，以秒为单位                   | Age:12                                               |
> | Allow                       | 对于资源的有效动作                                           | Allow:GET,POST,HEAD                                  |
> | Cache-control               | 告知客户端缓存机制，表示是否可缓存 或缓存有效时间以秒为单位  | Cache-control:no-cache                               |
> | Connection                  | 针对该链接的所有预期的选项                                   | Connection:close                                     |
> | Content-Disposition         | 对已知MIME类型资源的描述，浏览器可以根据此响应决定动作，如下载资源或打开 | Content-Disposition:attachment;filename="fname.text" |
> | Content-Encoding            | 响应资源使用的编码类型                                       | Content-Encoding:gzip                                |
> | Content-language            | 响应内容使用的语言                                           | Content-language:zh-cn                               |
> | Content-Length              | 响应消息体的长度，使用八进制表示                             | Content-Length:348                                   |
> | Content-Location            | 返回数据的一个候选位置                                       | Content-Location:/index.htm                          |
> | Content-MD5                 | 响应内容的MD5散列值以Base64方式编码                          | Content-MD5:IDKOiSsGsvjkKJHkjKbg                     |
> | Content-Range               | 如果响应的是部分消息，则表示属于完整消息的哪个部分           | Content-Range:bytes12020-47021/47022                 |
> | Content-Type                | 当前内容的MIME类型                                           | Content-Type:text/html;charset=utf-8                 |
> | Date                        | 此条消息被发送时的日期和时间(以RFC 7231中定义的"HTTP日期"格式来表示) | Date:Wed,18 Jul 2018 21:01:33 GTM                    |
> | Etag                        | 对于某个资源的特定版本的一个标识符， 通常是一个消息散列      | Etag:977823cd9080da09vsd89kj923jhkb8df8              |
> | Expires                     | 指定一个日期/时间，超过该时间此回应过期                      | Expires:Wed,18 Jul 2018 21:01:33 GTM                 |
> | Last-Modified               | 请求对象的最后修改时间 (以RFC 7231中定义的"HTTP日期"格式来表示) | Last-Modified:Wed,18 Jul 2018 21:01:33 GTM           |
> | Link                        | 用来表示与另外一个资之间的类型关系， 此类型关系是在RFC 5988中定义的 | Link:rel="alternate"                                 |
> | Location                    | 用于重定向或者在创建了某个新资源时使用                       | Location:http://www.baidu.com                        |
> | P3P                         | P3P策略的设置                                                | P3P:CP="This is not a P3Ppolicy!"                    |
> | Pragaa                      | 效果并不确定，这些响应头可能在请求/回应链 中的不同时候产生不同的效果 | Pragaa:no-cache                                      |
> | Proxy-Authenticate          | 要求在访问代理是提供身份认证信息                             | Proxy-Authenticate:Basic                             |
> | Public-Key-Pins             | 用于防止中间攻击，申明网站认证中 传输层安全协议的证书散列值  | Public-Key-Pins:max-age=259200;pin-sha256="… ..."    |
> | Refresh                     | 用于重定向或者当一个新的资源被创建时 默认在5秒后刷新重定向   | Refresh:5;url=http://www.baidu.com                   |
> | Retry-After                 | 如果某个实体临时不可用，那么此协议用于告知用户 端稍后重试，其值可以是特定的时间段(以秒为单位) 或者是一个超文本传输协议日期 | Retry-After:120/Wed,18 Jul 2018 21:01:33 GTM         |
> | Server                      | 服务器名称                                                   | Server:nginx/1.6.3                                   |
> | Set-Cookie                  | 设置HTTP Cookie,cookie被设置在请求的服务端域名下             | Set-Cookie:user_name=garrett;user_id=001             |
> | Status                      | 通用网管接口响应字段，用来说明当前HTTP链接状态               | Status:200 ok                                        |
> | Trailer                     | 说明传输中分块编码的编码信息                                 | Trailer:Max-Forwards                                 |
> | Transfer-Encoding           | 表示实体传输给用户的编码形式，包括：chunked, compress,deflate,gzip,identify等 | Transfer-Encoding:chunked                            |
> | Upgrade                     | 要求用户升级到另外一个高版本的协议                           | Upgrade:HTTP/2.0,SHTTP/1.3,IRC/6.9,RTA/X11           |
> | Vary                        | 告知下游的代理服务器如何对之后的请求协议头进行 匹配，以决定是否可使用已缓存的响应内容而不是 重新从原服务器请求新的内容 | Vary:*                                               |
> | Vis                         | 告知代理服务器的客户端，当前的响应式通过什么途径发送的       | Vis:1.0 FRED, 1.1 baidu.com                          |

> **响应数据**
> 用于存放需要返回给客户端的数据信息。

### 浏览器解析html代码 并请求html中资源

### 浏览器对页面进行渲染呈现



## 状态码

> 状态码的职责是当客户端向服务器端发送请求时，描述返回的请求结果。借助状态码，用户可以知道服务器端是正常处理了请求，还是出现了错误

|      | 类别                            | 类别                       |
| ---- | ------------------------------- | -------------------------- |
| 1xx  | Informational(信息性状态码)     | 接受的请求正在处理         |
| 2xx  | Success(成功状态码)             | 请求正常处理完毕           |
| 3xx  | Redirection(重定向状态码)       | 需要进行附加操作一完成请求 |
| 4xx  | Client Error (客户端错误状态码) | 服务器无法处理请求         |
| 5xx  | Server Error(服务器错误状态码)  | 服务器处理请求出错         |

#### 2xx 成功

> 2XX 的响应结果表明请求被正常处理了

##### 	200正常处理

> ​	响应交过表明请求被正常处理了

##### 	204无内容

> ​	服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。比如，当从浏览器发出请求处理后，返回 204 响应，那么浏览器显示的页面不发生更新。

#### 3xx 重定向

> 响应结果表明浏览器需要执行某些特殊的处理以正确处理请求

##### 	301永久性移动

> ​	该状态码表示请求的资源已被分配了新的 URI，以后应使用资源现在所指的 URI。也就是说，如果已经把资源对应的 URI保存为书签了，这时应该按 Location 首部字段提示的 URI 重新保存。

##### 	302临时重定向

> ​	该状态码表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。

##### 303另一个url

> ​	该状态码表示由于请求对应的资源存在着另一个 URI，应使用 GET方法定向获取请求的资源

##### 304未修改

> ​	自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。如果网页自请求者上次请求后再也没有更改过，您应将服务器配置为返回此响应(称为 If-Modified-Since HTTP 标头)。服务器可以告诉 Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。

#### 4XX 客户端

> ​	该状态码表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。另外，浏览器会像 200 OK 一样对待该状态码。

##### 401 未验证

> ​	该状态码表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。另外若之前已进行过 1 次请求，则表示用 户认证失败。
>
> ​	当浏览器初次接收到 401 响应，会弹出认证用的对话窗

##### 403不允许访问 拒绝

> ​	该状态码表明对请求资源的访问被服务器拒绝了。服务器端没有必要给出拒绝的详细理由，但如果想作说明的话，可以在实体的主体部分对原因进行描述，这样就能让用户看到了。
>
> ​	未获得文件系统的访问授权，访问权限出现某些问题（从未授权的发送源 IP 地址试图访问）等列举的情况都可能是发生 403 的原因

##### 404 没有请求得资源

> ​	该状态码表明服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由时使

#### 5xx服务器错误

##### 500 内部服务出错

> 该状态码表明服务器端在执行请求时发生了错误。也有可能是 Web应用存在的 bug 或某些临时的故障。

##### 503服务不可用

> 该状态码表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入RetryAfter 首部字段再返回给客户

## http头部信息

### 请求头

> 请求头用于说明是谁或什么在发送请求、请求源于何处，或者客户端的喜好及能力。服务器可以根据请求头部给出的客户端信息，试着为客户端提供更好的响应。

> - Accept:浏览器能够处理的内容类型
> - Accept-Charset:浏览器能够显示的字符集
> - Accept-Encoding：浏览器能够处理的压缩编码
> - Accept-Language：浏览器当前设置的语言
> - Connection：浏览器与服务器之间连接的类型
> - Cookie：当前页面设置的任何Cookie
> - Host：发出请求的页面所在的域
> - Referer：发出请求的页面的URL
> - User-Agent：浏览器的用户代理字符串

### 响应头

> 响应头向客户端提供一些额外信息，比如谁在发送响应、响应者的功能，甚至与响应相关的一些特殊指令。这些头部有助于客户端处理响应，并在将来发起更好的请求。

> - Date：表示消息发送的时间，时间的描述格式由rfc822定义
> - server:服务器名字。
> - Connection：浏览器与服务器之间连接的类型
> - content-type:表示后面的文档属于什么MIME类型
> - Cache-Control：控制HTTP缓存

[http请求头]: https://blog.csdn.net/wangzhen_csdn/article/details/80776991

### 实体头

> 实体头部提供了有关实体及其内容的大量信息，从有关对象类型的信息，到能够对资源使用的各种有效的请求方法。总之，实体头部可以告知接收者它在对什么进行处理。请求消息和响应消息都可以包含实体信息，实体信息一般由实体头域和实体组成。

> **Allow** ：服务器支持哪些请求方法（如GET、POST等）。
>
> Location 表示客户应当到哪里去提取文档，用于将接收端定位到资源的位置（URL）上。
>
> Content-Base　解析主体中的相对URL时使用的基础URL。
>
> Content-Encoding　　WEB服务器表明自己使用了什么压缩方法（gzip，deflate）压缩响应中的对象。例如：Content-Encoding：gzip
>
> Content-Language　　WEB 服务器告诉浏览器理解主体时最适宜使用的自然语言。
>
> Content-Length　　WEB服务器告诉浏览器自己响应的对象的长度或尺寸，例如：Content-Length: 26012
>
> Content-Location　　资源实际所处的位置。
>
> Content-MD5　　主体的MD5校验和。
>
> Content-Range　　实体头用于指定整个实体中的一部分的插入位置，他也指示了整个实体的长度。在服务器向客户返回一个部分响应，它必须描述响应覆盖的范围和整个实体长度。一般格式： Content-Range:bytes-unitSPfirst-byte-pos-last-byte-pos/entity-legth。例如，传送头500个字节次字段的形式：Content-Range:bytes0- 499/1234如果一个http消息包含此节（例如，对范围请求的响应或对一系列范围的重叠请求），Content-Range表示传送的范围，Content-Length表示实际传送的字节数。
>
> **Content-Type**　　WEB 服务器告诉浏览器自己响应的对象的类型。例如：Content-Type：application/xml
>
> Etag　　就是一个对象（比如URL）的标志值，就一个对象而言，比如一个html文件，如果被修改了，其Etag也会别修改，所以，ETag的作用跟Last-Modified的作用差不多，主要供WEB服务器判断一个对象是否改变了。比如前一次请求某个html文件时，获得了其 ETag，当这次又求这个文件时，浏览器就会把先前获得ETag值发送给WEB服务器，然后WEB服务器会把这个ETag跟该文件的当前ETag进行对比，然后就知道这个文件有没有改变了。
>
> Expires　　WEB服务器表明该实体将在什么时候过期，对于过期了的对象，只有在跟WEB服务器验证了其有效性后，才能用来响应客户请求。是 HTTP/1.0 的头部。例如：Expires：Sat, 23 May 2009 10:02:12 GMT
>
> Last-Modified　　WEB服务器认为对象的最后修改时间，比如文件的最后修改时间，动态页面的最后产生时间等等。例如：Last-Modified：Tue, 06 May 2008 02:42:43 GMT





## 数据的封装与解封

**封装**

![img](https://img-blog.csdnimg.cn/20200228205426715.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Bvd2VyY2h1bg==,size_16,color_FFFFFF,t_70)

> 在实际数据传输中每一层都有相应的协议，但是其中的表示层和会话层的协议（传输数据的时候不会对数据做任何操作），于是将这两层合并到应用层，也称为**TCP/IP五层模型**。
>
> 在这里我们假设我们的软件发送hello到目的端:
>
> 1、数据在应用层进行封装发出、经过 表示和会话层时候不会做任何操作：**数据包内容为hello**
>
> 2、当数据包传送到传输层时：传输层会对数据包进一步封装、为该数据包添加TCP/UDP头，具体添加哪一个取决于应用层使用得是哪一个，其中包含了源端口和目的端口号、源端口号往往是指定的、或是浏览器自动指派的端口。
>
> 3、在传输层封装了端口号、数据传送到网络层对数据包进一步封装，为该数据包添加了IP头、其中包含源ip和目的ip，这样在数据传输的过程中数据就可以找到对应的目的主机
>
> 4、经过以上的封装、数据就已经到达了设备的网卡上、下一步就要通过网线进行传输了、但是一个载体来进行传输、因此在数据包中在加入含有源MAC地址和目标MAC地址字段
>
> 5、经过物理层实际的网线进行数据传输

**解封**

![解封装过程](https://img-blog.csdn.net/20180904113047879?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYXl1bjE5OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

## TCP与UDP

### 为什么说TCP面向流 而UDP面向报文

> 从直观上理解，可以将TCP的传输方式看作是蓄水池，可以一次性发送所有数据，也可以分多次发送数据。而接收端也可一次性读取所有数据，也可以分批进行读取。当蓄水池满了，可以停止发送。
> 而UDP没有建立连接，所以可能会有多个发送发在向这单一ip端口发送数据，如果不面向报文，会将多个发送方的数据合并。所以UDP发送write了几次 接收方就要读几次
>
> > 面向报文的传输方式是应用层交给UDP多长的报文，UDP就**照样发送**，即**一次发送一个报文**。UDP对应用层交下来的报文，**既不合并，也不拆分**，而是保留这些报文的边界。这也就是说，应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。
> >
> > 应用程序和TCP的交互是**一次一个数据块**（大小不等），但TCP把应用程序看成是**一连串的无结构的字节流**。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它**划分短一些**再传送。如果应用程序一次只发送一个字节，TCP也可以等待**积累有足够多的字节**后再构成报文段发送出去。
> >
> > 在TCP建立连接前两次握手的SYN报文中选项字段的MSS值，通信双方**商定通信的最大报文长度**。如果应用层交付下来的数据过大，就会对数据分段，然后发送；否则通过滑动窗口协议来控制通信双发的数据。

## TCP长连接

> TCP 长连接是一种保持 TCP 连接的机制。当一个 TCP 连接建立之后，启用 TCP Keep Alive 的一端便会启动一个计时器，当这个计时器到达 0 之后，一个 TCP 探测包便会被发出。这个 TCP 探测包是一个纯 ACK 包，但是其 Seq 与上一个包是重复的。
>
> **keep alive 技术只是 TCP 技术中的一个可选项。因为不当的配置可能会引起诸如一个正在被使用的 TCP 连接被提前关闭这样的问题，所以默认是关闭的**



## HTTP长连接

http1.1中为了解决网页内容越来越复杂，且包含大量图片，css等资源后，效率太低的问题。所以引入了http长连接的概念（也称为HTTP keep-alive）

![img](https://upload-images.jianshu.io/upload_images/3108769-e429124b24c3f80e.png?imageMogr2/auto-orient/strip|imageView2/2/w/450/format/webp)

建立长连接时，在HTTP请求头中将包含以下内容

```http
Connection: Keep-Alive
```

服务端同意建立长连接后，响应头将包含

```http
Connection: Keep-Alive
```

需要关闭连接时，HTTP头中将包含

```http
Connection: Close
```



## TCP Keep Alive 与 HTTP Keep Alive 的关系

> TCP Keep Alive 和 HTTP Keep Alive 是两个目的不同的技术，不存在谁依赖于谁的关系。TCP Keep Alive 用于探测对端是否存在，而 HTTP Keep Alive 用于协商以复用 TCP 连接。即便一个 TCP 连接未启用 Keep Alive 功能，也不妨碍 HTTP 层面开启长连接。

## TCP保证可靠传输的措施

> TCP连接传送的数据**无差错**、**不重复**、且**按序到达**；
>
> 主要核心保障是 **超时重传**和**确认机制**

### **校验和**

> 在数据传输过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来，并且前面的进位不能丢弃，补在最后，然后取反，得到校验和。
>
> 1. 发送方：在发送数据之前计算校验和，并进行校验和的填充。
> 2. 接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方进行比较。

### **序列号**

> TCP传输时将**每个字节的数据都进行了编号**，这就是序列号。序列号的作用不仅仅是应答作用，有了序列号能够将接收到的数据根据序列号进行**排序**，并且**去掉重复**的数据。这也是TCP可靠性的保证之一。

### **确认应答**（核心）

> TCP传输过程中，每次接收方接收到数据后，都会**对传输方进行确认应答**。也就是**发送ACK报文**，这个ACK报文中带有对应的确认序列号，告诉发送方，接收了哪些数据，下一次数据从哪里传。

### **超时重传**（核心）

> 在进行TCP传输时，由于存在确认应答与序列号机制，也就是说发送方发送一部分数据后，都会等待接收方发送的ACK报文，并解析ACK报文，判断数据是否传输成功。如果发送方发送完数据后，**迟迟都没有接收到接收方传来的ACK报文，那么就对刚刚发送的数据进行重发**，如果是数据在传输过程中用于网络原因等发生丢包，导致接收方没有接收到，那么接收方第二次收到了数据后就会发送ACK报文给发送方；如果是接收方已经发送了ACK报文，但是ACK报文由于网络原因丢包了，导致发送方没有收到ACK报文，那么此时发送过来的报文已经存在就直接丢弃，仍然发送ACK报文。

### **连接管理**

> 就是三次握手、四次挥手的过程。

### **流量控制**

> 接收端在接收到数据后，对其进行处理。如果发送方的发送速度太快，导致接收方的接收**缓冲区填充满了**。此时如果继续传输数据，就会造成大量丢包，继而引起丢包重传等等一系列问题。因此TCP支持根据接收端的处理能力，来决定发送端的发送速度，这就是流量控制机制。**接收端可以将自己的接收缓冲区大小放入TCP首部的“窗口大小”字段中，通过ACK通知发送端。以此来决定发送端的发送速度。**如果接收缓冲区满了，窗口设置为0，这时发送方将不会再发送数据，但是会定期发送一个窗口探测数据段，使接收端把窗口大小告诉发送端。

### **拥塞控制**

> 所以TCP引入了**慢启动**机制，在开始发送数据的时候，先发少量的数据探探路。探清楚当前的网络状况如何，再决定按照多大的速度传输数据。这里需要引入一个拥塞窗口，发送开始的时候，**拥塞窗口**大小为1，每次接收到一个ACK应答，拥塞窗口加1，每次发送数据包的时候，将拥塞窗口和接收端的主机反馈的窗口大小做比较，取较小的值作为作为实际发送的窗口。
>
> 虽然“慢启动” 初始值很小，但是增长速度非常快，是**指数级别**的。因此在这里引入了一个慢启动阈值，当拥塞窗口超过这个阈值的时候，不再按照指数的方式增长了，而是线性增长。当TCP 开始启动的时候，慢启动的阈值等于窗口的最大值，**在每次超时重发的时候，慢启动阈值会变成原来的一半，同时拥塞窗口会置为1。**

# java

## 同步异步

> **同步和异步**
>
> 强调的是消息通信机制 (synchronous communication/ asynchronous communication)。所谓**同步，就是在发出一个"调用"时，在没有得到结果之前，该“调用”就不返回。但是一旦调用返回，就得到返回值了。**换句话说，就是由“调用者”主动等待这个“调用”的结果。而**异步则是相反，"调用"在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。**而是在"调用"发出后，"被调用者"通过状态、通知来通知调用者，或通过回调函数处理这个调用
>
> - **同步**： 同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。
> - **异步**： 异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。

> **阻塞和非阻塞** 
>
> 强调的是程序在**等待调用结果（消息，返回值）时的状态**. 阻**塞调用是指调用结果返回之前，当前线程会被挂起。**调用线程只有在得到结果之后才会返回。**非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。** 对于同步调用来说，很多时候当前线程还是激活的状态，只是从逻辑上当前函数没有返回而已，即同步等待时什么都不干，白白占用着资源。
>
> - **阻塞**： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。
> - **非阻塞**： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。

## 压缩算法

| **Algorithm** | **% remaining** | **Encoding** | **Decoding** |
| ------------- | --------------- | ------------ | ------------ |
| GZIP          | 13.4%           | 21 MB/s      | 118 MB/s     |
| LZO           | 20.5%           | 135 MB/s     | 410 MB/s     |
| Zippy/Snappy  | 22.2%           | 172 MB/s     | 409 MB/s     |

> 项目中使用压缩算法在cache中，利用snappy进行对于缓存的msg进行压缩，减少占用空间。另外由于相关缓存数据存放在redis中，对于压缩解压缩速度更为看重，所以采用了Snappy算法。

## 自动装箱 拆箱

```java
public class Main {
    public static void main(String[] args) {

        Integer i1 = 100;
        Integer i2 = 100;
        Integer i3 = 200;
        Integer i4 = 200;

        System.out.println(i1==i2);  //true
        System.out.println(i3==i4);  //false
    }
}
```

> 1、i1和i2会进行自动装箱，执行了valueOf函数，它们的值在(-128,128]这个范围内，它们会拿到SMALL_VALUES数组里面的同一个对象SMALL_VALUES[228]，它们引用到了同一个Integer对象，所以它们肯定是相等的。
>
> 2、i3和i4也会进行自动装箱，执行了valueOf函数，它们的值大于128，所以会执行new Integer(200)，也就是说它们会分别创建两个不同的对象，所以它们肯定不等。
>
> ![这里写图片描述](http://img.blog.csdn.net/20150922153039509)

```
 Integer num1 = 100;  
 int num2 = 100;  
 Long num3 = 200l;  
 System.out.println(num1 + num2);  //200
 System.out.println(num3 == (num1 + num2));  //true
 System.out.println(num3.equals(num1 + num2));  //false
```

> 1、当一个基础数据类型与封装类进行==、+、-、*、/运算时，会将封装类进行**拆箱**，对基础数据类型进行运算。 
> 2、对于num3.equals(num1 + num2)为false的原因很简单，我们还是根据代码实现来说明

```
 @Override
 public boolean equals(Object o) {
     return (o instanceof Long) && (((Long) o).value == value);
 }
```

> 它必须满足两个条件才为true： 
> 1、类型相同 
> 2、内容相同 
> 上面返回false的原因就是类型不同。

> **总结**
>
> > **包装类和基本类作比较**
> > **==				true**
> > **equals		 true**
>
> > **包装类和包装类比较**
> > **==					如果在+-128范围内 则是同一对象**
> > **equals			类型相同时内容相同为 true**



## <u>基本数据类型</u>

##### byte

> 8位 1字节
>
> - 最小值是 **-128（-2^7）**；
> - 最大值是 **127（2^7-1）**；
> - 默认值是 **0**；
> - 用于在大型数组中节约空间，代替整数

##### short

> 16位 2字节
>
> - 最小值是 **-32768（-2^15）**；
> - 最大值是 **32767（2^15 - 1）**；
> - 默认值是 **0**；
> - Short 数据类型也可以像 byte 那样节省空间。一个short变量是int型变量所占空间的二分之一；

##### int

> 32位 4字节
>
> - 最小值是 **-2,147,483,648（-2^31）**；
> - 最大值是 **2,147,483,647（2^31 - 1）**；
> - 一般地整型变量默认为 int 类型；
> - 默认值是 **0** ；

##### long

> 64位 8字节
>
> - 最小值是 **-9,223,372,036,854,775,808（-2^63）**；
> - 最大值是 **9,223,372,036,854,775,807（2^63 -1）**；
> - 这种类型主要使用在需要比较大整数的系统上；
> - 默认值是 **0L**；

##### float

> 32位 4字节
>
> - float 在储存大型浮点数组的时候可节省内存空间；
> - 默认值是 **0.0f**；
> - 浮点数不能用来表示精确的值，如货币；

##### double

> 64位 8字节
>
> - 浮点数的默认类型为double类型；
> - double类型同样不能表示精确的值，如货币；
> - 默认值是 **0.0d**；

##### char

> 16位 2字节
>
> - 最小值是 **\u0000**（即为0）；
> - 最大值是 **\uffff**（即为65,535）；
> - char 数据类型可以储存任何字符；

### *如何比较两个double类型大小？*

##### 1两者相减 

> 差和0相比较 如果小于一个非常小的数（允许的精度）那么认为相等

##### 2使用Double包装类

> 使用Double包装类中的equals方法

### *一个char可以存放中文字符吗？*

> 可以 一种中文字符占两个字节 一个char也占两个字节

### 一个英文ASCII字符占一个字节 为什么char占两个字节 会产生浪费吗（自问）

> 不会
>
> 因为在java中，所有的字符都是unicode编码，都占两个字符

## <u>JDK1.8新特性</u>

### 			Lambda表达式

> ​	简化匿名内部类的代码量

### 			函数式接口

> 简单来说就是只定义了一个抽象方法的接口（Object类的public方法除外），就是函数式接口，并且还提供了注解：@FunctionalInterface
>
> 通过提供的四大函数式接口 可以简化lamda，不用手动创建一个新的函数式接口

### 		方法引用和构造器调用

### 		Stream API

### 		接口中的默认方法和静态方法

> 在接口中可以使用default和static关键字来修饰接口中定义的普通方法

```java
public interface Interface {
    default  String getName(){
        return "zhangsan";
    }

    static String getName2(){
        return "zhangsan";
    }
}

```

> 可以避免在1.8中新增的接口方法 需要在1.7中全部添加实现，可以通过默认实现的方式
>
> 当一个类继承父类又实现接口时，若后两者方法名相同，则优先继承父类中的同名方法，即“类优先”，如果实现两个同名方法的接口，则要求实现类必须手动声明默认实现哪个接口中的方法。

### 		新时间日期API

> 新的日期API LocalDate | LocalTime | LocalDateTime
>
> 新的日期API都是不可变的，更使用于多线程的使用环境中
>
> >  * 之前使用的java.util.Date月份从0开始，我们一般会+1使用，很不方便，java.time.LocalDate月份和星期都改成了enum
> >  * java.util.Date和SimpleDateFormat都不是线程安全的，而LocalDate和LocalTime和最基本的String一样，是不变类型，不但线程安全，而且不能修改。
> >  * java.util.Date是一个“万能接口”，它包含日期、时间，还有毫秒数，更加明确需求取舍
> >  * 新接口更好用的原因是考虑到了日期时间的操作，经常发生往前推或往后推几天的情况。用java.util.Date配合Calendar要写好多代码，而且一般的开发人员还不一定能写对。

[新特性]: https://blog.csdn.net/qq_29411737/article/details/80835658





## <u>java中的流</u>

### 	字节流

> ​	以字节为导向的 stream------InputStream/OutputStream

### 	字符流

> ​	以字符为导向的 stream Reader/Writer

### 	流没有释放会导致的问题

> ​	长时间不进行释放会一直占用内存 长时间可能导致OOM



## <u>Tomcat类加载</u>

> https://www.cnblogs.com/aspirant/p/8991830.html



## <u>类加载如何打破双亲委派</u>

> 重写classload方法
>
> 重写findclass方法 实现自定义的类加载方式

## <u>OOM的场景 查询工具</u>

### 场景

> 1堆空间设置不合理 将其设置调大
>
> 2永久代空间太小
>
> 3gc时对象过多，导致内存溢出，可以调整gc的策略，不要占满后再gc
>
> 4本地线程空间溢出 线程栈过大？
>
> 5分配了一个大于堆大小的数组（连续空间）  是否数组过大 或调大堆
>
> 6由于从native堆中分配内存失败，并且堆内存可能接近耗尽
>
> 线程池中等待队列无限制扩张

### 工具

> **jstat**
>
> 可以使用jstat查看程序运行的实时情况，包括堆内存信息和垃圾回收信息，常用来查看程序的垃圾回收情况
>
> > jstat -gc pid
>
> Jprofiler
>
> > 插件 用于看内存是一个内存工具。可以直观的看到各个对象在堆内存中所占空间大小 类实例数量 对象引用关系



## <u>JDK提供的工具</u>



## <u>异常分为两种 有什么不同</u>

#### error

> 是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。

#### exception

> 运行时异常RuntimeException
>
> > 是那些可能在 Java 虚拟机正常运行期间抛出的异常的超类。 如果出现 RuntimeException，那么一定是程序员代码书写导致的错误.
> >
> > 例如：空指针异常 下标越界
>
> 检查异常 CheckedException
>
> > 一般是外部错误，这种异常都发生在编译阶段，Java 编译器会强
> > 制程序去捕获此类异常，即会出现要求你把这段可能出现异常的程序进行 try catch
> >
> > 例如：IOException SQLException

## java集合

### list

> ArrayList
>
> > **优点:** 底层数据结构是数组，查询快，增删慢。
> > **缺点:** 线程不安全，效率高
> > **扩容：**默认大小为0，第一次添加元素后，变为默认值10，后空间不足时，扩充为原有大小的1.5倍，通过移位来处理。
>
> Vector
>
> > **优点:** 底层数据结构是数组，查询快，增删慢。
> > **缺点:** 线程安全，效率低
>
> LinkedList
>
> > **优点:** 底层数据结构是链表，查询慢，增删快。
> > **缺点:** 线程不安全，效率高
> > **扩容：**插入新节点

### set

> HashSet
>
> > 底层数据结构是哈希表。(无序,唯一)
> > 如何来保证元素唯一性?
> > 1.依赖两个方法：hashCode()和equals()
>
> LinkedHashSet
>
> > 底层数据结构是链表和哈希表。(FIFO插入有序,唯一)
> > 1.由链表保证元素有序
> > 2.由哈希表保证元素唯一
>
> TreeSet
>
> > 底层数据结构是红黑树。(唯一，有序)
> > \1. 如何保证元素排序的呢?
> > 自然排序
> > 比较器排序
> > 2.如何保证元素唯一性的呢?
> > 根据比较的返回值是否是0来决定

### map

> Hashtable
>
> > 线程安全 使用了synchronized
>
> LinkedHashMap
>
> > 在hashmap的基础上增加了有序
>
> ConcurrentHashMap
>
> > 1.7中使用分段锁 1.8放弃了分段锁的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，如下图所示，并发控制使用Synchronized和CAS来操作，每一个Node节点都是用volatile修饰的，整个看起来就像是优化过且线程安全的HashMap。
>
> HashMap
>
> > Hashmap是线程不安全的 1.7数组+链表 1.8数组+链表/红黑树  默认初始容量为17 扩容阈值为0.75

## 红黑树

### 定义

> 红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质：
>
> - 性质1：每个节点要么是黑色，要么是红色。
> - 性质2：根节点是黑色。
> - 性质3：每个叶子节点（NIL）是黑色。
> - 性质4：每个红色结点的两个子结点一定都是黑色。
> - **性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。**



## 修饰符

### 	final

> 修饰方法：被final修饰的方法不能够被继承。final修饰方法的一个好处是可以提高运行效率，编译器遇到final方法会转入内嵌机制
>
> 修饰类：final修饰的类是不可以被继承的。比如常见的string类。当给类加上final修饰后，类内的方法加不加final都是不可以被重写的。
>
> 修饰参数：final修饰传入方法的参数时，该参数只读，不可以修改。
>
> 修饰对象：final修饰对象时，不可以再指向其它的对象，但是对象的内容是可以修改的。

### 	static

> static修饰**变量**：
> 对于静态变量在内存中只有一个拷贝（节省内存），JVM只为静态分配一次内存，在加载类的过程中完成静态变量的内存分配，可用类名直接访问（方便）
>
> static修饰**方法**：
> 静态方法可以直接通过类名调用，任何的实例也都可以调用，
> 因此静态方法中不能用this和super关键字，**不能直接访问所属类的实例变量和实例方法**(就是不带static的成员变量和成员成员方法)，**只能访问所属类的静态成员变量和成员方法**。
>
> static**代码块**：
> static代码块也叫静态代码块，是在类中独立于类成员的static语句块，可以有多个，位置可以随便放，它不在任何的方法体内，JVM加载类时会执行这些静态的代码块，如果static代码块有多个，JVM将按照它们在类中出现的先后顺序依次执行它们，每个代码块只会被执行一次。

## java的特性

> 封装 继承 多态

### 	通过什么实现多态

#### 		重载

> 重载(overloading) 是在一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。
>
> 每个重载的方法（或者构造函数）都必须有一个独一无二的参数类型列表。
>
> 最常用的地方就是构造器的重载。

> **重载规则:**
>
> - 被重载的方法**必须改变参数列表**(参数个数或类型不一样)；
> - 被重载的方法可以改变返回类型；
> - 被重载的方法可以改变访问修饰符；
> - 被重载的方法可以声明新的或更广的检查异常；
> - 方法能够在同一个类中或者在一个子类中被重载。
> - **无法以返回值类型作为重载函数的区分标准。**

#### 		重写

> 重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变。**即外壳不变，核心重写！**

> **重载规则:**
>
> - **参数列表**与被重写方法的参数列表必须**完全相同**。
> - 返回类型与被重写方法的**返回类型可以不相同**，但是必须是父类返回值的**派生类**（java5 及更早版本返回类型要一样，java7 及更高版本可以不同）。
> - 访问权限**不能比父类中被重写的方法的访问权限更低**。例如：如果父类的一个方法被声明为 public，那么在子类中重写该方法就不能声明为 protected。
> - 父类的成员方法只能被它的子类重写。
> - 声明为 final 的方法不能被重写。
> - 声明为 static 的方法不能被重写，但是能够被再次声明。
> - 子类和父类在同一个包中，那么子类可以重写父类所有方法，除了声明为 private 和 final 的方法。
> - 子类和父类不在同一个包中，那么子类只能够重写父类的声明为 public 和 protected 的非 final 方法。
> - 重写的方法能够抛出任何非强制异常，无论被重写的方法是否抛出异常。但是，重写的方法不能抛出新的强制性异常，或者比被重写方法声明的更广泛的强制性异常，反之则可以。
> - 构造方法不能被重写。
> - 如果不能继承一个方法，则不能重写这个方法。

## 并发

### concurrentHashMap如何保证线程安全

> put方法中，如果头结点为空，则进行cas将节点值写入
>
> 如果头结点不为空 则通过synchronized对头结点加锁，写入值

# 消息队列

## 市面上的消息队列选型

> **kafka：**
>
> 1、开发语言：   Scala开发
> 2、性能、吞吐量： 吞吐量所有MQ里最优秀，QPS十万级、性能毫秒级、支持集群部署
> 3、功能：     功能单一
> 4、缺点：     丢数据， 因为数据先写入磁盘缓冲区，未直接落盘。机器故障会造成数据丢失
> 5、应用场景：   适当丢失数据没有关系、吞吐量要求高、不需要太多的高级功能的场景，比如大数据场景。
>
> **RabbitMQ：**
>
> 1、开发语言：   Erlang开发
> 2、性能、吞吐量： 吞吐量比较低，QPS几万级、性能u秒级、主从架构
> 3、功能：功能单一
> 4、缺点：Erlang小众语言开发，吞吐量低，集群扩展麻烦
> 5、应用场景：中小公司对并发和吞吐量要求不高的场景。
>
> **RocketMQ：**
>
> 1、开发语言：   java开发
> 2、性能、吞吐量： 吞吐量高，QPS十万级、性能毫秒级、支持集群部署
> 3、功能：     支持各种高级功能，比如说**延迟消息、事务消息、消息回溯、死信队列、消息积压**等等
> 4、缺点：     官方文档相对简单可能是RocketMQ目前唯一的缺点
> 5、应用场景：   适当丢失数据没有关系、吞吐量要求高、不需要太多的高级功能的场景，比如大数据场景。





# Redis

## <u>Redis为什么快</u>

> 纯内存操作
>
> 单线程操作，减少了频繁的上下文切换
>
> 采用了非阻塞IO多路复用机制

## <u>什么是多路复用机制</u>

> 小名在 A 城开了一家快餐店店，负责同城快餐服务。小明因为资金限制，雇佣了一批配送员，然后小曲发现资金不够了，只够买一辆车送快递。
>
> 小明只雇佣一个配送员。当客户下单，小明按送达地点标注好，依次放在一个地方。最后，让配送员依次开着车去送，送好了就回来拿下一个。
>
> - 每个配送员→每个线程
> - 每个订单→每个 Socket(I/O 流)
> - 订单的送达地点→Socket 的不同状态
> - 客户送餐请求→来自客户端的请求
> - 明曲的经营方式→服务端运行的代码
> - 一辆车→CPU 的核数
>
> 只有单个线程(一个配送员)，通过跟踪每个 I/O 流的状态(每个配送员的送达地点)，来管理多个 I/O 流。
>
> Redis-client 在操作的时候，会产生具有不同事件类型的 Socket。在服务端，有一段 I/O 多路复用程序，将其置入**队列**之中。然后，**文件事件分派器**，**依次去队列中取**，转发到不同的事件处理器中。

## <u>Redis和Memcached的区别</u>

两者相同点 

> 两者都是基于内存的数据存储系统
>
> 本质上都是一个内存的key-value存储系统

两者的不同点

##### 1数据操作不同

> Memcached仅支持key-value的数据结构 不支持枚举，不支持持久化和复制
>
> Redis支持的数据结构更加丰富 支持list set zset hash string 并且通过了持久化和复制的功能

##### 2内存管理机制的不同

> Redis中，并不是所有的数据都一直存储在内存中，可以通过lru的机制，将一些很久没用的value交换到磁盘，并且在内存中进行删除
>
> Memcached默认使用Slab Allocation机制管理内存 思想是按照预先规定的大小，将分配的内存分割成特定长度的块以存储相应长度的key-value数据记录，以完全解决内存碎片问题。

##### 3性能不同

> Redis只能使用单核 平均每一个核上Redis在存储小数据时性能更高
>
> Memcached可以使用多核 存储100k以上的数据 性能更好

##### 4集群管理不同

> Memcached是全内存的数据缓冲系统，Redis虽然支持数据的持久化，但是全内存毕竟才是其高性能的本质。作为基于内存的存储系统来说，机器物理内存的大小就是系统能够容纳的最大数据量。如果需要处理的数据量超过了单台机器的物理内存大小，就需要构建分布式集群来扩展存储能力。
>
> Memcached本身不支持分布式，只能通过在客户端通过一致性hash的方式实现分布式存储。
>
> Redis则偏向于在服务端构建分布式存储。



## <u>为什么要使用Redis</u>

#### 性能问题

> 对于一些执行耗时很久，结果不频繁变动的SQL，适合将运行结果放入缓存，以减少对于MySQL的访问
>
> **例如 一些静态不会进行变更的一些数据 在秒杀时可以将其放在redis**

#### 并发问题

> 高并发的情况下，所有的请求直接访问数据库会极容易出现问题，所以需要用redis做一个缓冲操作
>
> **例如 redis实现的消息队列的形式**



## <u>Redis的问题以及解决方案</u>

#### *缓存和数据库双写一致性问题*

> 涉及双写问题就很难保证强一致性，只能保证最终一致性
>
> 读：先读缓存 命中直接返回 未命中读取数据库 并将结果写入缓存
> 写：先修改数据库，再将缓存删除
>
> 存在的问题：有可能删除缓存失败 有可能缓存正好失效的同时 有读取任务，写任务修改删除了缓存后，读任务将脏数据写入缓存
>
> 问题的解决方案：删除缓存时加一个消息队列  将删除失败的缓存进行删除

#### 	*缓存雪崩问题*

> 缓存雪崩，是指在某一个时间段，缓存集中过期失效。
>
> ​	解决方案：将设置时间时加入随机量

#### 	*缓存击穿问题*

> 是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。
>
> ​	让缓存永不过期

#### 	*缓存穿透*

> 是指查询一个数据库一定不存在的数据。正常的使用缓存流程大致是，数据查询先进行缓存查询，如果key不存在或者key已经过期，再对数据库进行查询，并把查询到的对象，放进缓存。如果数据库查询对象为空，则不放进缓存。
>
> ​	**互斥锁**
>
> ​		缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。
>
> ​	**布隆过滤器**
>
> ​	**缓存空对象**
>
> ​		即使结果为空也将其缓存下来，设置一个较短的过期时间

#### *缓存的并发竞争问题*

#### 

## <u>分布式锁一定要用Redis吗 分布式锁的实现</u>

#### *数据库乐观锁*

#### *基于Redis的分布式锁*

#### *基于ZooKeeper的分布式锁*



## <u>Redis的淘汰策略</u>

> redis使用的是定期删除+惰性删除的形式
>
> 为什么不适用定时删除
>
> ​	因为占用cpu资源
>
> 如何工作
>
> ​	定期删除，Redis 默认每个 100ms 检查，有过期 Key 则删除。需要说明的是，Redis 不是每个 100ms 将所有的 Key 检查一次，而是随机抽取进行检查。如果只采用定期删除策略，会导致很多 Key 到时间没有删除。于是，惰性删除派上用场。

- noeviction：当**内存不足**以容纳新写入数据时，新写入操作**会报错**。
- allkeys-lru：当**内存不足**以容纳新写入数据时，在键空间中，**移除最近最少使用的 Key**。（推荐使用，目前项目在用这种）(最近最久使用算法)
- allkeys-random：当**内存不足**以容纳新写入数据时，在键空间中，**随机移除某个 Key**。（应该也没人用吧，你不删最少使用 Key，去随机删）
- volatile-lru：当**内存不足**以容纳新写入数据时，在**设置了过期时间的键空间中，移除最近最少使用的 Key**。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。（不推荐）
- volatile-random：当**内存不足**以容纳新写入数据时，在**设置了过期时间的键空间中，随机移除某个 Key**。（依然不推荐）
- volatile-ttl：当**内存不足**以容纳新写入数据时，在设置了过期时间的键空间中，**有更早过期时间的 Key 优先移除**。（不推荐）

## <u>Redis内部的数据结构(使用场景)以及底层实现</u>

#### string

> ​	动态字符串 记录长度  空闲数量 以及用数组来保存字符串	

#### map

> ​	数组+链表 进行rehash的优化 存储两个数组结构 进行部分的扩容，当完全结束后再释放空间

#### 链表

> 双向链表的基础上 拓展了头尾节点 记录元素个数

#### 集合Set

> 

#### 有序集合ZSet

> ​	跳表（其本质和平衡树类似 但是相比而言 对于插入的调整较少 并且范围查询更方便）

[知乎解答]: https://zhuanlan.zhihu.com/p/50392209

## redis实现分布式锁

> key 使用 特定分布式锁前缀+当前用户pin
> value使用 （ip：port，过期时间）
>
> 加锁时：先用setNx进行加锁 如果没有设置成功 则获取原有的value 判断是否已经过期（当前时间和value中的过期时间相比） 如果过期用getset进行写入 判断是否已经成功写入自己的时间 如果是则加锁成功 否则加锁失败







# Spring原理层面笔记

## 自动装配

### 原理

> 1当spring容器启动的时候会去调用ConfigurationClassPostProcessor这个bean工厂的后置处理器完成扫描，其实所谓的spring扫描就是把类的信息读取到，但是读取到类的信息存放到哪里呢？spring设计了一个BeanDefintion的类用来存储这些信息。
>
> 2故而当spring读取到类的信息之后`②`[2]会实例化一个BeanDefinition的对象，继而调用这个对象的各种set方法存储信息；每扫描到一个符合规则的类，spring都会实例化一个BeanDefinition对象，然后把根据类的类名生成一个bean的名字
>
> 3继而spring会把这个beanDefinition对象和生成的beanName放到一个map当中，key=beanName，value=beanDefinition对象；
>
> 4 可能会执行程序员提供的 BeanFactoryPostProcessor
>
> 5 进行实例化

### 自动装配的两种方式

#### byName 

> 通过bean的id和set方法中的后缀匹配进行自动装配
>
> 例如：setAddress方法 能匹配bean配置文件中id为address的bean

#### byType

> 根据bean的类型
>
> 但是如果IOC容器中有一个以上的类型匹配则会报异常

### 自动装配缺点

> 所有属性都要自动装配 不够灵活、
>
> byType和byName不能混用



## bean的关系

### bean的继承

> 使用parent属性指定继承哪个bean
>
> 父类bean可以设置为abstract类似于抽象类使得其作为模板不可以被实例化
>
> 若某一个bean的class属性没有指定，则该bean一定是一个抽象bean

### bean的依赖关系

> depends-on 表示bean之间的依赖



## bean的作用域 scope

### 单例的singleton

> 在整个声明周期内只创建这一个bean

### 原型的prototype

> 容器创建时，不创建bean的实例，每次请求时创建一个新的Bean

### Session

### Request



## SpEL动态进行赋值

> 通过#{}的形式可以进行对属性赋值 包括别的bean 字面值 别的bean的属性值 方法返回值



## IOC容器中的Bean的生命周期

> 通过构造器或工厂方法创建Bean实例				**构造方法**
>
> 为Bean的属性设置 值和其他Bean的引用			**set方法**
>
> 调用bean后置处理器的前置方法 				**postBeforeInitialization方法**     
>
> ​																		参数一 Object bean 参数二 String beanName
>
> 调用Bean的初始化方法（指定init-method）	**指定的init方法**
>
> 调用bean后置处理器的后置方法 				**postAfterInitialization方法**     实现BeanPostProcessor接口
>
> Bean投入使用 
>
> 容器关闭时 调用Bean的销毁方法（指定destroy-method）		**指定的destroy方法**



## Bean的配置

### 反射 通过全类名

### 工厂方法

#### 	静态工厂

> 直接调用某个类的静态方法就可以返回Bean的实例
>
> 不用创建工厂实例 通过静态方法获取bean实例
>
> ```java
> public class StaticCarFactory{
> 	private static Map<String,Car> cars=new HashMap<String,Car>();
>  static{
>      cars.put("audi", new Car("audi",300));
>  }
>  public static Car getCar(String name){
>      return cars.get(name);
>  }
> }
> ```
>
> 在配置bean时只需要配置bean 尤其是其中的class为静态工厂方法 

#### 	实例工厂

> 通过创建工厂实例来进行生成Bean实例 
>
> 在配置时需要先配置工厂的bean 其中factory-bean为实例工厂

#### 通过FactoryBean

> 自定一的FactoryBean需要实现FactoryBean<>接口
>
> 通过类代码实现FactotyBean
>
> xml配置文件中bean的class指定为对应的FactoryBean的全类名



### 基于注解配置bean

#### 配置简单bean

> ##### 组件扫描
>
> Spring能够从classpath下自动扫描，侦测和实例化具有特定注解的组件 包括：
>
> @Component		 基本注解 标识了一个受Spring管理的组件
>
> @Respository		 标识持久层组件
>
> @Service				 标识服务层 业务层组件
>
> @Controller			标识表现层组件
>
> 使用组件后，还要在配置中声明 context:component-scan 指定IOC容器扫描的包
>
> resource-pattern  仅希望扫描特定的类而非基包下面的所有类
>
> include-filter   	   子节点标识要包含的目标类
>
> exclude-filter		  子节点表示要排除在外的目标类
>
> ​		其中存在五种方式进行指定 通过注解类型 通过bean名字

#### bean的关联关系的导入

> \<context:component-scan>元素自动注册AutowiredAnnotationBeanPostProcessor实例，可以指定装配具有@Autowired 和 @Resource @Inject注解的属性
>
> autowired可以自动装配类型兼容的bean
>
> 如果多个类型兼容 则需要通过名字进行装配（通过@Qualifier进行名字的设定）



### 泛型依赖注入

> 建立了依赖的两个父类，其子类也会建立依赖关系
>
> <img src="C:\Users\11346\AppData\Roaming\Typora\typora-user-images\image-20200421233205346.png" alt="image-20200421233205346" style="zoom:67%;" />



## AOP面向切面编程

### 为什么需要AOP

> 例如 有一个接口定义四则运算的操作，而一个类对他进行实现
>
> 现在有两个需求：1在每个运算前 输出日志 2进行数值的整型判断
>
> 如果不是用AOP技术，则需要每个方法前后都进行print。其中日志的输出方法是重复的，维护麻烦
>
> **问题1**代码混乱 原有的业务方法急剧膨胀 每个方法在处理核心逻辑时需要兼顾多个其他关注点
>
> **问题2**代码分散，多个模块重复实现重复代码，如果需求变更，需要改变多个模块的实现

### 动态代理实现AOP

> #### 代理模式
>
> 代理类和被代理类实现共同的接口（或继承），代理类中存有指向被代理类的索引，实际执行时通过调用代理类的方法、实际执行的是被代理类的方法。
>
> #### 静态代理
>
> 由程序员创建或特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了。
>
> ```java
> public class BirdLogProxy implements Flyable {
>  private Flyable flyable;
> 
>  public BirdLogProxy(Flyable flyable) {
>      this.flyable = flyable;
>  }
> 
>  @Override
>  public void fly() {
>      System.out.println("Bird fly start...");
> 
>      flyable.fly();
> 
>      System.out.println("Bird fly end...");
>  }
> }
> ```
>
> ```java
>  public static void main(String[] args) {
>      Bird bird = new Bird();
>      BirdLogProxy p1 = new BirdLogProxy(bird);
>      BirdTimeProxy p2 = new BirdTimeProxy(p1);
> 
>      p2.fly();
>  }
> 
> ```
>
> 这就时一个代理类，通过与被代理的类实现相同接口的形式，加上聚合的形式，将需要代理的对象作为参数传入，将原有方法进行增强。但是作为静态方法，面对大量需要被代理的方法，需要同样多的静态代理类。所以需要一个代理类来代理任意对象。
>
> #### 动态代理
>
> 程序运行时，运用反射机制动态创建而成，动态代理类的字节码在程序运行时由Java反射机制动态生成，无需程序员手工编写它的源代码。
>
> ##### 动态代理的两种实现方式
>
> ##### **JDK代理**
>
> JDK动态代理主要涉及java.lang.reflect包下的Proxy类和InvocationHandler接口。 JDK代理实现的三个要点：
>
> **通过java.lang.reflect.Proxy类来动态生成代理类；**
> **代理类要实现InvocationHandler接口；**
> **JDK代理只能基于接口进行动态代理；**
>
> 每一个动态代理类都必须要实现InvocationHandler这个接口，并且每个代理类实例都关联到了一个handler，当我们通过代理对象调用一个方法的时候，这个方法的调用就会被转发为由InvocationHandler这个接口的 invoke 方法来进行调用。
>
> ```java
> Object invoke(Object proxy, Method method, Object[] args) throws Throwable
> proxy:　　 指代我们所代理的那个真实对象
> method:　　指代的是我们所要调用真实对象的某个方法的Method对象
> args:　　  指代的是调用真实对象某个方法时使用的参数
> ```
>
> Proxy这个类的作用就是用来动态创建一个代理对象的类，它提供了许多的方法，但是我们用的最多的就是 newProxyInstance 这个方法，这个方法的作用就是得到一个动态的代理对象，其接收三个参数，我们来看看这三个参数所代表的含义。
>
> ```java
> public static Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h) throws IllegalArgumentException
> loader:　　    一个ClassLoader对象，定义了由哪个ClassLoader对象来对生成的代理对象进行加载
> interfaces:　　一个Interface对象的数组，表示的是我将要给我需要代理的对象提供一组什么接口，如果我提供了一组接口给它，这样我就能调用这组接口中的方法了
> h:　　         一个InvocationHandler对象，表示的是当我这个动态代理对象在调用方法的时候，会关联到哪一个InvocationHandler对象上
> ```
>
> 

### AOP术语

> 切面：横切关注点（跨越应用程序多个模块的功能）被模块化的特殊对象
>
> 通知：且面必须完成的工作（参数验证 日志每一个方法就是一个通知）
>
> 目标：被通知的对象（原本的加减乘除方法）
>
> 代理：向目标对象应用统治之后创建的对象
>
> 连接点：程序执行的某个特定位置 是一个真实存在的物理位置（例如加法执行之前 减法执行之后的位置 **某某某方法执行前/后/抛出异常时**）
>
> 切点：AOP通过切点定位到特殊的连接点

<img src="C:\Users\11346\AppData\Roaming\Typora\typora-user-images\image-20200422004426090.png" alt="image-20200422004426090" style="zoom:67%;" />



### 使用AOP

#### AspectJ注解的形式

> ​		需要把切面的类声明为一个切面
>
> ​		将改类放入到IIOC容器中@Component 再声明为一个切面@Aspect
>
> ​		在切面的方法前面加入@Before（前置通知）声明在哪些类的哪些方法前进行执行
>
> ​		在配置文件中设置 使AspectJ起作用
>
> ​		可以在通知方法中加一个类型为JointPoint的参数，就能访问到连接细节，如方和和参数值

#### 通知的类型

> ​	前置通知：在方法开始前执行 @Before （在动态代理的invoke方法前执行）
>
> ​	后置通知：在目标方法后（无论是否发生异常）执行的通知。在后置通知中还不能访问目标方法执行的结果  @After（在动态代理的invoke方法后 catch之外执行）
>
> ​	返回通知：在方法正常结束后执行的代码 是可以访问到方法返回值的@AfterReturning
>
> ​	异常通知：可以访问到方法运行时的异常 @AfterThrowing（在invoke的catch代码块中）
>
> ​	环绕通知：需要携带ProceedingJoinPoint参数 类似动态代理的全过程。方法的形式类似于实现动态代理。process方法代替了invoke





# SpringBoot

## 为什么要使用springboot

> 1、快速整合第三方框架，比如redis，mybatis等等
>
> 2、全部采用注解方式，没有繁琐的xml配置。
>
> 3、内置http服务器，比如jetty，tomcat。不需要额外的去集成下载tomcat。

## <u>SpringBoot在Controller中的常用注解</u>

> #### @RestController
>
> ​	等于@Controller + @ReponseBody
>
> ​	使用@RestController返回的是return里面的字符串 json



> @GetMapping
>
> ​	是@RequestMapping(method=RequestMethod.GET)缩写
>
> @PostMapping	对应post请求
>
> @PutMapping		对应put请求
>
> @DeleteMapping 对应delete请求



## <u>动态代理的两种实现区别</u>

### 	原生JDK

> ​	通过java的反射机制
>
> ​	生成类的过程中比较高效
>
> ​	目标类必须基于统一的接口
>
> ​	就是通过让target类和代理类实现同一接口，代理类持有target对象，来达到方法拦截的作用，这样通过接口的方式有两个弊端，一个是必须保证target类有接口，第二个是如果想要对target类的方法进行代理拦截，那么就要保证这些方法都要在接口中声明，实现上略微有点限制。

### 	CGLIB

> ​	通过asm来实现
>
> ​	生成类后的相关执行过程比较高效
>
> ​	它的底层使用ASM在内存中动态的生成被代理类的子类，使用CGLIB即使代理类没有实现任何接口也可以实现动态代理功能。CGLIB具有简单易用，它的运行速度要远远快于JDK的Proxy动态代理：
>
> cglib有两种可选方式，继承和引用。第一种是基于继承实现的动态代理，所以可以直接通过super调用target方法，但是这种方式在spring中是不支持的，因为这样的话，这个target对象就不能被spring所管理，所以cglib还是才用类似jdk的方式，通过持有target对象来达到拦截方法的效果。

## <u>Spring和SpringMVC的理解</u>

### 	MVC概述

> ​	在早期 Java Web 的开发中，统一把显示层、控制层、数据层的操作全部交给 JSP 或者 JavaBean 来进行处理，我们称之为 **Model1：**
>
> ![img](https://upload-images.jianshu.io/upload_images/7896890-7b3f9cd59394b017.png?imageMogr2/auto-orient/strip|imageView2/2/w/963/format/webp)**出现的弊端：**
>
> JSP 和 Java Bean 之间严重耦合，Java 代码和 HTML 代码也耦合在了一起
>
> 要求开发者不仅要掌握 Java ，还要有高超的前端水平
>
> 前端和后端相互依赖，前端需要等待后端完成，后端也依赖前端完成，才能进行有效的测试
>
> 代码难以复用
>
> 
>
> 正因为上面的种种弊端，所以很快这种方式就被 Servlet + JSP + Java Bean 所替代了，早期的 MVC 模型**（Model2）**就像下图这样：
>
> ![img](https://upload-images.jianshu.io/upload_images/7896890-403a273b08fec826.png?imageMogr2/auto-orient/strip|imageView2/2/w/985/format/webp)
>
> 首先用户的请求会到达 Servlet，然后根据请求调用相应的 Java Bean，并把所有的显示结果交给 JSP 去完成，这样的模式我们就称为 MVC 模式。
>
> **M 代表 模型（Model）**
> 模型是什么呢？ 模型就是数据，就是 dao,bean
>
> **V 代表 视图（View）**
> 视图是什么呢？ 就是网页, JSP，用来展示模型中的数据
>
> **C 代表 控制器（controller)**
> 控制器是什么？ 控制器的作用就是把不同的数据(Model)，显示在不同的视图(View)上，Servlet 扮演的就是这样的角色。

### 	SpringMVC

> ![img](https://upload-images.jianshu.io/upload_images/7896890-a25782fb05f315de.png?imageMogr2/auto-orient/strip|imageView2/2/w/1176/format/webp)
>
> **传统的模型层被拆分为了业务层(Service)和数据访问层（DAO,Data Access Object）。** 在 Service 下可以通过 Spring 的声明式事务操作数据访问层，而在业务层上还允许我们访问 NoSQL ，这样就能够满足异军突起的 NoSQL 的使用了，它可以大大提高互联网系统的性能。
>
> **特点：**
> 结构松散，几乎可以在 Spring MVC 中使用各类视图
> 松耦合，各个模块分离
> 与 Spring 无缝集成

### 	springMVC的请求过程

> ![img](https://upload-images.jianshu.io/upload_images/7896890-65ef874ad7da59a2.png?imageMogr2/auto-orient/strip|imageView2/2/w/784/format/webp)
>
> 第一站到达的就是 **DispatcherServlet**，DispatcherServlet 会拦截所有的请求，并且将这些请求发送给 Spring MVC 控制器。
>
> **DispatcherServlet 的任务就是拦截请求发送给 Spring MVC 控制器。**
>
> 第二站**处理器映射（HandlerMapping）** DispatcherServlet 会查询一个或多个处理器映射来确定请求的下一站在哪里，处理器映射会**根据请求所携带的 URL 信息来进行决策**
>
> 第三站**控制器**一旦选择了合适的控制器， DispatcherServlet 会将请求发送给选中的控制器，到了控制器，请求会卸下其负载（用户提交的请求）等待控制器处理完这些信息
>
> 第四站 **返回 DispatcherServlet**当控制器在完成逻辑处理后，通常会产生一些信息，这些信息就是需要返回给用户并在浏览器上显示的信息，它们被称为**模型（Model）**仅仅返回原始的信息时不够的——这些信息需要以用户友好的方式进行格式化，一般会是 HTML，所以，信息需要发送给一个**视图（view）**，通常会是 JSP。控制器所做的最后一件事就是将模型数据打包，并且表示出用于渲染输出的视图名**（逻辑视图名）。它接下来会将请求连同模型和视图名发送回 DispatcherServlet。**
>
> 第五站**控制器** 这样就不会和特定的视图相耦合，传递给 DispatcherServlet 的视图名并不直接表示某个特定的 JSP。（实际上，它甚至不能确定视图就是 JSP）相反，**它传递的仅仅是一个逻辑名称，这个名称将会用来查找产生结果的真正视图。**DispatcherServlet 将会使用视图解析器（view resolver）来将逻辑视图名匹配为一个特定的视图实现，它可能是也可能不是 JSP
>
> 第六站**视图** 既然 DispatcherServlet 已经知道由哪个视图渲染结果了，那请求的任务基本上也就完成了。它的最后一站是视图的实现，在这里它交付模型数据，请求的任务也就完成了。视图使用模型数据渲染出结果，这个输出结果会通过响应对象传递给客户端。



## <u>@Transactional的理解</u>

> @Transactional不仅可以注解在方法上，也可以注解在类上。
>
> 当注解在类上的时候意味着此类的所有public方法都是开启事务的。
>
> 如果类级别和方法级别同时使用了@Transactional注解，则使用在类级别的注解会重载方法级别的注解



## <u>隔离级别</u>

> DEFAULT ：这是默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是： READ_COMMITTED 。
> READ_UNCOMMITTED ：该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读和不可重复读，因此很少使用该隔离级别。
> READ_COMMITTED ：该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。
> REPEATABLE_READ ：该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。即使在多次查询之间有新增的数据满足该查询，这些新增的记录也会被忽略。该级别可以防止脏读和不可重复读。
> SERIALIZABLE ：所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

> 指定方法：通过使用 isolation 属性设置，例如：
> @Transactional(isolation = Isolation.DEFAULT)

## <u>事务传播级别</u>

> **REQUIRED** ：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。**默认的spring事务传播级别**
>
> 如果上下文中已经存在事务，那么就加入到事务中执行，如果当前上下文中不存在事务，则新建事务执行。所以这个级别通常能满足处理大多数的业务场景。
>
> **SUPPORTS** ：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。
>
> **MANDATORY** ：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。配置该方式的传播级别是有效的控制上下文调用代码遗漏添加事务控制的保证手段。
>
> 比如一段代码不能单独被调用执行，但是一旦被调用，就必须有事务包含的情况，就可以使用这个传播级别。
>
> **REQUIRES_NEW** ：创建一个新的事务，如果当前存在事务，则把当前事务挂起。
>
> 举一个应用场景：现在有一个发送100个红包的操作，在发送之前，要做一些系统的初始化、验证、数据记录操作，然后发送100封红包，然后再记录发送日志，发送日志要求100%的准确，如果日志不准确，那么整个父事务逻辑需要回滚。
> 怎么处理整个业务需求呢？就是通过这个PROPAGATION_REQUIRES_NEW 级别的事务传播控制就可以完成。发送红包的子事务不会直接影响到父事务的提交和回滚。
>
> **NOT_SUPPORTED** ：以非事务方式运行，如果当前存在事务，则把当前事务挂起。
>
> 可以帮助你将事务极可能的缩小。我们知道一个事务越大，它存在的风险也就越多。所以在处理事务的过程中，要保证尽可能的缩小范围。比如一段代码，是每次逻辑操作都必须调用的，比如循环1000次的某个非核心业务逻辑操作。这样的代码如果包在事务中，势必造成事务太大，导致出现一些难以考虑周全的异常情况。所以这个事务这个级别的传播级别就派上用场了。用当前级别的事务模板抱起来就可以了。
>
> **NEVER** ：以非事务方式运行，如果当前存在事务，则抛出异常。
>
> **NESTED** ：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于 REQUIRED 。



## <u>什么是Restful API</u>

> 本质上是一种设计规范，应用于前后端分离的项目中，用于规范API设计

![](https://upload-images.jianshu.io/upload_images/14699036-a4b9031041a5194c.png?imageMogr2/auto-orient/strip|imageView2/2/w/756/format/webp)

### 	设计原则

> 客户端-服务器：通过将用户UI与数据存储分开，我们可以简化服务器组件来提高跨多个平台的用户界面的可移植性并提高可伸缩性。 它可以比表现成前后端分离的思想。
>
> 无状态：从客户端到服务器的每个请求都必须包含理解请求所需的所有信息，并且不能利用服务器上任何存储的上下文。 这表示你应该尽可能的避免使用session，由客户端自己标识会话状态。（token）
>
> 规范接口：REST接口约束定义：资源识别; 请求动作; 响应信息; 它表示通过uri标出你要操作的`资源`，通过请求动作（http method）标识要执行的操作，通过返回的状态码来表示这次请求的执行结果。
>
> 可缓存： 缓存约束要求将对请求的响应中的数据隐式或显式标记为可缓存或不可缓存。如果响应是可缓存的，则客户端缓存有权重用该响应数据以用于以后的等效请求。 它表示get请求响应头中应该表示有是否可缓存的头（Cache-Control)

### 请求动作

> get	查询操作
>
> post  新增动作
>
> put	更新操作
>
> patch部分更新
>
> delete删除操作

### 	无状态

> 无状态通过将API部署到多个服务器，有助于将API扩展到数百万并发用户。任何服务器都可以处理任何请求，因为没有与会话相关的依赖。（集群）
>
> 无状态使得REST API不那么复杂 - 可以删除所有服务器端状态同步逻辑。（删除session，清理多余空间）
>
> 无状态API也很容易缓存。特定软件可以通过查看该一个请求来决定是否缓存HTTP请求的结果。从先前的请求中获得的状态可能会影响这个请求的可缓存性，这并不存在任何不确定性。它提高了应用程序的性能。
>
> 服务器永远不会忘记每个客户端身份”，因为客户端会在每个请求中发送所有必要的信息。（携带token）





## 单例模式和spring的单例有什么区别



## <u>如何优化减库存操作</u>

初始方法

```
query();
@transactional
set quantity=quantity-1
```

问题：在第一次进行查询时，如果不加事务的标记，则会导致超卖问题。如果加上了事务标记，则会影响并发

解决方案：不要进行query查询库存，直接用一次sql来处理，在一次sql中执行以下操作

```mysql
update set quantity=quantity-1
where good_id=1 and quantity>0
```

## <u>做登陆时有什么其他办法做用户的参数解析</u>

> 1用目前采用的方法。在请求发送到controller之前，用参数解析器，进行参数的解析。以用户信息实体的形式，传入controller
>
> 2threadlocal的形式来存放用户的相关信息。直接使用线程上下文的形式



## springboot 和 springmvc的区别



## 如何处理异常

### 全局异常 @ControllerAdvice @ExceptionHandler

> 可以通过@ControllerAdvice注解的方式 定义一个全局异常处理类
>
> 其中通过@ExceptionHandler注解可以设置处理的异常类类型

### 局部异常

> @ExceptionHandler注解修饰方法 但是会跳转刀统一的error页面

## 拦截器

### HandlerInterceptor

#### 	**简介**

>  SpringWebMVC的处理器拦截器，类似于Servlet开发中的过滤器Filter，用于处理器进行预处理和后处理。

#### 	**应用场景**

>  1、日志记录，可以记录请求信息的日志，以便进行信息监控、信息统计等。
>  2、权限检查：如登陆检测，进入处理器检测是否登陆，如果没有直接返回到登陆页面。
>  3、性能监控：典型的是慢日志。

```java
public interface HandlerInterceptor {

   /**
     * 预处理回调方法，实现处理器的预处理（如检查登陆），第三个参数为响应的处理器，自定义Controller
     * 返回值：true表示继续流程（如调用下一个拦截器或处理器）；false表示流程中断（如登录检查失败），不会继续调用其他的拦截器或处理器，此时我们需要通过response来产生响应；
   */
    boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)
            throws Exception;

   /**
     * 后处理回调方法，实现处理器的后处理（但在渲染视图之前），此时我们可以通过modelAndView（模型和视图对象）对模型数据进行处理或对视图进行处理，modelAndView也可能为null。
   */
    void postHandle(
            HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)
            throws Exception;

   /**
    * 整个请求处理完毕回调方法，即在视图渲染完毕时回调，如性能监控中我们可以在此记录结束时间并输出消耗时间，还可以进行一些资源清理，类似于try-catch-finally中的finally，但仅调用处理器执行链中
   */
    void afterCompletion(
            HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)
            throws Exception;

}
```

### **拦截器适配器HandlerInterceptorAdapter**

> 有时候我们可能只需要实现三个回调方法中的某一个，如果实现HandlerInterceptor接口的话，三个方法必须实现，不管你需不需要，此时spring提供了一个HandlerInterceptorAdapter适配器（种适配器设计模式的实现），允许我们只实现需要的回调方法。

```java
public abstract class HandlerInterceptorAdapter implements AsyncHandlerInterceptor {

    /**
     * 默认是true
     */
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)
            throws Exception {

        return true;
    }

    /**
     * This implementation is empty.
     */
    @Override
    public void postHandle(
            HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)
            throws Exception {
    }

    /**
     * This implementation is empty.
     */
    @Override
    public void afterCompletion(
            HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)
            throws Exception {
    }

    /**
     * 不是HandlerInterceptor的接口实现，是AsyncHandlerInterceptor的，AsyncHandlerInterceptor实现了HandlerInterceptor
     */
    @Override
    public void afterConcurrentHandlingStarted(
            HttpServletRequest request, HttpServletResponse response, Object handler)
            throws Exception {
    }

}
```

### 多拦截器执行顺序问题

![](https://upload-images.jianshu.io/upload_images/4582242-da4b3cb8777704d3.png?imageMogr2/auto-orient/strip|imageView2/2/w/679/format/webp)

> **1、拦截器执行顺序是按照Spring配置文件中定义的顺序而定的。**
>
> **2、会先按照顺序执行所有拦截器的preHandle方法，一直遇到return false为止，比如第二个preHandle方法是return false，则第三个以及以后所有拦截器都不会执行。若都是return true，则按顺序加载完preHandle方法。**
>
> **3、然后执行主方法（自己的controller接口），若中间抛出异常，则跟return false效果一致，不会继续执行postHandle，只会倒序执行afterCompletion方法。**
>
> **4、在主方法执行完业务逻辑（页面还未渲染数据）时，按倒序执行postHandle方法。若第三个拦截器的preHandle方法return false，则会执行第二个和第一个的postHandle方法和afterCompletion（postHandle都执行完才会执行这个，也就是页面渲染完数据后，执行after进行清理工作）方法。（postHandle和afterCompletion都是倒序执行）**





# 分布式相关

## [Zookeeper](https://www.cnblogs.com/takumicx/p/9508706.html)

> 主要作用是为分布式系统提供协调服务,包括但不限于:分布式锁,统一命名服务,配置管理,负载均衡,主控服务器选举以及主从切换等。

> Zookeeper自身通常也以分布式形式存在。一个Zookeeper服务通常由多台服务器节点构成,只要其中超过一半的节点存活,Zookeeper即可正常对外提供服务,所以Zookeeper也暗含高可用的特性。客户端可以通过TCP协议连接至任意一个服务端节点请求Zookeeper集群提供服务,而集群内部如何通信以及如何保持分布式数据一致性等细节对客户端透明。

![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180820225811262-1254286440.png)

> 对于多读场景QPS很高。

### zookeeper的地位

> **我们需要一个用起来像单机但是又比单机更可靠的东西。**zookeeper起着一个协调的作用

> 比如我们搭建了一个数据库集群，里面有一个Master，多个Slave，Master负责写，Slave只读，我们需要一个系统，来告诉客户端，哪个是Master。
>
> 有人说，很简单，我们把这个信息写到一个Java服务器的内存就好了，用一个map，key:master，value:master机器对应的ip
>
> ![](https://pic1.zhimg.com/80/v2-0095c9a6e471cd92e80cd77a9909eba6_720w.jpg)
>
> 但是别忘了，这是个单机，一旦这个机器挂了，就完蛋了，客户端将无法知道到底哪个是Master。
>
> 于是开始进行拓展，拓展成三台服务器的集群。
>
> ![](https://pic2.zhimg.com/80/v2-ddfe9dbf5ae13ca335e804ae5124181c_720w.jpg)
>
> 这下问题来了，如果我在其中一台机器修改了Master的ip，数据还没同步到其他两台，这时候客户端过来查询，如果查询走的是另外两台还没有同步到的机器，就会拿到旧的数据，往已经不是master的机器写数据。
>
> 所以我们需要这个存储master信息的服务器集群，做到当信息还没同步完成时，不对外提供服务，阻塞住查询请求，等待信息同步完成，再给查询请求返回信息。
>
> 这样一来，请求就会变慢，变慢的时间取决于什么时候这个集群认为数据同步完成了。
>
> 假设这个数据同步时间无限短，比如是1微妙，可以忽略不计，那么其实这个分布式系统，就和我们之前单机的系统一样，既可以保证数据的一致，又让外界感知不到请求阻塞，同时，又不会有SPOF（Single Point of Failure）的风险，即不会因为一台机器的宕机，导致整个系统不可用。
>
> **这样的系统，就叫分布式协调系统。谁能把这个数据同步的时间压缩的更短，谁的请求响应就更快，谁就更出色，Zookeeper就是其中的佼佼者。**
>
> **它用起来像单机一样，能够提供数据强一致性，但是其实背后是多台机器构成的集群，不会有SPOF。**



### 为什么Zookeeper的吞吐量高

> 1.Zookeeper集群的**任意一个服务端节点都可以直接响应客户端的读请求**(写请求会不一样些,下面会详谈),并且可以通过增加节点进行横向扩展。这是其吞吐量高的主要原因
>
> 2.Zookeeper将全量数据存储于**内存中**,从内存中读取数据不需要进行磁盘IO,速度要快得多。
>
> 3.Zookeeper**放松了对分布式数据的强一致性要求**,即不保证数据实时一致,允许分布式数据经过一个时间窗口达到最终一致,这也在一定程度上提高了其吞吐量。
>
> 而写请求,或者说事务请求,因为要进行不同服务器结点间状态的同步,一定程度上会影响其吞吐量。故而简单的增加Zookeeper的服务器节点数量,对其吞吐量的提升并不一定能起到正面效果。**服务器节点增加,有利于提升读请求的吞吐量,但会延长服务器节点数据的同步时间,必须视具体情况在这两者之间取得一个平衡。**



### Zookeeper集群角色

> **Leader**
> **Leader**服务器在整个正常运行期间有且仅有一台,集群会通过选举的方式选举出Leader服务器,由它同统一处理集群的事务性请求以及集群内各服务器的调度。

> **Follower**
> **Follower**的主要职责有以下几点:
>
> - 1.参与Leader选举投票
> - 2.参与事务请求Proposal的投票
> - 3.**处理**客户端非事务请求(**读**),并**转发**事务请求(**写**)给Leader服务器。

> **Observer**
> **Observer**是弱化版的Follower。其像Follower一样**能够处理非事务也就是读请求,并转发事务请求给Leader服务器**,但是其不参与任何形式的投票,不管是Leader选举投票还是事务请求Proposal的投票。引入这个角色主要是为了在**不影响集群事务处理能力的前提下提升集群的非事务处理的吞吐量**。

### Zookeeper数据模型

> Zookeeper将数据存储于内存中,具体而言,Znode是存储数据的最小单元。而Znode被以层次化的结构进行组织,形容一棵树。其对外提供的视图类似于Unix文件系统。树的根Znode节点相当于Unix文件系统的根路径。正如Unix中目录下可以有子目录一样,Znode结点下也可以挂载子结点,最终形成如下所示结构。
>
> ![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180820225846944-872688418.png)
>
> ## Znode的类型
>
> > Znode按其生命周期的长短可以分为持久结点(PERSISTENT)和临时结点(EPHEMERAL);在创建时还可选择是否由Zookeeper服务端在其路径后添加一串序号用来区分同一个父结点下多个结点创建的先后顺序。
> >
> > > - 1.持久结点(PERSISTENT)
> > >   最常见的Znode类型,一旦创建将在一直存在于服务端,除非客户端通过删除操作进行删除。持久结点下可以创建子结点。
> > > - 2.持久顺序结点(PERSISTENT_SEQUENTIAL)
> > >   在具有持久结点基本特性的基础上,会通过在结点路径后缀一串序号来区分多个子结点创建的先后顺序。这工作由Zookeeper服务端自动给我们做,只要在创建Znode时指定结点类型为该类型。
> > > - 3.临时结点(EPHEMERAL)
> > >   临时结点的生命周期和客户端会话保持一致。客户端段会话存在的话临时结点也存在,客户端会话断开则临时结点会自动被服务端删除。临时结点下不能创建子结点。
> > > - 4.临时顺序结点(EPHEMERAL_SEQUENTIAL)
> > >   具有临时结点的基本特性,又有顺序性。
>
> ## znode的结构
>
> ![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180821162953209-1229005978.png)
>
> > - czxid:
> >   即Created ZXID,表示**创建该Znode结点的事务ID**
> > - mzxid:
> >   即Modified ZXID,表示**最后一次更新该结点的事务ID**
> > - version
> >   该Znode结点的**版本号**。每个Znode结点被创建时版本号都为0,每更新一次都会导致版本号加1,即使更新前后Znode存储的值没有变化版本号也会加1。version值可以形象的理解为Znode结点被更新的次数。Znode状态信息中的版本号信息,使得服务端可以对多个客户端对同一个Znode的更新操作做并发控制。整个过程和java中的CAS有点像,是一种乐观锁的并发控制策略,而version值起到了冲突检测的功能。客户端拿到Znode的version信息,并在更新时附上这个version信息,服务端在更新Znode时必须必须比较客户端的version和Znode的实际version,只有这两个version一致时才会进行修改。



### Zookeeper保证数据一致性

> Zookeeper采用ZAB(Zookeeper Atomic Broadcast)协议来保证分布式数据一致性。ZAB协议包括两种基本模式:**崩溃恢复模式**和**消息广播模式**。崩溃恢复模式主要用来**在集群启动过程,或者Leader服务器崩溃退出后进行新的Leader服务器的选举以及数据同步**;消息广播模式主要用来进行**事务请求的处理**。

#### 事务请求处理（写）流程

> - 1.所有的事务请求都交由集群的Leader服务器来处理,Leader服务器会将一个事务请求转换成一个Proposal(提议),并为其生成一个全局递增的唯一ID,这个ID就是事务ID,即ZXID,Leader服务器对Proposal是按其ZXID的先后顺序来进行排序和处理的。
> - 2.之后Leader服务器会将Proposal放入每个Follower对应的队列中(Leader会为每个Follower分配一个单独的队列),并以FIFO的方式发送给Follower服务器。
> - 3.Follower服务器接收到事务Proposal后,首先以事务日志的方式写入本地磁盘,并且在成功后返回Leader服务器一个ACK响应。
> - 4.Leader服务器只要收到过半Follower的ACK响应,就会广播一个Commit消息给Follower以通知其进行Proposal的提交,同时Leader自身也会完成Proposal的提交。
>
> ![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180820231547149-911185014.png)

#### Leader服务器的选举流程

> 当集群中不存在Leader服务器时集群会进行Leader服务器的选举,这通常存在于两种情况:1.集群刚启动时 2.集群运行时,但Leader服务器因故退出。集群中的服务器会向其他所有的Follower服务器发送消息,这个消息可以形象化的称之为选票,选票主要由两个信息组成,所推举的Leader服务器的ID(即配置在myid文件中的数字),以及该服务器的事务ID,事务表示对服务器状态变更的操作,**一个服务器的事务ID越大,则其数据越新**。
>
> - 1.Follower服务器投出选票(SID,ZXID),第一次每个Follower都会推选自己为Leader服务器,也就是说每个Follower第一次投出的选票是**自己的服务器ID和事务ID**。
> - 2.每个Follower都会接收到来自于其他Follower的选票,它会基于如下规则重新生成一张选票:**比较收到的选票和自己的ZXID的大小,选取其中最大的**;**若ZXID一样则选取SID即服务器ID最大的**。最终每个服务器都会重新生成一张选票,并将该选票投出去。
>
> 这样经过多轮投票后,如果某一台服务器得到了**超过半数的选票,则其将当前选为Leader**。由以上分析可知,Zookeeper集群对Leader服务器的选择具有偏向性,偏向于那些ZXID更大,即数据更新的机器。
>
> ![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180820232822615-266765305.png)

### Zookeeper服务器故障的容错

> Zookeeper通过事务日志和数据快照来避免因为服务器故障导致的数据丢失。
>
> - 事务日志是指服务器在更新内存数据前先将事务操作以日志的方式写入磁盘,Leader和Follower服务器都会记录事务日志。
> - 数据快照是指周期性通过深度遍历的方式将内存中的树形结构数据转入外存快照中。但要注意这种快照是"模糊"的,因为可能在做快照时内存数据发生了变化。但是因为Zookeeper本身对事务操作进行了幂等性保证,故在将快照加载进内存后会通过执行事务日志的方式来讲数据恢复到最新状态。

### [Zookeeper实现分布式锁](https://www.cnblogs.com/ysw-go/p/11444993.html)

> 其实如果有客户端C、客户端D等N个客户端争抢一个zk分布式锁，原理都是类似的。
>
> - 大家都是上来直接创建一个锁节点下的一个接一个的临时顺序节点
> - 如果自己不是第一个节点，就对自己上一个节点加监听器
> - 只要上一个节点释放锁，自己就排到前面去了，相当于是一个排队机制。
>
> 而且用临时顺序节点的另外一个用意就是，如果某个客户端创建临时顺序节点之后，不小心自己宕机了也没关系，zk感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁，或者是自动取消自己的排队。
>
> ![img](https://user-gold-cdn.xitu.io/2018/11/30/1676531f71973f37?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## 一致性hash

> 一致性哈希算法也是使用取模的方法，只是，一般的取模法是对服务器的数量进行取模，而一致性哈希算法是对 **2^32** 取模
>
> 首先，我们把二的三十二次方想象成一个圆，就像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由2^32个点组成的圆，示意图如下：
>
> ![一致性哈希算法基本概念图示1.png-2.6kB](http://imgconvert.csdnimg.cn/aHR0cDovL3N0YXRpYy56eWJ1bHVvLmNvbS9SaWNvMTIzLzJ6d3F0anU3OXQ1MGJwcGc2Z3BwNzdzbC8lRTQlQjglODAlRTglODclQjQlRTYlODAlQTclRTUlOTMlODglRTUlQjglOEMlRTclQUUlOTclRTYlQjMlOTUlRTUlOUYlQkElRTYlOUMlQUMlRTYlQTYlODIlRTUlQkYlQjUlRTUlOUIlQkUlRTclQTQlQkExLnBuZw?x-oss-process=image/format,png)
>
> 　　圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1,也就是说0点左侧的第一个点代表2^32-1
> 我们把这个由2的32次方个点组成的圆环称为 **hash环**。
>
> 　　那么，一致性哈希算法与上图中的圆环有什么关系呢？我们继续聊，仍然以之前描述的场景为例，假设我们有3台缓存服务器，服务器A、服务器B、服务器C，那么，在生产环境中，这三台服务器肯定有自己的IP地址，我们使用它们各自的IP地址进行哈希计算，使用哈希后的结果对2^32取模
>
> ![一致性哈希算法基本概念图示4.png-19.7kB](http://imgconvert.csdnimg.cn/aHR0cDovL3N0YXRpYy56eWJ1bHVvLmNvbS9SaWNvMTIzL3oyczM3ejM1NzY0czJnampuZGVqd3Q3bS8lRTQlQjglODAlRTglODclQjQlRTYlODAlQTclRTUlOTMlODglRTUlQjglOEMlRTclQUUlOTclRTYlQjMlOTUlRTUlOUYlQkElRTYlOUMlQUMlRTYlQTYlODIlRTUlQkYlQjUlRTUlOUIlQkUlRTclQTQlQkE0LnBuZw?x-oss-process=image/format,png)
>
> 一致性哈希算法就是通过这种方法，判断一个对象应该被缓存到哪台服务器上的，**将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出发，沿顺时针方向遇到的第一个服务器，就是当前对象将要缓存于的服务器**，由于被缓存对象与服务器hash后的值是固定的，所以，在服务器不变的情况下，一张图片必定会被缓存到固定的服务器上，那么，当下次想要访问这张图片时，只要再次使用相同的算法进行计算，即可算出这个图片被缓存在哪个服务器上，直接去对应的服务器查找对应的图片即可。

### 	优点

> **避免缓存大面积同时失效 缓存雪崩**
>
> 如果简单的对服务器数量进行取模，那么当服务器数量发生变化时，会产生缓存的雪崩，从而很有可能导致系统崩溃
>
> 使用一致性哈希算法时，**服务器的数量如果发生改变，并不是所有缓存都会失效，而是只有部分缓存会失效，前端的缓存仍然能分担整个系统的压力，而不至于所有压力都在同一时间集中到后端服务器上。**

### 	hash环偏斜

> 由于我们只有3台服务器，当我们把服务器映射到hash环上的时候，很有可能出现hash环偏斜的情况
>
> ![一致性哈希算法基本概念图示12.png-23.1kB](http://imgconvert.csdnimg.cn/aHR0cDovL3N0YXRpYy56eWJ1bHVvLmNvbS9SaWNvMTIzLzdiZGh4bnZmcHV1NTN4ZW1kcjZjcWM3bC8lRTQlQjglODAlRTglODclQjQlRTYlODAlQTclRTUlOTMlODglRTUlQjglOEMlRTclQUUlOTclRTYlQjMlOTUlRTUlOUYlQkElRTYlOUMlQUMlRTYlQTYlODIlRTUlQkYlQjUlRTUlOUIlQkUlRTclQTQlQkExMi5wbmc?x-oss-process=image/format,png)
>
> 我们就只能将现有的物理节点通过虚拟的方法复制出来，这些由实际节点虚拟复制而来的节点被称为”虚拟节点”。
>
> **“虚拟节点”是”实际节点”（实际的物理服务器）在hash环上的复制品,一个实际节点可以对应多个虚拟节点。**





# JVM

## 内存区域

> **线程私有区域:程序计数器、Java虚拟机栈、本地方法栈**
> **线程共享区域:Java堆、方法区、运行时常量池**

![](https://img-blog.csdnimg.cn/20190417223121994.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE4NjU3MTc1,size_16,color_FFFFFF,t_70)

### 程序计数器（线程私有）

> 1. 程序计数器是一块比较小的内存空间，可以看做是当前线程所执行的字节码的行号指示器。
> 2. 如果当前的线程执行的是Java方法，程序计数器记录的是正在执行的虚拟机字节码指令地址（代码行数），如果执行的是本地Native方法，计数器值为空
> 3. 程序计数器是唯一一个在JVM规范中没有OOM（OutOfMemoryError，内存溢出）出现的区域

### Java虚拟机栈（线程私有）

> 描述 Java 方法执行的内存模型：每个方法都会在虚拟机栈中创建一个栈帧用于存储局部变量表、操作数栈、方法出口等信息，每一个方法从调用直至执行完成的过程，就对应一个栈帧在虚拟机栈中入栈和出栈的过程。声明周期与线程相同。
>
> 如果当前线程请求的栈深度 > 虚拟机栈深度（-Xss，设置栈大小），抛出 **StackOverflow**异常
> 如果虚拟机栈在动态扩展时，无法申请到足够大的内存，抛出**OOM(OutOfMemoryError)**异常

### 本地方法栈（线程私有）

> 服务的是本地方法 (native 方法)，其余与虚拟机栈相同
> HotSpot 中将本地方法栈与虚拟机栈合二为一

### Java堆（GC堆，线程共享，垃圾回收的主要区域）

> 1. Java堆在JVM启动时创建，存放的都是对象实例，JVM要求所有对象实例以及数组都在Java堆上存放
> 2. Java堆可以处于物理上不连续的区域，Java堆一般来说都是可扩展的（-Xms：设置堆最小值，-Xmx：设置堆最大值）
> 3. 如果堆中没有足够内存来完成对象实例化并且无法再扩展。抛出OOM。

### 方法区（线程共享，JDK1.8以前称之为永久代，以后称之为元空间）

> 1. 存储已被JVM加载的类信息、常量、静态变量
> 2. 此区域也会进行垃圾回收，主要是针对常量池的回收以及类型卸载
> 3. 方法区无法满足内存分配需求时，抛出OOM

#### 运行时常量池（线程共享，方法区一部分）

> 存放字面量以及符号引用
> 字面量：字符串、final常量、基本数据类型的值
> 符号引用：类和结构的完全限定名、字段的名称和描述符、方法的名称和描述符

## 类生命周期

![img](https://mmbiz.qpic.cn/mmbiz_png/PgqYrEEtEnokxXiapDdvntH8PGwa0zGXMyIBnM38m8eKia8wAVY8aXb0NhM9wFNDLVuoFKIZ0Q2SBk5yibFgXsXOw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> 加载、验证、准备、解析、初始化

### 加载

> 查找并加载类的二进制数据加载时类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情：
>
> - 通过一个类的全限定名来获取其定义的二进制字节流。
> - 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。
> - 在Java堆中生成一个代表这个类的 `java.lang.Class`对象，作为对方法区中这些数据的访问入口。
>
> 相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。
>
> 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个 `java.lang.Class`类的对象，这样便可以通过该对象访问方法区中的这些数据。

### **验证：确保被加载的类的正确性**

> 验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作：
>
> - **文件格式验证**：验证字节流是否符合Class文件格式的规范；例如：是否以 `0xCAFEBABE`开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。
> - **元数据验证**：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了 `java.lang.Object`之外。
> - **字节码验证**：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。
> - **符号引用验证**：确保解析动作能正确执行。
>
> 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用 `-Xverifynone`参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。

### **准备：为类的 `静态变量分`配内存，并将其初始化为默认值**

> 准备阶段是正式为类变量**分配内存并设置类变量初始值**的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：
>
> - 1、这时候进行内存分配的仅包括**类变量**（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。
> - 2、这里所设置的初始值通常情况下是数据类型**默认的零值**（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。
>
> 假设一个类变量的定义为： 
> `public static intvalue=3`；
> 那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的 `public static`指令是在程序编译后，存放于类构造器 `<clinit>（）`方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。
>
> > 这里还需要注意如下几点：
> >
> > - 对基本数据类型来说，对于类变量（static）和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。
> > - 对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。
> > - 对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。
> > - 如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。
>
> - 3、如果类字段的字段属性表中存在 `ConstantValue`属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。
>
> 假设上面的类变量value被定义为： 
> `public static final int value=3`；
>
> 编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据 `ConstantValue`的设置将value赋值为3。我们可以理解为static final常量在编译期就将其结果放入了调用它的类的常量池中

### **解析：把类中的符号引用转换为直接引用**

> 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。符号引用就是**一组符号**来描述目标，可以是任何字面量。
>
> 直接引用就是直接**指向目标的指针、相对偏移量或一个间接定位到目标的句柄**。

### **初始化**

> 初始化，为类的静态变量**赋予正确的初始值**，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式：
>
> - ①声明类变量是指定初始值
> - ②使用静态代码块为类变量指定初始值
>
> JVM初始化步骤
>
> - 1、假如这个类还没有被加载和连接，则程序先加载并连接该类
> - 2、假如该类的直接父类还没有被初始化，则先初始化其直接父类
> - 3、假如类中有初始化语句，则系统依次执行这些初始化语句
>
> 类初始化时机：**只有当对类的主动使用的时候才会导致类的初始化**，类的主动使用包括以下六种：
>
> - 创建类的实例，也就是**new**的方式
> - **访问某个类或接口的静态变量**，或者对该静态变量赋值
> - **调用类的静态方法**
> - **反射**（如 `Class.forName(“com.shengsiyuan.Test”)`）
> - **初始化某个类的子类，则其父类也会被初始化**
> - Java虚拟机启动时**被标明为启动类的类**（ `JavaTest`），直接使用 `java.exe`命令来运行某个主类

## 类加载器

![img](http://mmbiz.qpic.cn/mmbiz_png/PgqYrEEtEnokxXiapDdvntH8PGwa0zGXM7qXKib1ibsib1BuyLxjoP1sgorwib78yTD4896N5r1AibdhDXTHZ7z9VyBg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> **启动类加载器**： `BootstrapClassLoader`，负责加载存放在 `JDK\jre\lib`(JDK代表JDK的安装目录，下同)下，或被 `-Xbootclasspath`参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.开头的类均被 `BootstrapClassLoader`加载）。启动类加载器是无法被Java程序直接引用的。

> **扩展类加载器**： `ExtensionClassLoader`，该加载器由 `sun.misc.Launcher$ExtClassLoader`实现，它负责加载 `JDK\jre\lib\ext`目录中，或者由 `java.ext.dirs`系统变量指定的路径中的所有类库（如javax.开头的类），开发者可以直接使用扩展类加载器。

> **应用程序类加载器**： `ApplicationClassLoader`，该类加载器由 `sun.misc.Launcher$AppClassLoader`来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。

### **JVM类加载机制**

> - **全盘负责**，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入
> - **父类委托**，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类
> - **缓存机制**，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效

### 双亲委派模型

> 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。

#### 意义：

> - 系统类防止内存中出现多份同样的字节码
> - 保证Java程序安全稳定运行

## 垃圾回收机制

### 1如何判断对象已死

#### 1.1引用计数法

> 给对象增加一个引用计数器，每当有一个地方引用它时，计数器就+1；当引用失效时，计数器就-1；任何时刻计数器为0的对象就是不能再被使用的，即对象已“死”。
>
> **但是，在主流的JVM中没有选用引用计数法来管理内存，最主要的原因是引用计数法无法解决对象的循环引用问题。**

#### 1.2可达性分析算法

> 通过一系列称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索走过的路径称为“引用链”，当一个对象到 GC Roots **没有任何的引用链相连时**(从 GC Roots 到这个对象不可达)时，证明此对象不可用
>
> ![这里写图片描述](https://img-blog.csdn.net/20180626084654607?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YnVqaWFuX2w=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
>
> 能作为**GC Roots**的对象
>
> > 1. **虚拟机栈**(栈帧中的本地变量表)**中引用的对象。**
> > 2. **方法区中静态属性引用的对象**
> > 3. **方法区中常量引用的对象**
> > 4. **本地方法栈中(Native方法)引用的对象**

### 2引用的类型

> 1.**强引用**: 强引用指的是在程序代码之中普遍存在的，类似于"Object obj = new Object()"这类的引用，只要强引用还存在，垃圾回收器永远不会回收掉被引用的对象实例。
>
> 2.**软引用**: 软引用是用来描述一些还有用但是不是必须的对象。对于软引用关联着的对象，**在系统将要发生内存溢出之前**，会把这些对象列入回收范围之中进行第二次回收。如果这次回收还是没有足够的内存，才会抛出内存溢出异常。在JDK1.2之后，提供了SoftReference类来实现软引用。
>
> 3.**弱引用**: 弱引用也是用来描述非必需对象的。但是它的强度要弱于软引用。**被弱引用关联的对象只能生存到下一次垃圾回收发生之前**。当垃圾回收器开始进行工作时，无论当前内容是否够用，都会回收掉只被弱引用关联的对象。在JDK1.2之后提供了WeakReference类来实现弱引用。
>
> 4.**虚引用**: 虚引用也被称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用的唯一目的**就是能在这个对象被收集器回收时收到一个系统通知**。在JDK1.2之后，提供了PhantomReference类来实现虚引用。

### 3 finalize方法

> 要宣告一个对象的真正死亡，至少要经历两次标记过程: 如果对象在进行可达性分析之后发现没有与GC Roots相连接的引用链，那它将会被**第一次标记并且进行一次筛选**，筛选的条件是**此对象是否有必要执行ﬁnalize()方法**。当对象没有覆盖ﬁnalize()方法或者ﬁnalize()方法已经被JVM调用过，虚拟机会将这两种情况都视为"没有必要执行"，此时的对象才是真正"死"的对象。
>
> 如果这个对象被判定为有必要执行ﬁnalize()方法，那么这个对象将会被放置在一个叫做**F-Queue的队列之中**，并在稍后由一个虚拟机自动建立的、低优先级的Finalizer线程去执行它（这里所说的执行指的是虚拟机会触发ﬁnalize()方法）。ﬁnalize()方法是对象逃脱死亡的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，**如果对象在ﬁnalize()中成功拯救自己(只需要重新与引用链上的任何一个对象建立起关联关系即可)，那在第二次标记时它将会被移除出"即将回收"的集合；**如果对象这时候还是没有逃脱，那基本上它就是真的被回收了。
>
> finalize**方法只会执行一次**

### 4垃圾回收算法

#### 4.1标记清除算法

> “标记-清除”算法是最基础的收集算法。算法分为标记和清除两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象(标记过程参见1.2可达性分析)。后续的收集算法都是基于这种思路并对其不足加以改进而已。

> **不足在于**
>
> 1. **效率问题**：标记和清除这两个过程的**效率都不高**
> 2. **空间问题**：标记清除后会产生大量不连续的**内存碎片**，空间碎片太多可能会导致以后在程序运行中需要分配较大对象时，无法找到足够连续内存而不得不提前触发另一次垃圾收集。

#### 4.2复制算法（新生代回收算法）

> 复制”算法是为了解决“标记-清除”的效率问题。它将可用内存按容量划分为大小相等的两块，每次只使用其中一块。当这块内存需要进行垃圾回收时，会将此区域还存活着的对象复制到另一块上面，然后再把已经使用过的内存区域一次清理掉。

> **好处在于**
>
> 1. 每次都是对整个半区进行内存回收，内存分配时也就不需要考虑内存碎片等的复杂情况，只需要移动堆顶指针，按顺序分配即可。
> 2. 此算法实现简单，运行高效。

> **具体实现逻辑**
>
> 将内存(新生代内存)分为一块较大的Eden(伊甸园)空间和两块较小的Survivor(幸存者)空间，每次使用Eden和其中一块Survivor（两个Survivor区域一个称为From区，另一个称为To区域）。当回收时，将Eden和Survivor中还存活的对象一次性复制到另一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。
>
> 当Survivor空间不够用时，需要依赖其他内存(**老年代**)进行**分配担保**。
>
> HotSpot默认Eden与Survivor的大小比例是8 : 1，也就是说Eden:Survivor From : Survivor To = 8:1:1。所以**每次新生代可用内存空间为整个新生代容量的90%**,而剩下的10%用来存放回收后存活的对象。

#### 4.3标记整理（老年代回收算法）

> 复制收集算法在对象存活率较高时会进行比较多的复制操作，效率会变低。因此在老年代一般不能使用复制算法。
> 针对老年代的特点，提出了一种称之为“标记-整理算法”。标记过程仍与“标记-清除”过程一致，但后续步骤不是直接对可回收对象进行清理，而是让所有存活对象向一端移动，然后直接清理掉端边界以外的内存。流程图如下：
>
> ![这里写图片描述](https://img-blog.csdn.net/20180626165125641?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YnVqaWFuX2w=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### 5垃圾收集器

![这里写图片描述](https://img-blog.csdn.net/2018062809555037?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1YnVqaWFuX2w=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

parallel scavenge追求吞吐量

g1 cms最求时延最短

//todo 具体收集器



| 序号 | 类型     |                             题目                             |
| ---- | -------- | :----------------------------------------------------------: |
| 1    | java基础 |                      Java 垃圾回收机制                       |
| 2    | java基础 |               抽象类和接口的区别以及使用场景？               |
| 3    | java基础 |                 Map、Set、List的特点与用法？                 |
| 4    | java基础 |              ThreadLocal的使用以及实现原理解析;              |
| 5    | java基础 |                     Java中的多态是什么？                     |
| 6    | java基础 |     Java中变量，代码块，构造器之间的执行顺序是怎么样的？     |
| 7    | java基础 |                   final 关键字有哪些作用？                   |
| 8    | java基础 |                     Java中堆和栈的区别？                     |
| 9    | java基础 |               二叉平衡树，怎么用一维数组存储？               |
| 10   | java基础 |                    怎样判断链表是否有环？                    |
| 11   | 分布式   | 你能详细描述下现在项目的优劣势吗？这些缺点，你有什么好的想法补齐吗？ |
| 12   | 分布式   |                     如何做一个分布式锁？                     |
| 13   | 分布式   |               分布式集群下如何生成唯一序列号？               |
| 14   | 分布式   |                      什么是一致性hash？                      |
| 15   | 分布式   |                   redis为什么是单线程的？                    |
| 16   | 分布式   |                  redis过期key是怎么清理的？                  |
| 17   | 分布式   |              如何保证缓存和数据库数据的一致性？              |
| 18   | 分布式   |               分布式唯一ID生成方案是怎么样的？               |
| 19   | 分布式   |                     对分布式事务的理解？                     |
| 20   | 分布式   |                 分布式系统如何做到服务治理？                 |
| 21   | 框架     |     说说我们一般怎么定位cpu使用率过高，内存泄漏的问题。      |
| 22   | 框架     | 你记忆最深刻的一次定位问题的是什么？能详细描述下吗？对你有什么启发吗？ |
| 23   | 框架     |                   说说epoll下ET LT模式区别                   |
| 24   | 框架     |                        HTTPS 连接过程                        |
| 25   | 框架     |                         TCP 拥塞控制                         |
| 26   | 框架     |                spring boot的自动装配实现原理;                |
| 27   | 框架     |                   什么是IOC ？什么是AOP？                    |
| 28   | 框架     |                     bean的作用域有哪些？                     |
| 29   | 框架     |                    bean的生命周期是什么？                    |
| 30   | 框架     |           结合案例讲讲对spring事务传播行为的理解。           |
| 31   | 数据库   |                      MySQL 主从复制原理                      |
| 32   | 数据库   | mysql读写分离如果主从同步延迟大怎么办？怎么尽可能避免主从同步延迟大的问题？ |
| 33   | 数据库   | 简单描述mysql中，索引，主键，唯一索引，联合索引的区别，对数据库的性能有什么影响？ |
| 34   | 数据库   |                   什么情况下不宜建立索引？                   |
| 35   | 数据库   |          mysql数据库可重复读隔离级别如何解决幻读的;          |
| 36   | 数据库   |           MYSQL中一条更新语句的执行过程是怎样的？            |
| 37   | 数据库   |             undo log，redo log，bin log是什么？              |
| 38   | 数据库   |                   MVCC的实现原理是怎样的？                   |
| 39   | 数据库   |         为什么mysql早期选可重复读作为默认的隔离级别          |
| 40   | 数据库   |              mysql现在是如何做到支持全文索引的               |

# 算法

## 排序算法

### 堆排序

> nlogn
>
> 不稳定

### 快排

> nlogn
>
> 不稳定

### 希尔排序

### 直接选择排序

### 基数排序

### 冒泡排序

### 直接插入排序

### 折半插入排序

### 归并排序