## 消息队列

把消息队列比作是一个存放消息的容器，当我们需要使用消息的时候可以取出消息供自己使用。消息队列是分布式系统中重要的组件，使用消息队列主要是为了通过异步处理提高系统性能和削峰、降低系统耦合性。

![img](https://upload-images.jianshu.io/upload_images/2509688-311483f18a8d228e?imageMogr2/auto-orient/strip|imageView2/2/w/910)

### 为什么使用消息队列

#### 	异步处理提高性能（削峰 降低响应时间）

> 在不使用消息队列服务器的时候，用户的请求数据直接写入数据库，在高并发的情况下数据库压力剧增，使得响应速度变慢。但是在使用消息队列之后，用户的请求数据发送给消息队列之后立即 返回，再由消息队列的消费者进程从消息队列中获取数据，异步写入数据库。由于消息队列服务器处理速度快于数据库（消息队列也比数据库有更好的伸缩性），因此响应速度得到大幅改善。

> **削峰作用的功能**——即**通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。**

> **但是，需要修改业务，无法保证是否一定写入成功，需要后续的消息提醒** 

#### 	降低系统耦合

> ![img](https://upload-images.jianshu.io/upload_images/2509688-f3bddbdea97bb30c?imageMogr2/auto-orient/strip|imageView2/2/w/790)
>
> **消息队列使利用发布-订阅模式工作，消息发送者（生产者）发布消息，一个或多个消息接受者（消费者）订阅消息。** 从上图可以看到**消息发送者（生产者）和消息接受者（消费者）之间没有直接耦合**，消息发送者将消息发送至分布式消息队列即结束对消息的处理，消息接受者从分布式消息队列获取该消息后进行后续处理，并不需要知道该消息从何而来。**对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计**。

> 另外为了避免消息队列服务器宕机造成消息丢失，会将**成功发送到消息队列的消息存储在消息生产者服务器上**，等消息真正被消费者服务器处理后才删除消息。在消息队列服务器**宕机后**，生产者服务器会**选择分布式消息队列服务器集群中的其他服务器**发布消息。

### 使用MQ后带来的问题

#### 	系统可用性降低

> 需要额外考虑消息丢失的问题，以及MQ挂掉

#### 	系统复杂度提升

> 需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！

#### 	一致性问题

> 消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!



## JMQ

![img](http://img.mp.itc.cn/upload/20160830/2f6615760d134464a1321497b7925897_th.jpeg)

包括服务端 客户端 管理端 存储通过JFS和HBase

![img](http://dl2.iteye.com/upload/attachment/0122/2698/9a5c4783-c8cc-3903-8a67-ad9aafd90878.png)

### 服务端

> 服务端提供了配置信息分发、重试消息管理和消息存储与分发这三大类功能。每个服务端实例都具备这三类功能的服务能力，但是在实际部署上这三类功能对应三个不同的集群，对应每一个实例功能不叠加。在测试环境和库房等资源有限的环境下，这三类功能由同一个服务端实例提供服务。

#### 配置信息分发

> 负责客户端参数变更时与消息分配的服务端实例变更时通知客户端。

#### 重试消息管理

> 主要用于对业务系统临时处理不了的消息进行存放，然后再按照一定的策略投递给客户端处理。可以提供错误原因、错误处理次数等查询。

#### 消息存储与分发

> 接收生产者投递的消息，把消息存放在本地磁盘上，消费者从该服务上拉取消息进行消费。

### 客户端

> 提供了JAVA语言的SDK和支持HTTP协议的proxy，非JAVA语言通过proxy接入。

### 管理端

> 提供了JAVA语言的SDK和支持HTTP协议的proxy，非JAVA语言通过proxy接入。

### 特点

#### 数据可靠性

> 针对公司的业务特点，消息服务主要应用于订单、支付、物流等环节。服务端采用**MASTER-SLAVE**结构，消息在正常情况下会同时存放两份，其中一份会强制持久化到磁盘，磁盘做**RAID-5**。默认情况下客户端采用同步发送，每条消息到达服务端MASTER后会强制刷入磁盘同时并行推送一份到SLAVE上，SLAVE写入文件系统后不等待强制刷盘就反馈给MASTER。根据不同的场景为了提高服务的可用性，普通级别的消息SLAVE断开后，该组服务可以正常使用，当SLAVE连接上后又会自动切换为保存两份。当然对数据可靠级别高的消息是强制要求数据必须写两份才算成功的。

##### RAID-5

###### 原理

> RAID5和[RAID4](https://baike.baidu.com/item/RAID4)一样，数据以块为单位分布到各个硬盘上。RAID 5不对数据进行备份，而是把数据和与其相对应的[奇偶校验](https://baike.baidu.com/item/奇偶校验)信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。当RAID5的一个磁盘数据损坏后，利用剩下的数据和相应的[奇偶校验](https://baike.baidu.com/item/奇偶校验)信息去恢复被损坏的数据。

###### 读写

> 用简单的语言来表示，至少使用3块硬盘（也可以更多）组建RAID5[磁盘阵列](https://baike.baidu.com/item/磁盘阵列)，当有数据写入硬盘的时候，按照1块硬盘的方式就是直接写入这块硬盘的[磁道](https://baike.baidu.com/item/磁道)，如果是RAID5的话这次数据写入会根据算法分成3部分，然后写入这3块硬盘，写入的同时还会在这3块硬盘上写入校验信息，当读取写入的数据的时候会分别从3块硬盘上读取数据内容，再通过检验信息进行校验。当其中有1块硬盘出现损坏的时候,就从另外2块硬盘上[存储](https://baike.baidu.com/item/存储)的数据可以计算出第3块硬盘的数据内容。也就是说raid5这种存储方式只允许有一块硬盘出现故障，出现故障时需要尽快更换。当更换[故障](https://baike.baidu.com/item/故障)硬盘后，在故障期间写入的数据会进行重新校验。 如果在未解决[故障](https://baike.baidu.com/item/故障)又坏1块，那就是灾难性的了。

#### 服务高可用

> 每类消息一般都会分配3组及以上的服务组，每组服务包括一个MASTER和一个SLAVE，当然如果有需要也可以挂载多个SLAVE。
>
> 客户端发送消息时，如果其中一组出现故障会重试发送给其他的组。
>
> 虽然MASTER-SLAVE支re持切换，提高服务的可用性，但是在实际生产中MASTER出现故障时会优先采用通过其他服务组自动接替生产服务的方式，本组服务只提供从SLAVE读取的方式，而不是让SLAVE接替MASTER的写入，避免临界状态下丢失消息。

### JMQ架构

> JMQ的消息放在topic这样的逻辑概念中。P表示生产者，C表示消费者
>
> ![image-20200619094829793](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619094829793.png)

> 每个topic对应了多个分片（绿色部分）每个分片都是两台物理机（一主一从），而每个分片也可能存放多个topic主题
>
> ![image-20200619094923885](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619094923885.png)

> ![image-20200619095050882](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619095050882.png)
>
> 每个主题映射到分片上时，每个分片都会有一个队列的概念。每个topic都有一个固定的队列数
>
> 消息最终存在在journal中

![image-20200619095543543](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619095543543.png)

JMQ消费

### 发送生产方面

#### 	如何提高发送量？

> 1 有足够多的服务器容量（网络和存储）
>
> 2 足够大的压力（可以采用多线程的形式进行发送）
>
> 3 可以支撑发送量的性能

#### 	如何保障发送性能

> 1 设置合理的超时时间
>
> 2 合适的重试和降级策略（发送失败后 置入另一个发送队列）

### 消费方面

> ![image-20200619102138152](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619102138152.png)
>
> 1 线程x向分片请求拉取
>
> 2 抢占队列 返回消息集合
>
> 3 返回的消息 通过onMessage方法进行获取 处理
>
> 4 客户端将消费成功与否的命令返回给队列
>
> 5 释放队列 确认位置

#### 影响消费速度的三个因素

> ​	1 消费时 onMessage（List<Message> msgs）的执行时间
>
> ​	2 threadx的线程数量 线程越多 处理能力越强
>
> ​	3 服务端队列数量越多 阻塞程度越轻 消费性能越好

> **开启并行消费后，一个队列可以被多个消费线程消费**
>
> ![image-20200619105530681](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619105530681.png)
>
> ![image-20200619110014964](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619110014964.png)

### JMQ消费-容灾

> ![image-20200619110902488](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619110902488.png)
>
> 每个分片两台物理机，中从结构，所有的数据都存放在主节点上，从节点只是作为备份作用
>
> 当从节点失效后，主节点变为**只读**，客户端无法写入后，感知到节点失效
>
> 主节点失效后，无法写入。挤压的消息由于已经备份到从节点上，所有的消息拉取，由从节点来负责

### JMQ防重

> 由于在broker的成功反馈消息有可能中断，导致客户端启用重试机制，从而导致broker上两条或多条相同的消息
>
> ![image-20200619111419213](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619111419213.png)
>
> 由于client可能已经成功处理了请求，但确认消息由于网络的因素，导致无法成功被broker接收。queue此时仍然被锁定，所以在超时后，queue会自动进行解锁，消息会重复进行推送
>
> ![image-20200619111530418](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619111530418.png)

### JMQ重试

> 由于listener中的onMessage方法进行消息的接收和处理，但存在消息错误，无法处理的情况。此时，会再次调用两次onMessage方法，进行重试。如果三次都无法正确处理，即使再度重试，也无法正确的处理。所以，将这样的消息存放到mysql中，将队列中位置后移，避免影响后续的消息处理
>
> ![image-20200619112438546](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619112438546.png)
>
> 重试的逻辑
>
> ![image-20200619113109269](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619113109269.png)

## JIMDB

基于redis的分布式缓存与高速键值存储服务。

### 解决redis的问题

#### 	redis完全依赖内存，内存往往不够实用

> 引入RAM + SSD两级存储，在内存中存储热点数据，冷数据被自动交换到磁盘，解决内存不足的问题

#### 	redis启动需要将所有数据加载到内存，启动慢

> 启动时并不把所有数据加载入内存，而是在运行时根据需要加载，解决启动速度慢的问题

#### 	内存总量不断突破，不断进行扩容

> 因为引入了二级存储，存储容量通常比较大，所以不需要频繁的扩容了。

### 遇到的问题

#### 	内存不足

> 虽然Redis对于每一个命令处理之前都会检查内存占用情况，当超过配置的最大内存时会按照配置的淘汰策略部分key，但是这并不能满足我们的需求，因此我们需要在发现内存不足时按照一定的策略淘汰一部分内存中key（dirty key不会被淘汰），以释放宝贵的内存资源。
>
> 内存占用率>85%时采用随机淘汰策略，随机淘汰部分key直到内存占用率降到75%以下。
>
> 内存占用率>75%时采用LRU淘汰策略，这里参考了Redis的淘汰思路，采用随机采样然后按照LRU淘汰。
>
> 不过这两种淘汰策略都可能耗时比较长，如果直接放在原来Redis检查内存占用的地方，势必会影响单次请求的延时，所以我们将上述的淘汰策略放在定时任务中处理，同时原Redis的内存占用检查我们采用快速检查方案，即内存占用率>90%时，随机淘汰几个key。

#### 	磁盘内存数据交换

> Redis查找一个key，首先会在内存中查找，只有在内存中找不到才会在磁盘中查找，如果仍然没有找到，则表明这个key不存在，如果在磁盘中找到了，会将这对KV添加到Redis的字典以加载到内存。
>
> Redis修改一个key后，我们将这个key标记为**dirty key**，即将key的副本**添加到**专门用于保存dirty key的字典**dirty dict中**，为了节约空间，我们只存储了这个key（value为NULL）。我们在定时任务中**周期性执行flush dirty key to disk任务**，这个任务会将存储在dirty dict中的key写入磁盘，写磁盘时，我们需要对key的value进行**序列化编码成二进制流**，当dirty dict中的key都同步到磁盘上后，清空dirty dict。

#### 	过期key的存储

> 当一个key设置了过期时间但只存储在磁盘上，如果这个key已经过期，但是仍然占用磁盘空间，造成磁盘空间的浪费，因此我们需要**定期扫描磁盘上**存储的设置了过期时间的key，如果发现超时，即时删除以释放磁盘空间。
>
> 我们将所有设置了过期时间的key再单独存储一份{ key，expiretime }，上文中提到的key的存储格式中的第一个字节就派上用处了，我们约定”0”表示正常的KV，”1”表示设置过期时间的key，其中只存储过期时间，这样我们直接扫描前缀为”1”的key就可以快速判断其是否已经超时。

### 集群拓扑

> 最内层蓝色矩形代表一个jimdb实例 多个实例构成了一个集群
>
> 一份业务数据会被分成多个部分，称之为扇即shard 或 分片
>
> 一份业务数据也会有多个副本 即途中圆角虚线矩形部分（图中有两个分组）
>
> ![image-20200619161138416](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619161138416.png)
>
> 每个分片会有一个实例提供读写服务，成为master
>
> 其他实例提供制度服务 称之为slave

### 主从复制

![image-20200619164217433](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619164217433.png)

#### **增量复制**

> 主节点除了写入自己内存以外，还需要将自己接收到的命令写入环形缓冲区。并且记录下命令的偏移量。缓冲区会异步将数据写入从节点，从节点会定时向主节点上报自己的偏移量。如果偏移量不相同，则再次发送没有发送的数据

#### **全量复制**

> 发生在从节点刚连接到主节点，此时主节点会fork一个子进程，子进程将内存快照写入一个rdb文件，发送给rdb。slave节点收到后，将文件解析为数据加载。

#### 写入过快

> 如果写入过快，速度高于主从复制的速度，则环形缓冲区很快会被占满，且新命令会覆盖旧命令，注重之间无法完成增量复制，只能触发全量复制

#### 最终一致性而非强一致性

> 由于是异步写入从节点，所以数据无法保证强一致性。

#### hashtag

> 目的是为了让同一个key分布到同一个分片上 尤其是针对一些多key命令
>
> 在多实例的环境下，像是smove（将某个实例从一个集合移动到另一集合），无法保证原子操作。可能会导致（类似于删除失败）两个集合中都有该元素。所以需要将所有的相同的key分布在同一实例上。

#### 集群高可用

> 哨兵机制 
>
> 监控实例的存活 大多数哨兵认为实例死亡 则认为实例失效（哨兵部署在与实例同一机房的不同机架上）
>
> ![image-20200619165322240](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619165322240.png)

### 最佳实践

#### 	大key问题

> 可能会导致阻塞

> 拆分key

#### 	热key（一个key频繁被请求的）

> CPU过高
>
> 无法扩容
>
> 带宽问题
>
> 热写

> **本地缓存**（把热key放在本地缓存中，所有的读在本地读取 不再发送请求）
>
> **多副本扛读**（增加从节点 每个从节点分担一部分压力）提供异构的设计 可以在某一个实例上增加副本
>
> **保持空闲连接**

#### 	客户端高可用

> 读策略（设置更好的读取策略 从特定副本上读取）
>
> 自动摘流量（服务端判断一个实例的死亡 需要20-40s 但这个时间段 客户端不清楚服务端状况 所以需要客户端摘流量 ）当一个副本的读请求三次失败 会切换到另一个副本上 将原副本摘掉

#### 	连接池配置

> 一般需要压测来配置
>
> ![image-20200619171948474](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619171948474.png)

#### 	超时

> 时间组成：数据相应时间，链接创建时间，等待空闲时间。无法精确控制超时
>
> 秒杀或流量突增的场景，不合理的池配置会导致链接风暴（流量突增，导致cpu响应变慢，此时出现超时，会进一步导致创建连接，从而恶性循环）**需要保证一定的最小空闲连接**
>
> 过短的超时时间配置，在大流量情况下可能导致链接风暴（超时时间设置较短，很容易被判别为超时）
>
> 写命令超时重试，需要考虑命令是否是幂等的（写命令超时，无法判断是否成功写入已经成功了，此时重复操作应该要舍弃）

### 存在的问题

> 单副本可以做到实例的自动恢复，但是不能恢复数据
>
> 主从切换时，可能会丢失少量数据
>
> 内存可能会写满（会先淘汰过期key 后丢弃新的写入）

## JSF

杰夫，**京东服务框架**

### 适用场景

> 适合于分布式架构下，服务与服务之间的同步调用，数据量小（单个请求小于20K）并发大的场景；

### 设计原则

> 1.接口**参数**尽量用**简单的类型**，比如基础类型Integer、Boolean等，如使用自定义类型也请保证此类型的结构尽量简单、嵌套层数尽量少，这样会减少序列化时的消耗；
>
> 2.传输的**数据尽量少**，大数据会占用更多有限的带宽；
>
> 3.保证每次**RPC调用的原子性**，尽量减少在一个事务过程中发起的RPC调用，检查RPC调用的返回值或异常；
>
> 4.保证关键接口的**幂等性**；
>
> 5.制定服务等级协议（SLA），估算线上并发量，考虑每个请求的大小以及服务器带宽，压测单个服务在单位时间内的处理能力，计算需要部署的服务实例数；

### 设计架构

> ![image-20200619143909459](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619143909459.png)
>
> Index Service: 索引服务，提供注册中心地址列表；
>
> 注册中心：提供服务注册、订阅，服务上下线；配置下发、状态读取（如client所拥有的地址列表），为了容灾多实例部署；
>
> Monitor Service：收集所有客户端所上传的性能统计数据；
>
> Web管理端：服务管理界面，可以在此配置权重、路由规则等；



### PRC

> 远程过程调用，一个节点请求另一个节点提供的服务
>
> ![image-20200619141430436](d:%5C%E6%88%91%E7%9A%84%E6%96%87%E6%A1%A3%5C%E6%A1%8C%E9%9D%A2%5CRAID-5.assets%5Cimage-20200619141430436.png)
>
> 在微服务的设计中，一个服务A如果访问另一个Module下的服务B，可以采用HTTP REST传输数据，并在两个服务之间进行序列化和反序列化操作，服务B把执行结果返回过来。
>
> ![img](https://upload-images.jianshu.io/upload_images/7632302-19ad38cdd9a4b3ec.png?imageMogr2/auto-orient/strip|imageView2/2/w/723/format/webp)

#### 要解决的问题

> 1. **解决分布式系统中，服务之间的调用问题。**
> 2. **远程调用时，要能够像本地调用一样方便，让调用者感知不到远程调用的逻辑。**	

#### 	Call ID映射

> 本地调用，函数的调用是通过函数指针指定，
>
> 在远程调用则需要建立Call ID和和函数的映射

#### 	序列化和反序列化

> 本地调用，参数是压栈后弹栈赋值给参数。
>
> 远程调用，需要把参数转成字节流，服务端拿到后，再将其装变为自己能够读取的格式

#### 	网络传输

> 所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用**TCP**协议，但其实**UDP**也可以，而gRPC干脆就用了**HTTP2**。Java的Netty也属于这层的东西。



## 微服务与SOA架构

### 微服务

> 通常跟微服务相对的是单体应用，即将所有功能都打包成在一个独立单元的应用程序。

### SOA

> 面向服务的架构
>
> SOA是一种粗粒度、**松耦合**服务架构，服务之间通过简单、精确定义接口进行通讯，不涉及底层编程接口和通讯模型。

> 所谓**松耦合**（没有强制绑定到特定的实现上）的好处有两点
>
> 一点是它的灵活性
>
> 另一点是，当组成整个应用程序的每个服务的内部结构和实现逐渐地发生改变时，它能够继续存在。

### 对比

> | 功能     | SOA                  | 微服务                       |
> | -------- | -------------------- | ---------------------------- |
> | 组件大小 | 大块业务逻辑         | 单独任务或小块业务逻辑       |
> | 耦合     | 通常松耦合           | 总是松耦合                   |
> | 公司架构 | 任何类型             | 小型、专注于功能交叉团队     |
> | 管理     | 着重中央管理         | 着重分散管理                 |
> | 目标     | 确保应用能够交互操作 | 执行新功能、快速拓展开发团队 |
>
> 微服务架构一般来说，每个独立的小服务就有自己的持久化业务数据。每个微服务只能访问自己的数据库，而无权访问其他服务的数据。

## 高并发环境（接口的降级和熔断）

### 降级

**降级意味着相比降级之前功能表现得不完美**

> 当系统出现问题时，有一个备选的方案可以马上进行切换
>
> > 例如，接口的功能是实时预测未来一个月某个商品的采购数量，突然间依赖的上游系统出现问题了，那么我们的接口就完全不可用了吗？显然这是不应该的，这时我接口就可以**降级**，返回昨天实时计算出来的结果，虽然准确性可能差一点，但系统能够正常运转

#### 	自动降级

> 系统自动检测到问题时，自动切换

#### 	手动降级

> 系统监测到问题报警，人为的进行切换

#### 	降级的时机

> **超时降级**	调用服务时超时返回了默认值或其他处理方法
>
> **失败次数降级**	服务可用率下降时降级
>
> **限流**	限流同样是一种降级的方法
>
> **故障降级**	依赖的外系统发生故障时降级
>
> **拒绝服务降级**	

### 熔断

> **遇到危险了，必须马上停掉**
>
> > 假设一个接口部署了10台机器（分布式），突然某一台机器的接口调用情况正确率降到90%，那么这台机器肯定出现问题了，这个时候就需要熔断这台机器，把这台机器从整个集群中摘掉，从而保证用户的请求100%的正确
>
> > 一个系统中有很多功能，这些功能有些是核心功能，有些是非核心功能，那么在一些大促中，我们可能熔断掉一些非核心功能，从而保证核心功能的流转（登录和注册，登录属于核心，注册是属于非核心）

#### 	熔断的时机

> 系统攻击熔断	当某个服务遭遇流量攻击时，可以熔断这个服务
>
> 涉及核心功能运行时的熔断	下单和评论功能，关键时刻可以熔断评论功能

**两者的目的都是为了维护系统的可用性和稳定性**

**在设计熔断和降级时，需要考虑熔断算法，恢复机制，报警**

**但是不同在于：降级是牺牲部分功能的（可以用手机号注册，邮箱不可以）但是熔断是放弃全部的功能（注册模块完全不可用）**



### 实现降级和熔断的手段

#### 1 服务码+配置中心

> 调用所有的服务，都传入必参数服务码和开关，默认关闭。当触发某种条件时可打开开关，或者通过配置中心手动推送开关新的值，从而保护系统不被单个服务压垮

```python

func  DowngradeAndFuse (ctx context.Context){
    //业务码
    bizValue := ctx.Value("bizCode")
    //熔断降级标识
    flag := ctx.Value("flag")
   
    if bizValue == "指定业务" && flag {
       //降级或者熔断
       return
    }
}
```

#### 2 Hystrix

##### 	采用的手段

> 1. 资源隔离（线程池和信号量两种手段的隔离）
> 2. 限流
> 3. 降级
> 4. 熔断（断路器）

##### 	设计方式

> 1. 使用命令模式将所有对外部服务（或依赖关系）的调用包装在HystrixCommand或HystrixObservableCommand对象中，并将该对象放在单独的线程中执行
> 2. 每一个依赖都有自己对应的线程池或者信号量，线程池耗尽时，拒绝请求
> 3. **维护**请求的各种**状态**（成功，失败，超时的次数）
> 4. 当**错误率到达一定阈值时，进行熔断**，过一定的时间后又**恢复**
> 5. 提供降级，失败，成功，熔断后的**回调逻辑**
> 6. 实时的监控指标和配置信息的修改

### 限流

> 有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询（评论的最后几页），因此需有一种手段来限制这些场景的并发/请求量，即限流。

> 目的是通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（**定向到错误页**或告知资源没有了）、**排队或等待**（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如**商品详情页库存默认有货**）

#### 	限流算法

##### 		令牌桶

> 系统按照恒定的时间间隔1/QPS向桶内加入Token。新请求到达时，会各自拿走一个token，如果没有token可拿，就进行阻塞或者拒绝服务。

![img](https://img-blog.csdn.net/20160423213519927)

> 想法来源于计算机网络中的拥塞控制。
>
> 传送到令牌桶的数据包需要消耗令牌。不同大小的数据包，消耗的令牌数量不一样。
>
> 令牌桶这种控制机制基于令牌桶中是否存在令牌来指示什么时候可以发送流量。令牌桶中的每一个令牌都代表一个字节。如果令牌桶中存在令牌，则允许发送流量；而如果令牌桶中不存在令牌，则不允许发送流量。因此，如果突发门限被合理地配置并且令牌桶中有足够的令牌，那么流量就可以以峰值速率发送。

##### 		漏桶

> 请求进入漏桶内，漏桶以一定速度出水（交给接口进行处理）请求进入速率过大会溢出，拒绝请求。

##### 		计数器

> 通过原子操作的AtomicLong进行限制流量的计数。

```java
try {
if(atomic.incrementAndGet() > 限流数) {
//拒绝请求
    }
//处理请求
} finally {
    atomic.decrementAndGet();
}
```

##### 		基于Redis

> 设置访问接口的时间间隔 **每一个用户对此服务接口的访问就把键值加1，在60秒内当键值增加到10的时候，就禁止访问服务接口**

## 生成全局唯一objectid

使用12个字节用来表示objectId 其中4bytes时间 3bytes机器码 2bytes进程pid 3字节自增码（随机生成）？



## Dozer的使用

> Dozer是Java Bean到Java Bean映射器，它以递归方式将数据从一个对象复制到另一个对象。通常，这些Java Bean将具有不同的复杂类型。
>
> Dozer支持简单属性映射，复杂类型映射，双向映射，隐式显式映射以及递归映射。这包括映射还需要在元素级别进行映射的集合属性。





## RPC远程调用



## springMVC中的ModelAndView

> 使用ModelAndView类用来存储处理完后的结果数据，以及显示该数据的视图。从名字上看ModelAndView中的Model代表模型，View代表视图，这个名字就很好地解释了该类的作用。业务处理器调用模型层处理完用户请求后，把**结果数据存储在该类的model属性中**，把要返回的**视图信息存储在该类的view属性**中，然后让该ModelAndView返回该Spring MVC框架。框架通过调用配置文件中定义的视图解析器，对该对象进行解析，最后把结果数据显示在指定的页面上。 

### 	方法

> #### 	添加模型数据addObject方法
>
> #### 	设置视图 setViewName

### 	作用

#### 		设置转向的地址

```java
ModelAndView view = new ModelAndView("path:student");//通过构造的方式	
```

```java
public void setViewName(String viewName){...}//通过setViewName的方法
```

#### 		将控制器方法中处理的结果数据传递到结果页面

> 也就是把在结果页面上需要的数据放到ModelAndView对象中即可）
>
> 其作用类似于request对象的setAttribute方法的作用，用来在一个请求过程中传递处理的数据。

```java
public ModelAndView addObject(String attributeName, Object attributeValue){...}
public ModelAndView addObject(Object attributeValue){...}
```





# MySQL

## 范式

> #### 第一范式 原子性
>
> > 数据库中的每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性
>
> #### 第二范式 完全依赖主键
>
> > 数据库的每个实例或行必须可以被唯一的区分，即表中要有一列属性可以将实体完全区分，这个属性就是主键，即每一个属性完全依赖于主键
> >
> > 完全依赖概念：即非主属性不能依赖于主键的部分属性，必须依赖于主键的所有属性。
>
> #### 第三范式 不存在函数依赖
>
> > 属性不依赖与其他非主属性，也就是说，如果存在非主属性对于码的传递函数依赖，则不符合第三范式

## 数据类型

### char与varchar

> varchar是**变长**字符串 比定长类型更省空间
>
> 用1-2个额外字节存储字符串长度
>
> 超出设置长度部分 会截断 因为变长存取慢 省空间

> char是**定长** 更具定义的字符串长度分配足够空间
>
> 超出设置长度部分 会截断 因为定长存取快 可能浪费空间

> 经常变更的列 使用char比使用varchar好 不容易产生碎片
>
> 非常短的列 char比varchar存储上更有效率
>
> 使用时 只分配需要的空间 更长的列在排序时会消耗更多的内存

### timestamp和datetime

> 尽量使用timestamp 其空间效率高于datetime



## Innodb引擎 MyISAM引擎

> Innodb支持**行锁 表锁**
>
> MyISAM支持**表锁**

> Innodb支持**事务**
>
> MyISAM不支持**事务**

> Innodb对于 增删改更快
>
> MyISAM对于查找更快

> Innodb索引是**聚簇索引**
>
> MyISAM是**非聚簇索引**

> Innodb主键索引的叶子节点存储**行数据** 主键索引非常高效
>
> MyISAM索引叶子节点存储的**行数据地址** 需要再寻址一次才能得到数据



## 聚集索引 非聚集索引

> *聚簇索引中 主键索引页节点保存所有的数据 辅助索引叶节点则是主键的值（可以通过覆盖索引 避免回表）*
>
> *非聚簇索引中 主键索引和辅助键索引叶节点都是数据的地址*

![img](https://img2018.cnblogs.com/i-beta/1464190/201911/1464190-20191106151527647-152458631.png)

### 聚簇索引

> **聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分；**

> **我们日常工作中，根据实际情况自行添加的索引都是辅助索引，辅助索引就是一个为了需找主键索引的二级索引，现在找到主键索引再通过主键索引找数据；**

#### 优点

> 1.数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快
>
> 2.聚簇索引对于主键的排序查找和范围查找速度非常快

#### 缺点

> 1.插入速度严重依赖于插入顺序，按照主键的**顺序插入**是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个**自增的ID列为主键**
> 2.**更新主键的代价很高**，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。
> 3.二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。

#### 查询过程

> InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上，若使用"where id = 14"这样的条件查找主键，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。若对Name列进行条件搜索，则需要两个步骤：第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。第二步使用主键在主索引B+树种再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。

### 非聚簇索引

> 使用B+Tree作为索引结构，叶节点的**data域存放的是数据记录的地址**
>
> 主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，这两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。



## 索引的数据结构

### B+树索引

> #### n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。
>
> 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
>
> 所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
>
> B+ 树中，数据对象的插入和删除仅在叶节点上进行。
>
> B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。

### 哈希索引

> 将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。

## 索引的使用

### 最左匹配原则

> 组合索引非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，在查询的where中 a,b,d的顺序可以任意调整。索引的顺序和建立有关，和where中顺序无关。

> =可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式

> like 需要 左侧保证无通配符 whn%



## 创建索引原则

> 2）较频繁作为查询条件的字段才去创建索引
>
> 3）更新频繁字段不适合创建索引
>
> 4）若是不能有效区分数据的列不适合做索引列(如性别，男女未知，最多也就三种，区分度实在太低)
>
> 5）尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。
>
> 6）定义有外键的数据列一定要建立索引。
>
> 7）对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。
>
> 8）对于定义为text、image和bit的数据类型的列不要建立索引。

## 索引的下推和覆盖

> > 索引的下推
> >
> > ​	可以在索引遍历过程中，**对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表字数**。
>
> ```mysql
> select * from tuser 
> where name like '张 %' and age=10 and ismale=1;
> ```
>
> 该语句在搜索索引树的时候，只能匹配到名字第一个字是‘张’的记录（即记录ID3）接下来是怎么处理的呢？当然就是从ID3开始，逐个回表，到主键索引上找出相应的记录，再比对age和ismale这两个字段的值是否符合。
>
> 索引下推优化后，可以在索引遍历过程中，**对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表字数**。
>
> ![img](https://upload-images.jianshu.io/upload_images/6271376-e4e98a8af8fc9ca8.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1142/format/webp)
>
> ![](https://upload-images.jianshu.io/upload_images/6271376-53f9161adfddeb10.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1142/format/webp)
>
> > 索引的覆盖
> >
> > ​	只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快。
> >
> > explain的输出结果Extra字段为Using index时，能够触发索引覆盖。

## B树B+树的比较

> - 在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。
> - B+树的叶子节点有一条链相连，而B树的叶子节点各自独立。

### 使用B树好处

> B树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近根节点的地方将会大大提高**热点数据**的查询效率。这种特性使得B树在特定数据重复多次查询的场景中更加高效。

### 使用B+树的好处

> 由于B+树的内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。 B+树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B+树只需要使用O(logN)时间找到最小的一个节点，然后通过链进行O(N)的顺序遍历即可。



## 事务四大特性ACID

> **原子性**： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
> **一致性**： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
> **隔离性**： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
> **持久性**： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

## 脏读 幻读 不可重复读

> **脏读(Drity Read)**：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。（读取到另一个事务没有提交的数据）
> **不可重复读**(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。（同一事务中 两次读取结果不一）
> **幻读(Phantom Read)**:在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。（）

## 事务隔离级别

| 隔离级别         | 脏读 | 不可重复读 | 幻影读 |
| ---------------- | ---- | ---------- | ------ |
| READ-UNCOMMITTED | √    | √          | √      |
| READ-COMMITTED   | ×    | √          | √      |
| REPEATABLE-READ  | ×    | ×          | √      |
| SERIALIZABLE     | ×    | ×          | ×      |

> READ-UNCOMMITTED**(读取未提交)**： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
> READ-COMMITTED**(读取已提交)**： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。（基于查询加共享锁，查询结束后释放锁 ）
> REPEATABLE-READ**(可重复读)**： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
> SERIALIZABLE**(可串行化)**： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

## MVCC简介

> MVCC多版本并发控制(Multi-Version Concurrency Control)是MySQL中**基于乐观锁理论实现隔离级别**的方式，用于实现读已提交和可重复读取隔离级别。
>
> 这项技术使得InnoDB的事务隔离级别下执行一致性读操作有了保证，换言之，就是**为了查询一些正在被另一个事务更新的行**，并且可以看到它们被更新之前的值。这是一个可以用来增强并发性的强大的技术，因为这样的一来的话查询就**不用等待另一个事务释放锁**。
>
> 核心是在每一行隐藏了两个字段，用于表示版本号。
>
> - **SELECT**
>   - **读取创建版本小于或等于当前事务版本号，并且删除版本为空或大于当前事务版本号的记录。这样可以保证在读取之前记录是存在的。**
> - **INSERT**
>   - **将当前事务的版本号保存至行的创建版本号**
> - **UPDATE**
>   - **新插入一行，并以当前事务的版本号作为新行的创建版本号，同时将原记录行的删除版本号设置为当前事务版本号**
>   - **修改的时候一定不是快照读，而是当前读。**
> - **DELETE**
>   - **将当前事务的版本号保存至行的删除版本号**
> - 只有普通的SELECT才是快照读，其它诸如UPDATE、删除都是当前读。
> - 修改的时候一定不是快照读，而是当前读。

## 各种隔离级别的实现 使用的协议（一致性读+锁）

> **一致性读**：InnoDB用多版本来提供查询数据库在**某个时间点的快照**。一致性读不会给它所访问的表加任何形式的锁，因此其它事务可以同时并发的修改它们。
>
> 可重复读：
>
> ​	如果隔离级别是REPEATABLE READ，那么在同一个事务中的所有一致性读都读的是事务中第一个这样的读读到的快照；
>
> 读已提交：
>
> ​	如果是READ COMMITTED，那么一个事务中的每一个一致性读都会读到它自己刷新的快照版本。
>
> 幻读：
>
> ​	利用Gap Locks间隙锁和Next-Key可以阻止其它事务在锁定区间内插入数据，因此解决了幻读问题

##### 通过MVCC实现一致性非锁定读，这就有保证在同一个事务中多次读取相同的数据返回的结果是一样的，解决了不可重复读的问题

##### 利用Gap Locks和Next-Key可以阻止其它事务在锁定区间内插入数据，因此解决了幻读问题



## 隔离级别与锁的关系

> 在**Read Uncommitted**级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突
>
> 在**Read Committed**级别下，读操作需要加**共享锁**，但是在**语句执行完**以后释放共享锁；
>
> 在**Repeatable Read**级别下，读操作需要加**共享锁**，但是在事务提交之前并不释放共享锁，也就是必须等待**事务执行完毕**以后才释放共享锁。
>
> **SERIALIZABLE** 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。



## 锁的粒度分数据库锁有哪些？

> MyISAM和InnoDB存储引擎使用的锁：
>
> **MyISAM采用表级锁(table-level locking)。**
> **InnoDB**支持行级锁(row-level locking)和表级锁，**默认为行级锁**
>
> **行级锁** 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。
>
> 特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
>
> **表级锁** 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。
>
> 特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。
>
> **页级锁** 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。
>
> 特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

## InnoDB存储引擎的锁的算法有三种

> **Record lock：单个行记录上的锁**
> **Gap lock：间隙锁，锁定一个范围，不包括记录本身**
> **Next-key lock：record+gap 锁定一个范围，包含记录本身**

> innodb对于行的查询使用next-key lock
> Next-locking keying为了解决Phantom Problem**幻读**问题
> 当查询的索引含有唯一属性时，将next-key lock降级为record key
> Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内
> 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1
>
> for update时，锁的使用是基于索引的，如果查询的字段不是索引键那么将退化为表锁

## 视图

### 什么是视图

> 视图（view）是一种虚拟存在的表，是一个逻辑表，本身并不包含数据。作为一个select语句保存在数据字典中的。
>
> 通过视图，可以展现基表的部分数据；视图数据来自定义视图的查询中使用的表，使用视图动态生成。

### 视图优点

> 1）简单：使用视图的用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。
>
> 2）安全：使用视图的用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单的实现。
>
> 3）数据独立：一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响。



# 并发编程

## 并发与并行

> **并发**：多个任务在同一个 CPU 核上，按细分的时间片轮流(交替)执行，从逻辑上来看那些任务是同时执行。
> **并行**：单位时间内，多个处理器或多核处理器同时处理多个任务，是真正意义上的“同时进行”。
> **串行**：有n个任务，由一个线程按顺序执行。由于任务、方法都在一个线程执行所以不存在线程不安全情况，也就不存在临界区的问题。

## 进程与线程

### 定义

> 进程
>
> 一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程

> 线程
>
> 进程中的一个执行任务（控制单元），负责当前进程中程序的执行。一个进程至少有一个线程，一个进程可以运行多个线程，多个线程可共享数据。

## 进程线程区别

> **根本区别**：进程是操作系统**资源分配的基本单位**，而线程是处理器**任务调度和执行的基本单位**
>
> **资源开销**：每个**进程都有独立的代码和数据空间**（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，**每个线程都有自己独立的运行栈和程序计数器**（PC），线程之间切换的开销小。
>
> **包含关系**：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。
>
> **内存分配**：同一进程的**线程共享本进程的地址空间和资源**，而进程之间的地址空间和资源是相互独立的
>
> **影响关系**：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以**多进程要比多线程健壮**。
>
> **执行过程**：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

## 死锁的必要条件

> **互斥条件**：线程(进程)对于所分配到的资源具有排它性，即一个资源只能被一个线程(进程)占用，直到被该线程(进程)释放
> **请求与保持条件**：一个线程(进程)因请求被占用资源而发生阻塞时，对已获得的资源保持不放。
> **不剥夺条件**：线程(进程)已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
> **循环等待条件**：当发生死锁时，所等待的线程(进程)必定会形成一个环路（类似于死循环），造成永久阻塞

## 避免死锁

### **破坏请求与保持条件**

> 一次性**申请所有**的资源。

### **破坏不剥夺条件**

> 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以**主动释放**它占有的资源。

### **破坏循环等待条件**

> 靠按序申请资源来预防。按**某一顺序**申请资源，释放资源则反序释放。破坏循环等待条件。

## 为什么不能直接调用run方法

> new 一个 Thread，线程进入了新建状态。调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。
>
> 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。
>
> 总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。

## 线程生命周期

![线程的基本状态](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxNy8xMi8xNS8xNjA1OWNjOTFlZThlZmIz?x-oss-process=image/format,png)

## <u>线程同步的方式</u>

#### object的wait notify 

> 需要阻塞
>
> JVM会为一个使用内部锁（synchronized）的对象维护两个集合，**Entry Set**和**Wait Set**
>
> 对于Entry Set：如果线程A已经持有了对象锁，此时如果有其他线程也想获得该对象锁的话，它只能进入Entry Set，并且处于线程的BLOCKED状态。
>
> 对于Wait Set：如果线程A调用了wait()方法，那么线程A会释放该对象的锁，进入到Wait Set，并且处于线程的WAITING状态。
>
> 某个线程B想要获得对象锁，一般情况下有两个先决条件，一是对象锁已经被释放了（如曾经持有锁的前任线程A执行完了synchronized代码块或者调用了wait()方法等等），二是线程B已处于RUNNABLE状态。
>
> 对于Entry Set中的线程，当对象锁被释放的时候，JVM会唤醒处于Entry Set中的某一个线程，这个线程的状态就从BLOCKED转变为RUNNABLE。
>
> 对于Wait Set中的线程，当对象的notify()方法被调用时，JVM会唤醒处于Wait Set中的某一个线程，这个线程的状态就从WAITING转变为RUNNABLE；或者当notifyAll()方法被调用时，Wait Set中的全部线程会转变为RUNNABLE状态。所有Wait Set中被唤醒的线程会被转移到Entry Set中。

```java
	static class A extends Thread {
        public void run() {
            while (true) {
                synchronized (lockA){
                    System.out.print("A");
                    lockA.notify();
                    try {
                        lockA.wait();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        }
    }
```

> 此处交替输出AB所以使用一个锁来限制



#### 简单的显式lock的方式 和信号量方式类似

```java
	static Lock lock = new ReentrantLock();
    static Integer i = new Integer(3);

    static class A extends Thread {
        public void run() {
            while (true) {
                lock.lock();
                while (i % 3 == 0) {
                    System.out.print("a");
                    i++;
                }
                lock.unlock();
            }
        }
    }
```



#### condition的await和signal

```java
	static Lock lock = new ReentrantLock();
    static Condition a=lock.newCondition();
    static Condition b=lock.newCondition();
    static Condition c=lock.newCondition();
```

> 通过lock来创建不同的condition 每个condition类似于对应某个输出
>
> await对应wait  signal对应notify signalAll对应notifyAll

```java
	static class A extends Thread {
        public void run() {
            while (true) {
                lock.lock();
                while (i % 3 != 0) {
                    try {
                        a.await();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                i++;
                System.out.print("a");
                b.signal();
                lock.unlock();
            }
        }
    }
```

##### condition原理 

*（AQS维护blocked condition维护一个waiting的FIFO队列）*

> 我们知道Lock的本质是AQS，AQS自己维护的队列是当前等待资源的队列，AQS会在资源被释放后，依次唤醒队列中从前到后的所有节点，使他们对应的线程恢复执行，直到队列为空。而Condition自己也维护了一个队列，该队列的作用是维护一个等待signal信号的队列。但是，两个队列的作用不同的，事实上，每个线程也仅仅会同时存在以上两个队列中的一个，流程是这样的：
>
> \1. 线程1调用reentrantLock.lock时，尝试获取锁。如果成功，则返回，从AQS的队列中移除线程；否则阻塞，保持在AQS的等待队列中。
> \2. 线程1调用await方法被调用时，对应操作是被加入到Condition的等待队列中，等待signal信号；同时释放锁。
> \3. 锁被释放后，会唤醒AQS队列中的头结点，所以线程2会获取到锁。
> \4. 线程2调用signal方法，这个时候Condition的等待队列中只有线程1一个节点，于是它被取出来，并被加入到AQS的等待队列中。注意，这个时候，线程1 并没有被唤醒，只是被加入AQS等待队列。
> \5. signal方法执行完毕，线程2调用unLock()方法，释放锁。这个时候因为AQS中只有线程1，于是，线程1被唤醒，线程1恢复执行。
> 所以：
> 发送signal信号只是将Condition队列中的线程加到AQS的等待队列中。只有到发送signal信号的线程调用reentrantLock.unlock()释放锁后，这些线程才会被唤醒。
>
> 可以看到，整个协作过程是靠结点在AQS的等待队列和Condition的等待队列中来回移动实现的，Condition作为一个条件类，很好的自己维护了一个等待信号的队列，并在适时的时候将结点加入到AQS的等待队列中来实现的唤醒操作。

#### Semaphore信号量

> 类似于同步信号量的形式，更加方便操作

```java
	static Semaphore a=new Semaphore(1);
    static Semaphore b=new Semaphore(0);
    static class A extends Thread{
        public void run(){
            while(true) {
                try {
                    a.acquire();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.print("a");
                b.release();
            }
        }
    }
    static class B extends Thread{
        public void run(){
            while(true) {

                try {
                    sleep(100);
                    b.acquire();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("b");
                a.release();
            }
        }
    }
    static class C extends Thread{
        public void run(){
            while(true) {
                try {
                    sleep(100);
                    b.acquire();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("c");
                a.release();
            }
        }
    }
```

> 交替输出AB 或 AC

## 如何暂停线程的运行

> （1）线程体中调用了 **yield 方法**让出了对 cpu 的占用权利（由运行态转到就绪态）
>
> （2）线程体中调用了 sleep 方法使线程进入睡眠状态
>
> （3）线程由于 IO 操作受到阻塞
>
> （4）另外一个更高优先级线程出现
>
> （5）在支持时间片的系统中，该线程的时间片用完

## 如何停止一个正在运行的线程

> 1. 使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。
> 2. 使用**stop方法**强行终止，但是不推荐这个方法，因为stop和suspend及resume一样都是过期作废的方法。
> 3. 使用**interrupt方法**中断线程。

## sleep和wait的区别

> 类的不同：sleep() 是 Thread线程类的静态方法，wait() 是 Object类的方法。
>
> 是否释放锁：sleep() 不释放锁；wait() 释放锁。且wait要结合锁使用
>
> 用途不同：Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。
>
> 用法不同：wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用wait(long timeout)超时后线程会自动苏醒。

## 如何实现多线程之间的通讯和协作？

### 通信协作

> 一.syncrhoized加锁的线程的**Object类**的wait()/notify()/notifyAll()
>
> 二.ReentrantLock类加锁的线程的**Condition类的**await()/signal()/signalAll()

### 直接数据交换

> 三.通过**管道**进行线程间通信：1）字节流；2）字符流

## 进程通信的方式

| 通信方法               | 无法介于内核态与用户态的原因         |
| ---------------------- | ------------------------------------ |
| 管道（不包括命名管道） | 局限于父子进程间的通信。             |
| 消息队列               | 在硬、软中断中无法无阻塞地接收数据。 |
| 信号量                 | 无法介于内核态和用户态使用。         |
| 共享内存               | 需要信号量辅助，而信号量又无法使用。 |

## Synchronized底层实现原理

> 一个线程也执行同步代码块，首先要获取锁，而获取锁的过程就是monitorenter ，在执行完代码块之后，要释放锁，释放锁就是执行monitorexit指令。

## Synchronized可重入的原理

> 重入锁是指一个线程获取到该锁之后，该线程可以继续获得该锁。底层原理维护一个计数器，当线程获取该锁时，计数器加一，再次获得该锁时继续加一，释放锁时，计数器减一，当计数器值为0时，表明该锁未被任何线程所持有，其它线程可以竞争获取锁。

## Synchronized加锁的范围

>  **锁定某一特定对象**
>
> 加在非静态方法 或 synchronized(this)
>
> **锁定某个类的所有对象**
>
> 夹在静态方法 或 synchronized(A.class) （如双重检验单例）



## Synchronized和Reentrantlock的区别

### Api层面

> synchronized可以修饰方法 代码块 对象 基于原语 必须显示的进行加锁 隐式的进行解锁 是否成功获得锁并不知道
>
> reentrantlock修饰代码块 基于API 显示的进行加锁 释放 只能修饰代码块，必须显式的进行加锁解锁。

### 等待可中断

> 使用synchronized。如果Thread1不释放，Thread2将一直等待，不能被中断
>
> 使用ReentrantLock。如果Thread1不释放，Thread2等待了很长时间以后，可以中断等待，转而去做别的事情。

### 公平锁

> synchronized的锁是非公平锁，ReentrantLock默认情况下也是非公平锁，但可以通过带布尔值的构造函数要求使用公平锁。

### 绑定多个条件

> ReentrantLock可以同时绑定多个Condition对象，只需多次调用newCondition方法即可。
>
> synchronized中，锁对象的wait和notify() 或notifyAll()方法可以实现一个隐含的条件。但如果要和多于一个的条件关联的时候就不得不额外添加一个锁。

### 相同点

> 都是可重入的。可重入值的是同一个线程多次试图获取它所占的锁，请求会成功。当释放的时候，直到冲入次数清零，锁才释放。

## volatile作用

>  volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。
>
> **防止指令重排序**
>
> **线程可见性**

### ps 原子类如何保证原子性

> 通过volatile和自选保证数据的原子性

## 双重检验volatile单例中的作用

> 防止指令重排，可能会出现半初始化的对象被单例使用

## AQS

> AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。

### 核心思想

> **AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。**
>
> **![AQS原理图](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8xMS8yNS8xNmVhMDQ3Njc4NGNkMzJi?x-oss-process=image/format,png)**

### **AQS 对资源的共享方式**

> **独占**：只有一个线程能执行，如ReentrantLock。
>
> **共享**：多个线程可同时执行，如Semaphore/CountDownLatch

### 可重入的实现

> **1在线程获取锁的时候，如果已经获取锁的线程是当前线程的话则直接再次获取成功**
>
> **2由于锁会被获取n次，那么只有锁在被释放同样的n次之后，该锁才算是完全释放成功**。

## ConcurrentHashMap

### HashMap线程不安全

> 1.7以前使用头插法 会导致桶内形成循环链表在 扩容时可能导致插入的数据丢失
>
> 1.8后改进了头插法 但可能在多线程环境下 遇见相同hash值的数据插入 导致数据丢失

### Hashtable线程安全但效率低下

> Hashtable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下Hashtable的效率非常低下。因为当一个线程访问Hashtable的同步方法时，其他线程访问Hashtable的同步方法时，可能会进入阻塞或轮询状态。

### ConcurrentHashMap原理

> 在1.7之前 concurrentHashMap使用的是分段锁，可以满足分段数量的并发度
>
> ConcurrentHashMap 定位一个元素的过程需要进行两次Hash操作，第一次 Hash 定位到 Segment，第二次 Hash 定位到元素所在的链表的头部，因此，这一种结构的带来的副作用是 Hash 的过程要比普通的 HashMap 要长，但是带来的好处是写操作的时候可以只对元素所在的 Segment 进行操作即可，不会影响到其他的 Segment。其中分段锁的实现是通过**自旋**的方式实现的。
>
> ![img](https://images2018.cnblogs.com/blog/1202638/201808/1202638-20180814213921035-778397290.png)

> 1.8中抛弃了分段锁的概念。而是启用了一种全新的方式实现，利用 **CAS 算法**以及**synchronized**。底层依然由“数组”+链表+红黑树的方式思想
>
> 锁的粒度就是HashEntry（首节点）。put时先扩容，如果没有出现hash碰撞则采用CAS自旋的方式进行插入。如果出现了hash冲突，则对这个链表或红黑树的头节点进行加synchronized锁

### 1.7 1.8版本对比

> 其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树,相对而言，总结如下思考
>
> 1. JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点）
> 2. JDK1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了
> 3. JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档

## <u>ThreadLocal软引用</u>

> **强引用**：只有当没有引用指向该对象才会进行gc
>
> **软引用**：只有在堆空间满后才会在gc时回收
>
> **软引用**：被gc时会就会被回收u
>
> ThreadLocal作为线程私有属性 thread中会有一个强引用指向threadlocal对象
>
> threadlocal的本质是thread本身维护一个map，其中键为弱引用的threadlocak 值为object
>
> 之所以使用软引用是防止在thread对象的强引用消除后，仍有key指针指向threadlocal导致空间无法回收
>
> 但是即使使用了弱引用后，仍有可能需要remove来消除这条记录

> - 

## ThreadLocal内存泄漏问题

> ThreadLocalMap 中使用的 key 为 ThreadLocal 的**弱引用**,而 value 是**强引用**。所以，**如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。**这样一来，ThreadLocalMap 中就会**出现key为null的Entry**。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法

## 为什么ThreadLocalMap中Entry的key的引用是弱引用

> 在方法中新建一个ThreadLocal对象，就有一个强引用指向它，在调用set（）后，线程的ThreadLocalMap对象里的Entry对象又有一个引用 k 指向它。如果后面这个引用 k 是强引用就会使方法执行完，栈帧中的强引用销毁了，对象还不能回收，造成严重的内存泄露。

## 阻塞队列BlockingQueue

> 阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。
>
> 这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。

### JDK7提供的阻塞队列

> ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。
>
> LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。
>
> PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。
>
> DelayQueue：一个使用优先级队列实现的无界阻塞队列。
>
> SynchronousQueue：一个不存储元素的阻塞队列。
>
> LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
>
> LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。
>
> **阻塞队列中加锁基本通过reentrantlock实现**

## 线程池

> 提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。

### 常见的线程池静态工厂方法

> （1）**newSingleThreadExecutor**：创建一个**单线程**的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个**新的线程来替代它**。此线程池保证所有任务的**执行顺序按照任务的提交顺序**执行。
>
> （2）**newFixedThreadPool**：创建**固定大小的线程池**。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。**如果希望在服务器上使用线程池，建议使用 newFixedThreadPool方法来创建线程池，这样能获得更好的性能。**
>
> （3） **newCachedThreadPool**：创建一个可缓存的线程池。如果**线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲**（60 秒不执行任务）**的线程**，**当任务数增加时，此线程池又可以智能的添加新线程来处理任务。**此线程池不会对线程池大小做限制，**线程池大小完全依赖于操作系统**（或者说 JVM）能够创建的最大线程大小。
>
> （4）**newScheduledThreadPool**：创建一个**大小无限的线程池**。此线程池支持定时以及周期性执行任务的需求。

### 优点

> **降低资源消耗**：重用存在的线程，减少对象创建销毁的开销。
>
> **提高响应速度**。可**有效的控制最大并发线程数**，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
>
> **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行**统一的分配，调优和监控**。
>
> **附加功能**：提供定时执行、定期执行、单线程、并发数控制等功能。

### 核心参数

> ​	**corePoolSize核心线程池大小**
>
> ​	当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，也会通过创建一个新线程来执行该任务，直到已创建的线程数大于或等于corePoolSize时

> ​	**maximumPoolSize线程池最大大小**
>
> ​	线程池所允许的最大线程个数。当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。**无界队列此参数无效**

> ​	**keepAliveTime线程存活保持时间**
>
> ​	当线程池中线程数大于核心线程数时，线程的空闲时间如果超过线程存活时间，那么这个线程就会被销毁，直到线程池中的线程数小于等于核心线程数。

> ​	**workQueue任务队列**
>
> ​	用于传输和保存等待执行任务的阻塞队列

> ​	**threadFactory线程工厂**
>
> ​	用于创建新线程。threadFactory创建的线程也是采用new Thread()方式

> ​	**handler线程饱和策略**
>
> ​	当线程池和队列都满了，再加入线程会执行此策略

### <u>为什么使用阻塞队列</u>

> 1 使用队列可以限制线程无限制的创建，避免因为内存占用导致的oom问题
>
> 2 阻塞队列可以保证任务队列中没有任务时阻塞获取任务的线程，使得线程进入wait状态，释放cpu资源。当队列中有任务时才唤醒对应线程从队列中取出消息进行执行。

### <u>如何关闭一个线程池</u>

> shutdownnow
>
> shutdown

### <u>如何确定一个线程池的参数 设置是合理的</u>

#### CPU密集型任务

> 尽量使用较小的线程池，一般为CPU核心数+1。 因为CPU密集型任务使得CPU使用率很高，若开过多的线程数，会造成CPU过度切换。

#### IO密集型任务

> 可以使用稍大的线程池，一般为2*CPU核心数。 IO密集型任务CPU使用率并不高，因此可以让CPU在等待IO的时候有其他线程去处理别的任务，充分利用CPU时间。

#### 混合型任务

> 可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。 只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。

### <u>Java中的线程池</u>

![](https://upload-images.jianshu.io/upload_images/6024478-9e47d2796c8ab1aa.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

#### newCachedThreadPool

> 用来创建一个可以无限扩大的线程池，适用于负载较轻的场景，执行短期异步任务。（可以使得任务快速得到执行，因为任务时间执行短，可以很快结束，也不会造成cpu过度切换）
>
> **可能会因为创建线程过多导致oom**

#### newFixedThreadPool

> 创建一个固定大小的线程池，因为采用无界的阻塞队列，所以实际线程数量永远不会变化，适用于负载较重的场景，对当前线程数量进行限制。（保证线程数可控，不会造成线程过多，导致系统负载更为严重）
>
> **可能因为等待队列中过长导致oom**

#### newScheduledThreadPool

> 适用于执行延时或者周期性任务。

#### newSingleThreadExecutor

> 创建一个单线程的线程池，适用于需要保证顺序执行各个任务。
>
> **可能因为等待队列中过长导致oom**

### <u>线程池中使用的阻塞工作队列</u>

#### LinkedBlockingQueue

> 三种构造函数
>
> > ​	LinkedBlockingQueue() 无参构造函数，链表长度为Integer.MAX_VALUE
> >
> > ​	LinkedBlockingQueue(int capacity) 指定capacity长度
> >
> > ​	LinkedBlockingQueue(Collection c) 不指定长度，即默认长度为Integer.MAX_VALUE，提供初始化元素
>
> 特点：
>
> > ​	链表节点由Node对象组成，每个Node有item变量用于存储元素，next变量指向下一个节点
> >
> > 执行put的时候，将元素放到链表尾部节点；take的时候从头部取元素
> >
> > 两种操作分别有一个锁putLock, takeLock,互不影响,可以同时进行

#### ArrayBlockingQueue

> 三种构造函数
>
> > ​	ArrayBlockingQueue(int capacity) 指定长度
> >
> > ​	ArrayBlockingQueue(int capacity, boolean fair) 指定长度，及指定是否使用FIFO顺序进出队列
> >
> > ​	ArrayBlockingQueue(int capacity, boolean fair, Collection c) 指定长度，进行队列顺序，初始元素
>
> 特点：
>
> > ​	ArrayBlockingQueue必须指定初始化长度，如果线程池使用该队列，指定长度大了浪费内存，长度小队列并发性不高，在数组满的时候，put操作只能阻塞等待，或者返回false
> >
> > ArrayBlockingQueue 只定义了一个Lock，put和take使用同一锁，不能同时进行

#### SynchronousQueue

> 内部并没有数据缓存空间
>
> 队列头元素是第一个排队要插入数据的**线程**，而不是要交换的数据。数据是在配对的生产者和消费者线程之间直接传递的，并不会将数据缓冲数据到队列中。
>
> 线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。

![](https://upload-images.jianshu.io/upload_images/16015500-8bf4856f92829bdc.png?imageMogr2/auto-orient/strip|imageView2/2/w/948/format/webp)

### <u>**饱和策略**</u>

> > - ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。**抛出异常拒绝**
> > - ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。**增加队列容量运行**
> > - ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。**直接丢弃**
> > - ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。**丢弃等待最久的**

![图解线程池实现原理](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS8xMS8yNS8xNmVhMDQ3NjEyOTVlNzY2?x-oss-process=image/format,png)

## 原子操作类

> 原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。
>
> 处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。在 Java 中可以通过锁和循环 CAS 的方式来实现原子操作。

> i++的本质是三步操作 **并非是原子操作**
> 1 从内存中将i的值读取到cpu寄存器中
> 2 将i的值+1
> 3 将修改后的i的值 写入内存

> java.util.concurrent 这个包里面提供了一组原子类。其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由 JVM 从等待队列中选择另一个线程进入，这只是一种逻辑上的理解。
>
> AtomicInteger 类主要**利用 CAS** (compare and swap) + **volatile** 和 **native 方法**来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。
>
> CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是**用来拿到“原来的值”的内存地址**，返回值是 valueOffset。另外 **value 是一个volatile变量**，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。



# Linux

## linux体系结构

![linux体系结构](https://img-blog.csdnimg.cn/20200229173922281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RoaW5rV29u,size_16,color_FFFFFF,t_70)

> **用户空间**(User Space) ：用户空间又包括用户的应用程序(User Applications)、C 库(C Library) 。
>
> **内核空间**(Kernel Space) ：内核空间又包括**系统调用接口**(System Call Interface)、**内核**(Kernel)、**平台架构相关的代码**(Architecture-Dependent Kernel Code) 。

## 两种条件下完成从用户态到内核态的转移

> 系统调用
>
> 硬件中断

## 硬链接 软链接

> ### **硬链接**
>
> 由于 Linux 下的文件是通过索引节点(inode)来识别文件，硬链接可以认为是一个**指针**，指向**文件索引节点的指针**，系统并**不为它重新分配 inode** 。每添加一个一个硬链接，文件的链接数就加 1 。
>
> 不足：1）不可以在不同文件系统的文件间建立链接；2）只有超级用户才可以为目录创建硬链接。

> ### 软链接
>
> 软链接克服了硬链接的不足，**没有任何文件系统的限制**，任何用户可以创建指向目录的符号链接。因而现在更为广泛使用，它具有更大的灵活性，甚至可以**跨越不同机器、不同网络**对文件进行链接。
>
> 不足：因为**链接文件包含有原文件的路径信息**，所以当原文件从一个目录下移到其他目录中，再访问链接文件，系统就找不到了，而硬链接就没有这个缺陷，你想怎么移就怎么移；还有它要系统分配额外的空间用于建立新的索引节点和保存原文件的路径。

## 虚拟内存 驻留内存 共享内存

![t1](http://www.bo56.com/wp-content/uploads/2013/08/t1.png)

> **虚拟内存**是操作系统内核为了对进程地址空间进行管理（process address space management）而精心设计的一个**逻辑意义上的内存空间概念**。我们程序中的指针其实都是这个虚拟内存空间中的地址。
>
> 凡是程序运行过程中可能需要用到的指令或者数据都必须在虚拟内存空间中。既然说虚拟内存是一个逻辑意义上（假象的）的内存空间，为了能够让程序在物理机器上运行，那么必须有一套机制可以让这些假象的虚拟内存空间映射到物理内存空间（实实在在的RAM内存条上的空间）。这其实就是操作系统中**页映射表**（page table）所做的事情了。内核会为系统中每一个进程维护一份相互独立的页映射表。。页映射表的基本原理是将程序运行过程中需要访问的一段虚拟内存空间通过页映射表映射到一段物理内存空间上，这样CPU访问对应虚拟内存地址的时候就可以通过这种查找页映射表的机制访问物理内存上的某个对应的地址。**“页（page）”是虚拟内存空间向物理内存空间映射的基本单元。**（上方两个矩形区域都是虚拟内存）

> **驻留内存**，顾名思义是指那些被映射到进程虚拟内存空间的物理内存。上图1中，在系统物理内存空间中被着色的部分都是驻留内存。比如，A1、A2、A3和A4是进程A的驻留内存；B1、B2和B3是进程B的驻留内存。进程的**驻留内存就是进程实实在在占用的物理内存**。一般我们所讲的进程占用了多少内存，其实就是说的占用了多少驻留内存而不是多少虚拟内存。

> **共享内存**，表示的是进程占用的共享内存大小。在上图1中我们看到进程A虚拟内存空间中的A4和进程B虚拟内存空间中的B3都映射到了物理内存空间的A4/B3部分。为什么会出现这样的情况呢？其实我们写的程序会依赖于很多外部的**动态库**（.so），比如libc.so、libld.so等等。这些动态库在内存中仅仅会保存/映射一份，如果某个进程运行时需要这个动态库，那么动态加载器会将这块内存映射到对应进程的虚拟内存空间中。多个进展之间通过共享内存的方式相互通信也会出现这样的情况。这么一来，就会出现不同进程的虚拟内存空间会映射到相同的物理内存空间。这部分物理内存空间其实是被多个进程所共享的，所以我们将他们称为共享内存，用SHR来表示。某个进程占用的内存除了和别的进程共享的内存之外就是自己的独占内存了。所以要计算进程独占内存的大小只要用RES的值减去SHR值即可。

## linux命令

```
netstat -ntlp   //查看当前所有tcp端口·
```

```
netstat -ntulp |grep 80   //查看所有80端口使用情况·
```

```
netstat -an | grep 3306   //查看所有3306端口使用情况·
```

```
netstat  -lanp	//查看一台服务器上面哪些服务及端口
```

## <u>进程通信的方式</u>

### 管道

> 通常指无名管道
>
> 1. 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。
> 2. 它只能用于具有亲缘关系的进程之间的通信（也是**父子进程或者兄弟进程**之间）。
> 3. 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

### 命名管道

> 也称FIFO 是一种文件类型
>
> 1. FIFO可以在**无关的进程**之间交换数据，与无名管道不同。
> 2. FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。

### 消息队列

> 是消息的链接表，存放在内核中
>
> 1. 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。
> 2. 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。
> 3. 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。

### 信号量

> 它是一个计数器。信号量用于实现进程间的**互斥与同步**，而不是用于存储进程间通信数据
>
> 1. 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。
> 2. 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。
> 3. 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。
> 4. 支持信号量组。

### 共享内存

> 指两个或多个进程共享一个给定的存储区。
>
> 1. 共享内存是最快的一种 IPC，因为进程是直接对内存进行存取。
> 2. 因为多个进程可以同时操作，所以需要进行同步。
> 3. 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。

#### **总结**

> 1.管道：速度慢，容量有限，只有父子进程能通讯   
>
> 2.FIFO：任何进程间都能通讯，但速度慢   
>
> 3.消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题   
>
> 4.信号量：不能传递复杂消息，只能用来同步   
>
> 5.共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存

系统调用内核切换的细节





# 网络

## DNS解析过程

![img](https://img-blog.csdn.net/20171211190812796?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbTBfMzc4MTI1MTM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

> 1 先查询浏览器本地缓存 如果命中直接访问
> 2 查询本地操作系统的存储 如没有 查询host文件中是否对于域名和ip做了绑定
> \3.  如果至此还没有命中域名，才会真正的请求本地域名服务器（LDNS）来解析这个域名，这台服务器一般在你的城市的某个角落，距离你不会很远，并且这台服务器的性能都很好，一般都会缓存域名解析结果，大约80%的域名解析到这里就完成了。
>
> \4. 如果LDNS仍然没有命中，就直接跳到Root Server 域名服务器请求解析
>
> \5. 根域名服务器返回给LDNS一个所查询域的主域名服务器（gTLD Server，国际顶尖域名服务器，如.com .cn .org等）地址
>
> \6. 此时LDNS再发送请求给上一步返回的gTLD
>
> \7. 接受请求的gTLD查找并返回这个域名对应的Name Server的地址，这个Name Server就是网站注册的域名服务器
>
> \8. Name Server根据映射关系表找到目标ip，返回给LDNS
>
> \9. LDNS缓存这个域名和对应的ip
>
> \10. LDNS把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束

## 一个HTTP请求详细过程

### 域名解析

> **DNS域名解析过程**
>
> 如果在hosts文件中也没有找到对应的条目，浏览器就会发起一个**DNS的系统调用**，就会向本地配置的首选DNS服务器（一般是电信运营商提供的，也可以使用像Google提供的DNS服务器）发起域名解析请求（通过的是UDP协议向DNS的53端口发起请求，这个请求是递归的请求，也就是运营商的DNS服务器必须得提供给我们该域名的IP地址），运营商的DNS服务器首**先查找自身的缓存，找到对应的条目，且没有过期，则解析成功**。如果没有找到对应的条目，则有运营商的DNS代我们的浏览器发起迭代DNS解析请求，它首先是会**找根域的DNS的IP地址**（这个DNS服务器都内置13台根域的DNS的IP地址），找打根域的DNS地址，就会向其发起请求（请问www.cnblogs.com这个域名的IP地址是多少啊？），根域发现这是一个顶级域**com域的一个域名**，于是就告诉运营商的DNS我不知道这个域名的IP地址，但是我知道com域的IP地址，你去找它去，于是运营商的DNS就得到了com域的IP地址，又**向com域的IP地址发起了请求**（请问www.cnblogs.com这个域名的IP地址是多少?）,com域这台服务器告诉运营商的DNS我不知道www.cnblogs.com这个域名的IP地址，但是我知道cnblogs.com这个域的DNS地址，你去找它去，于是运营商的DNS又向cnblogs.com这个域名的DNS地址（这个一般就是由域名注册商提供的，像万网，新网等）发起请求（请问www.cnblogs.com这个域名的IP地址是多少？），这个时候cnblogs.com域的DNS服务器一查，诶，果真在我这里，于是就把找到的结果发送给运营商的DNS服务器，这个时候运营商的DNS服务器就拿到了www.cnblogs.com这个域名对应的IP地址，并返回给Windows系统内核，内核又把结果返回给浏览器，终于浏览器拿到了www.cnblogs.com 对应的IP地址，该进行一步的动作了。
>
> **本地运营商DNS服务器--》根域DNS服务器--》（从根服务器向下）直到找到对应域名对应IP--》交给运营商服务器，进行返回浏览器**

### 与服务器建立连接

#### 三次握手

> **三次握手**
>
> 第一次握手：建立连接时，[客户端](http://baike.baidu.com/view/930.htm)发送[syn](http://baike.baidu.com/view/488528.htm)包（syn=j）到[服务器](http://baike.baidu.com/view/899.htm)，并进入[SYN_SENT](http://baike.baidu.com/view/840439.htm)状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers），表示建立连接。即主机A发送位码为syn＝1，随机产生seq number=1234567的数据包到服务器，主机B由SYN=1知道，A要求建立联机；
>
> 第二次握手：[服务器](http://baike.baidu.com/view/899.htm)收到[syn](http://baike.baidu.com/view/488528.htm)包，必须确认客户的SYN（[ack](http://baike.baidu.com/view/204040.htm)=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入[SYN_RECV](http://baike.baidu.com/view/1520054.htm)状态；即主机B收到请求后要确认联机信息，向A发送ack number=(主机A的seq+1)，syn=1，ack=1，随机产生seq=7654321的包；
>
> 第三次握手：[客户端](http://baike.baidu.com/view/930.htm)收到[服务](http://baike.baidu.com/view/133203.htm)器的SYN+ACK包，向[服务器](http://baike.baidu.com/view/899.htm)发送确认包ACK([ack](http://baike.baidu.com/view/204040.htm)=k+1），此包发送完毕，客户端和服务器进入[ESTABLISHED](http://baike.baidu.com/view/1137549.htm)（TCP连接成功）状态，完成三次握手，表示响应。即主机A收到后检查ack number是否正确，即第一次发送的seq number+1，以及位码ack是否为1，若正确，主机A会再发送ack number=(主机B的seq+1)，ack=1，主机B收到后确认seq值与ack=1则连接建立成功。

#### 四次挥手

![img](https://img2018.cnblogs.com/blog/1703075/201907/1703075-20190717131606589-451665711.png)

> **四次挥手**
>
> 第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入**FIN_WAIT_1**状态；这表示主机1没有数据要发送给主机2了；
>
> 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入**FIN_WAIT_2**状态；主机2告诉主机1，我“同意”你的关闭请求；
>
> 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入**LAST_ACK**状态；
>
> 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入**TIME_WAIT**状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。

##### 	time_wait状态

> #### **time_wait状态是什么**
>
> 在TCP连接中四次挥手关闭连接时，主动关闭连接的一方（上图中时Client）会在发送最后一条ACK报文后维持一段时长2MSL（MSL指的是数据包在网络中的最大生存时间）的等待时间后才会真正关闭连接到CLOSED状态，该时间段内主动关闭方的状态为TIME_WAIT。
>
> #### **为什么需要time_wait**
>
> **为实现TCP连接的可靠释放**
> 若主动断开连接方（上图中Client）最后一次ACK报文丢失了，会触发被动方（上图中Server）的超时重传机制，Server再次向Client发送FIN+ACK报文，如果Client在发送完最后一次ACK后立即断开连接（没有TIME_WAIT状态），则Server会收到RST=1的报文响应，表示连接建立异常，而此时并非异常，只是正常的关闭连接过程，进而导致Server端不能正常关闭连接。因此，Client必须维护2MSL的等待时间，确保在Server端第二次发送的FIN+ACK被Client正常接收，收到后Client立即发送ACK给Server，并重新启动2MSL计时器。（因为极端情况涉及两次报文传输（Client向Server的ACK，Server向Client的FIN+ACK），所以等待时间为2MSL）
>
> **为使旧的重复数据包在网络中因过期而消失**
> 可能存在一些数据包在传输过程中出现异常而导致严重推迟，而在它到来之前发送方已经重发了该报文，并完成其任务。如果在被推迟的报文未抵达前接收方断开了连接，随后又建立了一个与之前相同IP、Port的连接，而之前被推迟的报文在这时恰好到达，而此时此新连接非彼连接，从而会发生数据错乱，进而导致无法预知的情况。因此必须维持一段等待时间，使迟到的报文在网络中完全消失，并且在等待时间内，因为连接并未关闭，所以不能建立相同四元组的新连接，就不会出现数据错乱。
>
> #### 服务端主动结束从而进入time_wait状态的危害
>
> 大量的文件描述符占据，导致无法接入新的连接
>
> 因为端口（可能是80）还被之前处于TIME_WAIT的连接占用着，如果TIME_WAIT状态维持60秒，60秒服务器都起不来

### 发起HTTP请求

#### HTTP请求报文

> 一个HTTP请求报文由**请求行**（request line）、**请求头部**（header）、**空行**和**请求数据**4个部分组成

> **请求行**分为三个部分：**请求方法**、**请求地址**和**协议版本**
>
> HTTP/1.1 定义的**请求方法**有8种：GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE。
> 最常的两种GET和POST，如果是RESTful接口的话一般会用到GET、POST、DELETE、PUT。
>
> **请求地址**
> URL:统一资源定位符，是一种自愿位置的抽象唯一识别方法。
> 组成：<协议>：//<主机>：<端口>/<路径>
>
> **协议版本**的格式为：HTTP/主版本号.次版本号，常用的有HTTP/1.0和HTTP/1.1

> **请求头部**
> 请求头部为请求报文添加了一些附加信息，由“名/值”对组成，每行一对，名和值之间使用冒号分隔。
>
> > ​		8、Accept
> >
> > 　　告诉WEB服务器自己接受什么介质类型，*/* 表示任何类型，type/* 表示该类型下的所有子类型，type/sub-type。
> >
> > 　　9、Accept-Charset
> >
> > 　　浏览器告诉服务器自己能接收的字符集。
> >
> > 　　10、Accept-Encoding
> >
> > 　　浏览器申明自己接收的编码方法，通常指定压缩方法，是否支持压缩，支持什么压缩方法（gzip，deflate）。
> >
> > 　　11、Accept-Language
> >
> > 　　浏览器申明自己接收的语言。语言跟字符集的区别：中文是语言，中文有多种字符集，比如big5，gb2312，gbk等等。
> >
> > 　　12、**Authorization**
> >
> > 　　当客户端接收到来自WEB服务器的 WWW-Authenticate 响应时，用该头部来回应自己的身份验证信息给WEB服务器。
> >
> > 　　13、If-Match
> >
> > 　　如果对象的 ETag 没有改变，其实也就意味著对象没有改变，才执行请求的动作，获取文档。
> >
> > 　　14、If-None-Match
> >
> > 　　如果对象的 ETag 改变了，其实也就意味著对象也改变了，才执行请求的动作，获取文档。
> >
> > 　　15、If-Modified-Since
> >
> > 　　如果请求的对象在该头部指定的时间之后修改了，才执行请求的动作（比如返回对象），否则返回代码304，告诉浏览器该对象没有修改。例如：If-Modified-Since：Thu, 10 Apr 2008 09:14:42 GMT
> >
> > 　　16、If-Unmodified-Since
> >
> > 　　如果请求的对象在该头部指定的时间之后没修改过，才执行请求的动作（比如返回对象）。
> >
> > 　　17、If-Range
> >
> > 　　浏览器告诉 WEB 服务器，如果我请求的对象没有改变，就把我缺少的部分给我，如果对象改变了，就把整个对象给我。浏览器通过发送请求对象的ETag 或者自己所知道的最后修改时间给 WEB 服务器，让其判断对象是否改变了。总是跟 Range 头部一起使用。
> >
> > 　　18、Range
> >
> > 　　浏览器（比如 Flashget 多线程下载时）告诉 WEB 服务器自己想取对象的哪部分。例如：Range: bytes=1173546
> >
> > 　　19、Proxy-Authenticate
> >
> > 　　代理服务器响应浏览器，要求其提供代理身份验证信息。
> >
> > 　　20、Proxy-Authorization
> >
> > 　　浏览器响应代理服务器的身份验证请求，提供自己的身份信息。
> >
> > 　　21、**Host**
> >
> > 　　客户端指定自己想访问的WEB服务器的域名/IP 地址和端口号。如Host：rss.sina.com.cn
> >
> > 　　22、Referer
> >
> > 　　浏览器向WEB 服务器表明自己是从哪个网页URL获得点击当前请求中的网址/URL，例如：Referer：http://www.ecdoer.com/
> >
> > 　　23、User-Agent
> >
> > 　　浏览器表明自己的身份（是哪种浏览器）。例如：User-Agent：Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN;rv:1.8.1.14) Gecko/20080404 Firefox/2.0.0.14

> **请求数据**
> 可选部分，比如GET请求就没有请求数据。

### 服务器响应HTTP请求，浏览器得到html代码

> 接收到HTTP请求之后，就轮到负载均衡登场了，它位于网站的最前端，把短时间内较高的访问量分摊到不同机器上处理。负载均衡方案有软件、硬件两种

#### HTTP响应报文

> HTTP响应报文主要由**状态行**、**响应头部**、**空行**以及**响应数据**组成。

> **状态行**
> 由3部分组成，分别为：协议版本，状态码，状态码描述。
>
> **协议版本**的格式为：HTTP/主版本号.次版本号，常用的有HTTP/1.0和HTTP/1.1
>
> **状态码**描述是对状态码的简单描述1xx：指示信息–表示请求已接收，继续处理。
> 2xx：成功–表示请求已被成功接收、理解、接受。
> 3xx：重定向–要完成请求必须进行更进一步的操作。
> 4xx：客户端错误–请求有语法错误或请求无法实现。
> 5xx：服务器端错误–服务器未能实现合法的请求。

> **响应头部**
>
> | Access-Control-Allow-Origin | 指定哪些网站可以跨域资源共享                                 | Access-Control-Allow-Origin:*                        |
> | --------------------------- | ------------------------------------------------------------ | :--------------------------------------------------- |
> | Accept-Patch                | 指定服务器所支持的文档补丁格式                               | Accept-Patch:text/exa,ple;charset=utf-8              |
> | Accept-Ranges               | 服务器支持的内容范围                                         | Accept-Ranges:bytes                                  |
> | Age                         | 响应对象在代理缓存中存在的时间，以秒为单位                   | Age:12                                               |
> | Allow                       | 对于资源的有效动作                                           | Allow:GET,POST,HEAD                                  |
> | Cache-control               | 告知客户端缓存机制，表示是否可缓存 或缓存有效时间以秒为单位  | Cache-control:no-cache                               |
> | Connection                  | 针对该链接的所有预期的选项                                   | Connection:close                                     |
> | Content-Disposition         | 对已知MIME类型资源的描述，浏览器可以根据此响应决定动作，如下载资源或打开 | Content-Disposition:attachment;filename="fname.text" |
> | Content-Encoding            | 响应资源使用的编码类型                                       | Content-Encoding:gzip                                |
> | Content-language            | 响应内容使用的语言                                           | Content-language:zh-cn                               |
> | Content-Length              | 响应消息体的长度，使用八进制表示                             | Content-Length:348                                   |
> | Content-Location            | 返回数据的一个候选位置                                       | Content-Location:/index.htm                          |
> | Content-MD5                 | 响应内容的MD5散列值以Base64方式编码                          | Content-MD5:IDKOiSsGsvjkKJHkjKbg                     |
> | Content-Range               | 如果响应的是部分消息，则表示属于完整消息的哪个部分           | Content-Range:bytes12020-47021/47022                 |
> | Content-Type                | 当前内容的MIME类型                                           | Content-Type:text/html;charset=utf-8                 |
> | Date                        | 此条消息被发送时的日期和时间(以RFC 7231中定义的"HTTP日期"格式来表示) | Date:Wed,18 Jul 2018 21:01:33 GTM                    |
> | Etag                        | 对于某个资源的特定版本的一个标识符， 通常是一个消息散列      | Etag:977823cd9080da09vsd89kj923jhkb8df8              |
> | Expires                     | 指定一个日期/时间，超过该时间此回应过期                      | Expires:Wed,18 Jul 2018 21:01:33 GTM                 |
> | Last-Modified               | 请求对象的最后修改时间 (以RFC 7231中定义的"HTTP日期"格式来表示) | Last-Modified:Wed,18 Jul 2018 21:01:33 GTM           |
> | Link                        | 用来表示与另外一个资之间的类型关系， 此类型关系是在RFC 5988中定义的 | Link:rel="alternate"                                 |
> | Location                    | 用于重定向或者在创建了某个新资源时使用                       | Location:http://www.baidu.com                        |
> | P3P                         | P3P策略的设置                                                | P3P:CP="This is not a P3Ppolicy!"                    |
> | Pragaa                      | 效果并不确定，这些响应头可能在请求/回应链 中的不同时候产生不同的效果 | Pragaa:no-cache                                      |
> | Proxy-Authenticate          | 要求在访问代理是提供身份认证信息                             | Proxy-Authenticate:Basic                             |
> | Public-Key-Pins             | 用于防止中间攻击，申明网站认证中 传输层安全协议的证书散列值  | Public-Key-Pins:max-age=259200;pin-sha256="… ..."    |
> | Refresh                     | 用于重定向或者当一个新的资源被创建时 默认在5秒后刷新重定向   | Refresh:5;url=http://www.baidu.com                   |
> | Retry-After                 | 如果某个实体临时不可用，那么此协议用于告知用户 端稍后重试，其值可以是特定的时间段(以秒为单位) 或者是一个超文本传输协议日期 | Retry-After:120/Wed,18 Jul 2018 21:01:33 GTM         |
> | Server                      | 服务器名称                                                   | Server:nginx/1.6.3                                   |
> | Set-Cookie                  | 设置HTTP Cookie,cookie被设置在请求的服务端域名下             | Set-Cookie:user_name=garrett;user_id=001             |
> | Status                      | 通用网管接口响应字段，用来说明当前HTTP链接状态               | Status:200 ok                                        |
> | Trailer                     | 说明传输中分块编码的编码信息                                 | Trailer:Max-Forwards                                 |
> | Transfer-Encoding           | 表示实体传输给用户的编码形式，包括：chunked, compress,deflate,gzip,identify等 | Transfer-Encoding:chunked                            |
> | Upgrade                     | 要求用户升级到另外一个高版本的协议                           | Upgrade:HTTP/2.0,SHTTP/1.3,IRC/6.9,RTA/X11           |
> | Vary                        | 告知下游的代理服务器如何对之后的请求协议头进行 匹配，以决定是否可使用已缓存的响应内容而不是 重新从原服务器请求新的内容 | Vary:*                                               |
> | Vis                         | 告知代理服务器的客户端，当前的响应式通过什么途径发送的       | Vis:1.0 FRED, 1.1 baidu.com                          |

> **响应数据**
> 用于存放需要返回给客户端的数据信息。

### 浏览器解析html代码 并请求html中资源

### 浏览器对页面进行渲染呈现



## 状态码

> 状态码的职责是当客户端向服务器端发送请求时，描述返回的请求结果。借助状态码，用户可以知道服务器端是正常处理了请求，还是出现了错误

|      | 类别                            | 类别                       |
| ---- | ------------------------------- | -------------------------- |
| 1xx  | Informational(信息性状态码)     | 接受的请求正在处理         |
| 2xx  | Success(成功状态码)             | 请求正常处理完毕           |
| 3xx  | Redirection(重定向状态码)       | 需要进行附加操作一完成请求 |
| 4xx  | Client Error (客户端错误状态码) | 服务器无法处理请求         |
| 5xx  | Server Error(服务器错误状态码)  | 服务器处理请求出错         |

#### 2xx 成功

> 2XX 的响应结果表明请求被正常处理了

##### 	200正常处理

> ​	响应交过表明请求被正常处理了

##### 	204无内容

> ​	服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。比如，当从浏览器发出请求处理后，返回 204 响应，那么浏览器显示的页面不发生更新。

#### 3xx 重定向

> 响应结果表明浏览器需要执行某些特殊的处理以正确处理请求

##### 	301永久性移动

> ​	该状态码表示请求的资源已被分配了新的 URI，以后应使用资源现在所指的 URI。也就是说，如果已经把资源对应的 URI保存为书签了，这时应该按 Location 首部字段提示的 URI 重新保存。

##### 	302临时重定向

> ​	该状态码表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。

##### 303另一个url

> ​	该状态码表示由于请求对应的资源存在着另一个 URI，应使用 GET方法定向获取请求的资源

##### 304未修改

> ​	自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。如果网页自请求者上次请求后再也没有更改过，您应将服务器配置为返回此响应(称为 If-Modified-Since HTTP 标头)。服务器可以告诉 Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。

#### 4XX 客户端

> ​	该状态码表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。另外，浏览器会像 200 OK 一样对待该状态码。

##### 401 未验证

> ​	该状态码表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。另外若之前已进行过 1 次请求，则表示用 户认证失败。
>
> ​	当浏览器初次接收到 401 响应，会弹出认证用的对话窗

##### 403不允许访问 拒绝

> ​	该状态码表明对请求资源的访问被服务器拒绝了。服务器端没有必要给出拒绝的详细理由，但如果想作说明的话，可以在实体的主体部分对原因进行描述，这样就能让用户看到了。
>
> ​	未获得文件系统的访问授权，访问权限出现某些问题（从未授权的发送源 IP 地址试图访问）等列举的情况都可能是发生 403 的原因

##### 404 没有请求得资源

> ​	该状态码表明服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由时使

#### 5xx服务器错误

##### 500 内部服务出错

> 该状态码表明服务器端在执行请求时发生了错误。也有可能是 Web应用存在的 bug 或某些临时的故障。

##### 503服务不可用

> 该状态码表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入RetryAfter 首部字段再返回给客户

## http头部信息

### 请求头

> 请求头用于说明是谁或什么在发送请求、请求源于何处，或者客户端的喜好及能力。服务器可以根据请求头部给出的客户端信息，试着为客户端提供更好的响应。

> - Accept:浏览器能够处理的内容类型
> - Accept-Charset:浏览器能够显示的字符集
> - Accept-Encoding：浏览器能够处理的压缩编码
> - Accept-Language：浏览器当前设置的语言
> - Connection：浏览器与服务器之间连接的类型
> - Cookie：当前页面设置的任何Cookie
> - Host：发出请求的页面所在的域
> - Referer：发出请求的页面的URL
> - User-Agent：浏览器的用户代理字符串

### 响应头

> 响应头向客户端提供一些额外信息，比如谁在发送响应、响应者的功能，甚至与响应相关的一些特殊指令。这些头部有助于客户端处理响应，并在将来发起更好的请求。

> - Date：表示消息发送的时间，时间的描述格式由rfc822定义
> - server:服务器名字。
> - Connection：浏览器与服务器之间连接的类型
> - content-type:表示后面的文档属于什么MIME类型
> - Cache-Control：控制HTTP缓存

[http请求头]: https://blog.csdn.net/wangzhen_csdn/article/details/80776991

### 实体头

> 实体头部提供了有关实体及其内容的大量信息，从有关对象类型的信息，到能够对资源使用的各种有效的请求方法。总之，实体头部可以告知接收者它在对什么进行处理。请求消息和响应消息都可以包含实体信息，实体信息一般由实体头域和实体组成。

> **Allow** ：服务器支持哪些请求方法（如GET、POST等）。
>
> Location 表示客户应当到哪里去提取文档，用于将接收端定位到资源的位置（URL）上。
>
> Content-Base　解析主体中的相对URL时使用的基础URL。
>
> Content-Encoding　　WEB服务器表明自己使用了什么压缩方法（gzip，deflate）压缩响应中的对象。例如：Content-Encoding：gzip
>
> Content-Language　　WEB 服务器告诉浏览器理解主体时最适宜使用的自然语言。
>
> Content-Length　　WEB服务器告诉浏览器自己响应的对象的长度或尺寸，例如：Content-Length: 26012
>
> Content-Location　　资源实际所处的位置。
>
> Content-MD5　　主体的MD5校验和。
>
> Content-Range　　实体头用于指定整个实体中的一部分的插入位置，他也指示了整个实体的长度。在服务器向客户返回一个部分响应，它必须描述响应覆盖的范围和整个实体长度。一般格式： Content-Range:bytes-unitSPfirst-byte-pos-last-byte-pos/entity-legth。例如，传送头500个字节次字段的形式：Content-Range:bytes0- 499/1234如果一个http消息包含此节（例如，对范围请求的响应或对一系列范围的重叠请求），Content-Range表示传送的范围，Content-Length表示实际传送的字节数。
>
> **Content-Type**　　WEB 服务器告诉浏览器自己响应的对象的类型。例如：Content-Type：application/xml
>
> Etag　　就是一个对象（比如URL）的标志值，就一个对象而言，比如一个html文件，如果被修改了，其Etag也会别修改，所以，ETag的作用跟Last-Modified的作用差不多，主要供WEB服务器判断一个对象是否改变了。比如前一次请求某个html文件时，获得了其 ETag，当这次又求这个文件时，浏览器就会把先前获得ETag值发送给WEB服务器，然后WEB服务器会把这个ETag跟该文件的当前ETag进行对比，然后就知道这个文件有没有改变了。
>
> Expires　　WEB服务器表明该实体将在什么时候过期，对于过期了的对象，只有在跟WEB服务器验证了其有效性后，才能用来响应客户请求。是 HTTP/1.0 的头部。例如：Expires：Sat, 23 May 2009 10:02:12 GMT
>
> Last-Modified　　WEB服务器认为对象的最后修改时间，比如文件的最后修改时间，动态页面的最后产生时间等等。例如：Last-Modified：Tue, 06 May 2008 02:42:43 GMT





## 数据的封装与解封

**封装**

![img](https://img-blog.csdnimg.cn/20200228205426715.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Bvd2VyY2h1bg==,size_16,color_FFFFFF,t_70)

> 在实际数据传输中每一层都有相应的协议，但是其中的表示层和会话层的协议（传输数据的时候不会对数据做任何操作），于是将这两层合并到应用层，也称为**TCP/IP五层模型**。
>
> 在这里我们假设我们的软件发送hello到目的端:
>
> 1、数据在应用层进行封装发出、经过 表示和会话层时候不会做任何操作：**数据包内容为hello**
>
> 2、当数据包传送到传输层时：传输层会对数据包进一步封装、为该数据包添加TCP/UDP头，具体添加哪一个取决于应用层使用得是哪一个，其中包含了源端口和目的端口号、源端口号往往是指定的、或是浏览器自动指派的端口。
>
> 3、在传输层封装了端口号、数据传送到网络层对数据包进一步封装，为该数据包添加了IP头、其中包含源ip和目的ip，这样在数据传输的过程中数据就可以找到对应的目的主机
>
> 4、经过以上的封装、数据就已经到达了设备的网卡上、下一步就要通过网线进行传输了、但是一个载体来进行传输、因此在数据包中在加入含有源MAC地址和目标MAC地址字段
>
> 5、经过物理层实际的网线进行数据传输

**解封**

![解封装过程](https://img-blog.csdn.net/20180904113047879?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYXl1bjE5OTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

## TCP长连接

> TCP 长连接是一种保持 TCP 连接的机制。当一个 TCP 连接建立之后，启用 TCP Keep Alive 的一端便会启动一个计时器，当这个计时器到达 0 之后，一个 TCP 探测包便会被发出。这个 TCP 探测包是一个纯 ACK 包，但是其 Seq 与上一个包是重复的。
>
> **keep alive 技术只是 TCP 技术中的一个可选项。因为不当的配置可能会引起诸如一个正在被使用的 TCP 连接被提前关闭这样的问题，所以默认是关闭的**



## HTTP长连接

http1.1中为了解决网页内容越来越复杂，且包含大量图片，css等资源后，效率太低的问题。所以引入了http长连接的概念（也称为HTTP keep-alive）

![img](https://upload-images.jianshu.io/upload_images/3108769-e429124b24c3f80e.png?imageMogr2/auto-orient/strip|imageView2/2/w/450/format/webp)

建立长连接时，在HTTP请求头中将包含以下内容

```http
Connection: Keep-Alive
```

服务端同意建立长连接后，响应头将包含

```http
Connection: Keep-Alive
```

需要关闭连接时，HTTP头中将包含

```http
Connection: Close
```



## TCP Keep Alive 与 HTTP Keep Alive 的关系

> TCP Keep Alive 和 HTTP Keep Alive 是两个目的不同的技术，不存在谁依赖于谁的关系。TCP Keep Alive 用于探测对端是否存在，而 HTTP Keep Alive 用于协商以复用 TCP 连接。即便一个 TCP 连接未启用 Keep Alive 功能，也不妨碍 HTTP 层面开启长连接。





# java

## 同步异步

> **同步和异步**
>
> 强调的是消息通信机制 (synchronous communication/ asynchronous communication)。所谓**同步，就是在发出一个"调用"时，在没有得到结果之前，该“调用”就不返回。但是一旦调用返回，就得到返回值了。**换句话说，就是由“调用者”主动等待这个“调用”的结果。而**异步则是相反，"调用"在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。**而是在"调用"发出后，"被调用者"通过状态、通知来通知调用者，或通过回调函数处理这个调用

> **阻塞和非阻塞** 
>
> 强调的是程序在**等待调用结果（消息，返回值）时的状态**. 阻**塞调用是指调用结果返回之前，当前线程会被挂起。**调用线程只有在得到结果之后才会返回。**非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。** 对于同步调用来说，很多时候当前线程还是激活的状态，只是从逻辑上当前函数没有返回而已，即同步等待时什么都不干，白白占用着资源。

## 压缩算法

| **Algorithm** | **% remaining** | **Encoding** | **Decoding** |
| ------------- | --------------- | ------------ | ------------ |
| GZIP          | 13.4%           | 21 MB/s      | 118 MB/s     |
| LZO           | 20.5%           | 135 MB/s     | 410 MB/s     |
| Zippy/Snappy  | 22.2%           | 172 MB/s     | 409 MB/s     |

> 项目中使用压缩算法在cache中，利用snappy进行对于缓存的msg进行压缩，减少占用空间。另外由于相关缓存数据存放在redis中，对于压缩解压缩速度更为看重，所以采用了Snappy算法。

## 自动装箱 拆箱

```java
public class Main {
    public static void main(String[] args) {

        Integer i1 = 100;
        Integer i2 = 100;
        Integer i3 = 200;
        Integer i4 = 200;

        System.out.println(i1==i2);  //true
        System.out.println(i3==i4);  //false
    }
}
```

> 1、i1和i2会进行自动装箱，执行了valueOf函数，它们的值在(-128,128]这个范围内，它们会拿到SMALL_VALUES数组里面的同一个对象SMALL_VALUES[228]，它们引用到了同一个Integer对象，所以它们肯定是相等的。
>
> 2、i3和i4也会进行自动装箱，执行了valueOf函数，它们的值大于128，所以会执行new Integer(200)，也就是说它们会分别创建两个不同的对象，所以它们肯定不等。
>
> ![这里写图片描述](http://img.blog.csdn.net/20150922153039509)

```
 Integer num1 = 100;  
 int num2 = 100;  
 Long num3 = 200l;  
 System.out.println(num1 + num2);  //200
 System.out.println(num3 == (num1 + num2));  //true
 System.out.println(num3.equals(num1 + num2));  //false
```

> 1、当一个基础数据类型与封装类进行==、+、-、*、/运算时，会将封装类进行**拆箱**，对基础数据类型进行运算。 
> 2、对于num3.equals(num1 + num2)为false的原因很简单，我们还是根据代码实现来说明

```
 @Override
 public boolean equals(Object o) {
     return (o instanceof Long) && (((Long) o).value == value);
 }
```

> 它必须满足两个条件才为true： 
> 1、类型相同 
> 2、内容相同 
> 上面返回false的原因就是类型不同。

> **总结**
>
> > **包装类和基本类作比较**
> > **==				true**
> > **equals		 true**
>
> > **包装类和包装类比较**
> > **==					如果在+-128范围内 则是同一对象**
> > **equals			类型相同时内容相同为 true**



## <u>基本数据类型</u>

##### byte

> 8位 1字节
>
> - 最小值是 **-128（-2^7）**；
> - 最大值是 **127（2^7-1）**；
> - 默认值是 **0**；
> - 用于在大型数组中节约空间，代替整数

##### short

> 16位 2字节
>
> - 最小值是 **-32768（-2^15）**；
> - 最大值是 **32767（2^15 - 1）**；
> - 默认值是 **0**；
> - Short 数据类型也可以像 byte 那样节省空间。一个short变量是int型变量所占空间的二分之一；

##### int

> 32位 4字节
>
> - 最小值是 **-2,147,483,648（-2^31）**；
> - 最大值是 **2,147,483,647（2^31 - 1）**；
> - 一般地整型变量默认为 int 类型；
> - 默认值是 **0** ；

##### long

> 64位 8字节
>
> - 最小值是 **-9,223,372,036,854,775,808（-2^63）**；
> - 最大值是 **9,223,372,036,854,775,807（2^63 -1）**；
> - 这种类型主要使用在需要比较大整数的系统上；
> - 默认值是 **0L**；

##### float

> 32位 4字节
>
> - float 在储存大型浮点数组的时候可节省内存空间；
> - 默认值是 **0.0f**；
> - 浮点数不能用来表示精确的值，如货币；

##### double

> 64位 8字节
>
> - 浮点数的默认类型为double类型；
> - double类型同样不能表示精确的值，如货币；
> - 默认值是 **0.0d**；

##### char

> 16位 2字节
>
> - 最小值是 **\u0000**（即为0）；
> - 最大值是 **\uffff**（即为65,535）；
> - char 数据类型可以储存任何字符；

### *如何比较两个double类型大小？*

##### 1两者相减 

> 差和0相比较 如果小于一个非常小的数（允许的精度）那么认为相等

##### 2使用Double包装类

> 使用Double包装类中的equals方法

### *一个char可以存放中文字符吗？*

> 可以 一种中文字符占两个字节 一个char也占两个字节

### 一个英文ASCII字符占一个字节 为什么char占两个字节 会产生浪费吗（自问）

> 不会
>
> 因为在java中，所有的字符都是unicode编码，都占两个字符

## <u>JDK1.8新特性</u>

### 			Lambda表达式

> ​	简化匿名内部类的代码量

### 			函数式接口

> 简单来说就是只定义了一个抽象方法的接口（Object类的public方法除外），就是函数式接口，并且还提供了注解：@FunctionalInterface
>
> 通过提供的四大函数式接口 可以简化lamda，不用手动创建一个新的函数式接口

### 		方法引用和构造器调用

### 		Stream API

### 		接口中的默认方法和静态方法

> 在接口中可以使用default和static关键字来修饰接口中定义的普通方法

```java
public interface Interface {
    default  String getName(){
        return "zhangsan";
    }

    static String getName2(){
        return "zhangsan";
    }
}

```

> 可以避免在1.8中新增的接口方法 需要在1.7中全部添加实现，可以通过默认实现的方式
>
> 当一个类继承父类又实现接口时，若后两者方法名相同，则优先继承父类中的同名方法，即“类优先”，如果实现两个同名方法的接口，则要求实现类必须手动声明默认实现哪个接口中的方法。

### 		新时间日期API

> 新的日期API LocalDate | LocalTime | LocalDateTime
>
> 新的日期API都是不可变的，更使用于多线程的使用环境中
>
> >  * 之前使用的java.util.Date月份从0开始，我们一般会+1使用，很不方便，java.time.LocalDate月份和星期都改成了enum
> >  * java.util.Date和SimpleDateFormat都不是线程安全的，而LocalDate和LocalTime和最基本的String一样，是不变类型，不但线程安全，而且不能修改。
> >  * java.util.Date是一个“万能接口”，它包含日期、时间，还有毫秒数，更加明确需求取舍
> >  * 新接口更好用的原因是考虑到了日期时间的操作，经常发生往前推或往后推几天的情况。用java.util.Date配合Calendar要写好多代码，而且一般的开发人员还不一定能写对。

[新特性]: https://blog.csdn.net/qq_29411737/article/details/80835658





## <u>java中的流</u>

### 	字节流

> ​	以字节为导向的 stream------InputStream/OutputStream

### 	字符流

> ​	以字符为导向的 stream Reader/Writer

### 	流没有释放会导致的问题

> ​	长时间不进行释放会一直占用内存 长时间可能导致OOM



## <u>Tomcat类加载</u>

> https://www.cnblogs.com/aspirant/p/8991830.html



## <u>类加载如何打破双亲委派</u>

> 重写classload方法
>
> 重写findclass方法 实现自定义的类加载方式

## <u>OOM的场景 查询工具</u>

### 场景

> 1堆空间设置不合理 将其设置调大
>
> 2永久代空间太小
>
> 3gc时对象过多，导致内存溢出，可以调整gc的策略，不要占满后再gc
>
> 4本地线程空间溢出 线程栈过大？
>
> 5分配了一个大于堆大小的数组（连续空间）  是否数组过大 或调大堆
>
> 6由于从native堆中分配内存失败，并且堆内存可能接近耗尽
>
> 线程池中等待队列无限制扩张

### 工具

> **jstat**
>
> 可以使用jstat查看程序运行的实时情况，包括堆内存信息和垃圾回收信息，常用来查看程序的垃圾回收情况
>
> > jstat -gc pid
>
> Jprofiler
>
> > 插件 用于看内存是一个内存工具。可以直观的看到各个对象在堆内存中所占空间大小 类实例数量 对象引用关系



## <u>JDK提供的工具</u>



## <u>异常分为两种 有什么不同</u>

#### error

> 是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。

#### exception

> 运行时异常RuntimeException
>
> > 是那些可能在 Java 虚拟机正常运行期间抛出的异常的超类。 如果出现 RuntimeException，那么一定是程序员代码书写导致的错误.
> >
> > 例如：空指针异常 下标越界
>
> 检查异常 CheckedException
>
> > 一般是外部错误，这种异常都发生在编译阶段，Java 编译器会强
> > 制程序去捕获此类异常，即会出现要求你把这段可能出现异常的程序进行 try catch
> >
> > 例如：IOException SQLException

## java集合

### list

> ArrayList
>
> > **优点:** 底层数据结构是数组，查询快，增删慢。
> > **缺点:** 线程不安全，效率高
>
> Vector
>
> > **优点:** 底层数据结构是数组，查询快，增删慢。
> > **缺点:** 线程安全，效率低
>
> LinkedList
>
> > **优点:** 底层数据结构是链表，查询慢，增删快。
> > **缺点:** 线程不安全，效率高

### set

> HashSet
>
> > 底层数据结构是哈希表。(无序,唯一)
> > 如何来保证元素唯一性?
> > 1.依赖两个方法：hashCode()和equals()
>
> LinkedHashSet
>
> > 底层数据结构是链表和哈希表。(FIFO插入有序,唯一)
> > 1.由链表保证元素有序
> > 2.由哈希表保证元素唯一
>
> TreeSet
>
> > 底层数据结构是红黑树。(唯一，有序)
> > \1. 如何保证元素排序的呢?
> > 自然排序
> > 比较器排序
> > 2.如何保证元素唯一性的呢?
> > 根据比较的返回值是否是0来决定

### map

> Hashtable
>
> > 线程安全 使用了synchronized
>
> LinkedHashMap
>
> > 在hashmap的基础上增加了有序
>
> ConcurrentHashMap
>
> > 1.7中使用分段锁 1.8放弃了分段锁的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，如下图所示，并发控制使用Synchronized和CAS来操作，每一个Node节点都是用volatile修饰的，整个看起来就像是优化过且线程安全的HashMap。
>
> HashMap
>
> > Hashmap是线程不安全的 1.7数组+链表 1.8数组+链表/红黑树





# 消息队列

## 市面上的消息队列选型

> **kafka：**
>
> 1、开发语言：   Scala开发
> 2、性能、吞吐量： 吞吐量所有MQ里最优秀，QPS十万级、性能毫秒级、支持集群部署
> 3、功能：     功能单一
> 4、缺点：     丢数据， 因为数据先写入磁盘缓冲区，未直接落盘。机器故障会造成数据丢失
> 5、应用场景：   适当丢失数据没有关系、吞吐量要求高、不需要太多的高级功能的场景，比如大数据场景。
>
> **RabbitMQ：**
>
> 1、开发语言：   Erlang开发
> 2、性能、吞吐量： 吞吐量比较低，QPS几万级、性能u秒级、主从架构
> 3、功能：功能单一
> 4、缺点：Erlang小众语言开发，吞吐量低，集群扩展麻烦
> 5、应用场景：中小公司对并发和吞吐量要求不高的场景。
>
> **RocketMQ：**
>
> 1、开发语言：   java开发
> 2、性能、吞吐量： 吞吐量高，QPS十万级、性能毫秒级、支持集群部署
> 3、功能：     支持各种高级功能，比如说**延迟消息、事务消息、消息回溯、死信队列、消息积压**等等
> 4、缺点：     官方文档相对简单可能是RocketMQ目前唯一的缺点
> 5、应用场景：   适当丢失数据没有关系、吞吐量要求高、不需要太多的高级功能的场景，比如大数据场景。





# Redis

## <u>Redis为什么快</u>

> 纯内存操作
>
> 单线程操作，减少了频繁的上下文切换
>
> 采用了非阻塞IO多路复用机制

## <u>什么是多路复用机制</u>

> 小名在 A 城开了一家快餐店店，负责同城快餐服务。小明因为资金限制，雇佣了一批配送员，然后小曲发现资金不够了，只够买一辆车送快递。
>
> 小明只雇佣一个配送员。当客户下单，小明按送达地点标注好，依次放在一个地方。最后，让配送员依次开着车去送，送好了就回来拿下一个。
>
> - 每个配送员→每个线程
> - 每个订单→每个 Socket(I/O 流)
> - 订单的送达地点→Socket 的不同状态
> - 客户送餐请求→来自客户端的请求
> - 明曲的经营方式→服务端运行的代码
> - 一辆车→CPU 的核数
>
> 只有单个线程(一个配送员)，通过跟踪每个 I/O 流的状态(每个配送员的送达地点)，来管理多个 I/O 流。
>
> Redis-client 在操作的时候，会产生具有不同事件类型的 Socket。在服务端，有一段 I/O 多路复用程序，将其置入**队列**之中。然后，**文件事件分派器**，**依次去队列中取**，转发到不同的事件处理器中。

## <u>Redis和Memcached的区别</u>

两者相同点 

> 两者都是基于内存的数据存储系统
>
> 本质上都是一个内存的key-value存储系统

两者的不同点

##### 1数据操作不同

> Memcached仅支持key-value的数据结构 不支持枚举，不支持持久化和复制
>
> Redis支持的数据结构更加丰富 支持list set zset hash string 并且通过了持久化和复制的功能

##### 2内存管理机制的不同

> Redis中，并不是所有的数据都一直存储在内存中，可以通过lru的机制，将一些很久没用的value交换到磁盘，并且在内存中进行删除
>
> Memcached默认使用Slab Allocation机制管理内存 思想是按照预先规定的大小，将分配的内存分割成特定长度的块以存储相应长度的key-value数据记录，以完全解决内存碎片问题。

##### 3性能不同

> Redis只能使用单核 平均每一个核上Redis在存储小数据时性能更高
>
> Memcached可以使用多核 存储100k以上的数据 性能更好

##### 4集群管理不同

> Memcached是全内存的数据缓冲系统，Redis虽然支持数据的持久化，但是全内存毕竟才是其高性能的本质。作为基于内存的存储系统来说，机器物理内存的大小就是系统能够容纳的最大数据量。如果需要处理的数据量超过了单台机器的物理内存大小，就需要构建分布式集群来扩展存储能力。
>
> Memcached本身不支持分布式，只能通过在客户端通过一致性hash的方式实现分布式存储。
>
> Redis则偏向于在服务端构建分布式存储。



## <u>为什么要使用Redis</u>

#### 性能问题

> 对于一些执行耗时很久，结果不频繁变动的SQL，适合将运行结果放入缓存，以减少对于MySQL的访问
>
> **例如 一些静态不会进行变更的一些数据 在秒杀时可以将其放在redis**

#### 并发问题

> 高并发的情况下，所有的请求直接访问数据库会极容易出现问题，所以需要用redis做一个缓冲操作
>
> **例如 redis实现的消息队列的形式**



## <u>Redis的问题以及解决方案</u>

#### *缓存和数据库双写一致性问题*

#### 	*缓存雪崩问题*

> 缓存雪崩，是指在某一个时间段，缓存集中过期失效。
>
> ​	解决方案：将设置时间时加入随机量

#### 	*缓存击穿问题*

> 是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。
>
> ​	让缓存永不过期

#### 	*缓存穿透*

> 是指查询一个数据库一定不存在的数据。正常的使用缓存流程大致是，数据查询先进行缓存查询，如果key不存在或者key已经过期，再对数据库进行查询，并把查询到的对象，放进缓存。如果数据库查询对象为空，则不放进缓存。
>
> ​	**互斥锁**
>
> ​		缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。
>
> ​	**布隆过滤器**
>
> ​	**缓存空对象**
>
> ​		即使结果为空也将其缓存下来，设置一个较短的过期时间

#### *缓存的并发竞争问题*

#### 

## <u>分布式锁一定要用Redis吗 分布式锁的实现</u>

#### *数据库乐观锁*

#### *基于Redis的分布式锁*

#### *基于ZooKeeper的分布式锁*



## <u>Redis的淘汰策略</u>

> redis使用的是定期删除+惰性删除的形式
>
> 为什么不适用定时删除
>
> ​	因为占用cpu资源
>
> 如何工作
>
> ​	定期删除，Redis 默认每个 100ms 检查，有过期 Key 则删除。需要说明的是，Redis 不是每个 100ms 将所有的 Key 检查一次，而是随机抽取进行检查。如果只采用定期删除策略，会导致很多 Key 到时间没有删除。于是，惰性删除派上用场。

- noeviction：当**内存不足**以容纳新写入数据时，新写入操作**会报错**。
- allkeys-lru：当**内存不足**以容纳新写入数据时，在键空间中，**移除最近最少使用的 Key**。（推荐使用，目前项目在用这种）(最近最久使用算法)
- allkeys-random：当**内存不足**以容纳新写入数据时，在键空间中，**随机移除某个 Key**。（应该也没人用吧，你不删最少使用 Key，去随机删）
- volatile-lru：当**内存不足**以容纳新写入数据时，在**设置了过期时间的键空间中，移除最近最少使用的 Key**。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。（不推荐）
- volatile-random：当**内存不足**以容纳新写入数据时，在**设置了过期时间的键空间中，随机移除某个 Key**。（依然不推荐）
- volatile-ttl：当**内存不足**以容纳新写入数据时，在设置了过期时间的键空间中，**有更早过期时间的 Key 优先移除**。（不推荐）

## <u>Redis内部的数据结构(使用场景)以及底层实现</u>

#### string

> ​	动态字符串 记录长度  空闲数量 以及用数组来保存字符串	

#### map

> ​	数组+链表 进行rehash的优化 存储两个数组结构 进行部分的扩容，当完全结束后再释放空间

#### 链表

> 双向链表的基础上 拓展了头尾节点 记录元素个数

#### 集合Set

> 

#### 有序集合ZSet

> ​	跳表（其本质和平衡树类似 但是相比而言 对于插入的调整较少 并且范围查询更方便）

[知乎解答]: https://zhuanlan.zhihu.com/p/50392209

## redis实现分布式锁

> key 使用 特定分布式锁前缀+当前用户pin
> value使用 （ip：port，过期时间）
>
> 加锁时：先用setNx进行加锁 如果没有设置成功 则获取原有的value 判断是否已经过期（当前时间和value中的过期时间相比） 如果过期用getset进行写入 判断是否已经成功写入自己的时间 如果是则加锁成功 否则加锁失败





# [Zookeeper](https://www.cnblogs.com/takumicx/p/9508706.html)

> 主要作用是为分布式系统提供协调服务,包括但不限于:分布式锁,统一命名服务,配置管理,负载均衡,主控服务器选举以及主从切换等。

> Zookeeper自身通常也以分布式形式存在。一个Zookeeper服务通常由多台服务器节点构成,只要其中超过一半的节点存活,Zookeeper即可正常对外提供服务,所以Zookeeper也暗含高可用的特性。客户端可以通过TCP协议连接至任意一个服务端节点请求Zookeeper集群提供服务,而集群内部如何通信以及如何保持分布式数据一致性等细节对客户端透明。

![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180820225811262-1254286440.png)

> 对于多读场景QPS很高。



## 为什么Zookeeper的吞吐量高

> 1.Zookeeper集群的**任意一个服务端节点都可以直接响应客户端的读请求**(写请求会不一样些,下面会详谈),并且可以通过增加节点进行横向扩展。这是其吞吐量高的主要原因
>
> 2.Zookeeper将全量数据存储于**内存中**,从内存中读取数据不需要进行磁盘IO,速度要快得多。
>
> 3.Zookeeper**放松了对分布式数据的强一致性要求**,即不保证数据实时一致,允许分布式数据经过一个时间窗口达到最终一致,这也在一定程度上提高了其吞吐量。
>
> 而写请求,或者说事务请求,因为要进行不同服务器结点间状态的同步,一定程度上会影响其吞吐量。故而简单的增加Zookeeper的服务器节点数量,对其吞吐量的提升并不一定能起到正面效果。**服务器节点增加,有利于提升读请求的吞吐量,但会延长服务器节点数据的同步时间,必须视具体情况在这两者之间取得一个平衡。**



## Zookeeper集群角色

> **Leader**
> **Leader**服务器在整个正常运行期间有且仅有一台,集群会通过选举的方式选举出Leader服务器,由它同统一处理集群的事务性请求以及集群内各服务器的调度。

> **Follower**
> **Follower**的主要职责有以下几点:
>
> - 1.参与Leader选举投票
> - 2.参与事务请求Proposal的投票
> - 3.**处理**客户端非事务请求(**读**),并**转发**事务请求(**写**)给Leader服务器。

> **Observer**
> **Observer**是弱化版的Follower。其像Follower一样**能够处理非事务也就是读请求,并转发事务请求给Leader服务器**,但是其不参与任何形式的投票,不管是Leader选举投票还是事务请求Proposal的投票。引入这个角色主要是为了在**不影响集群事务处理能力的前提下提升集群的非事务处理的吞吐量**。

## Zookeeper数据模型

> Zookeeper将数据存储于内存中,具体而言,Znode是存储数据的最小单元。而Znode被以层次化的结构进行组织,形容一棵树。其对外提供的视图类似于Unix文件系统。树的根Znode节点相当于Unix文件系统的根路径。正如Unix中目录下可以有子目录一样,Znode结点下也可以挂载子结点,最终形成如下所示结构。
>
> ![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180820225846944-872688418.png)
>
> ## Znode的类型
>
> > Znode按其生命周期的长短可以分为持久结点(PERSISTENT)和临时结点(EPHEMERAL);在创建时还可选择是否由Zookeeper服务端在其路径后添加一串序号用来区分同一个父结点下多个结点创建的先后顺序。
> >
> > > - 1.持久结点(PERSISTENT)
> > >   最常见的Znode类型,一旦创建将在一直存在于服务端,除非客户端通过删除操作进行删除。持久结点下可以创建子结点。
> > > - 2.持久顺序结点(PERSISTENT_SEQUENTIAL)
> > >   在具有持久结点基本特性的基础上,会通过在结点路径后缀一串序号来区分多个子结点创建的先后顺序。这工作由Zookeeper服务端自动给我们做,只要在创建Znode时指定结点类型为该类型。
> > > - 3.临时结点(EPHEMERAL)
> > >   临时结点的生命周期和客户端会话保持一致。客户端段会话存在的话临时结点也存在,客户端会话断开则临时结点会自动被服务端删除。临时结点下不能创建子结点。
> > > - 4.临时顺序结点(EPHEMERAL_SEQUENTIAL)
> > >   具有临时结点的基本特性,又有顺序性。
>
> ## znode的结构
>
> ![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180821162953209-1229005978.png)
>
> > - czxid:
> >   即Created ZXID,表示**创建该Znode结点的事务ID**
> > - mzxid:
> >   即Modified ZXID,表示**最后一次更新该结点的事务ID**
> > - version
> >   该Znode结点的**版本号**。每个Znode结点被创建时版本号都为0,每更新一次都会导致版本号加1,即使更新前后Znode存储的值没有变化版本号也会加1。version值可以形象的理解为Znode结点被更新的次数。Znode状态信息中的版本号信息,使得服务端可以对多个客户端对同一个Znode的更新操作做并发控制。整个过程和java中的CAS有点像,是一种乐观锁的并发控制策略,而version值起到了冲突检测的功能。客户端拿到Znode的version信息,并在更新时附上这个version信息,服务端在更新Znode时必须必须比较客户端的version和Znode的实际version,只有这两个version一致时才会进行修改。



## Zookeeper保证数据一致性

> Zookeeper采用ZAB(Zookeeper Atomic Broadcast)协议来保证分布式数据一致性。ZAB协议包括两种基本模式:**崩溃恢复模式**和**消息广播模式**。崩溃恢复模式主要用来**在集群启动过程,或者Leader服务器崩溃退出后进行新的Leader服务器的选举以及数据同步**;消息广播模式主要用来进行**事务请求的处理**。

### 事务请求处理（写）流程

> - 1.所有的事务请求都交由集群的Leader服务器来处理,Leader服务器会将一个事务请求转换成一个Proposal(提议),并为其生成一个全局递增的唯一ID,这个ID就是事务ID,即ZXID,Leader服务器对Proposal是按其ZXID的先后顺序来进行排序和处理的。
> - 2.之后Leader服务器会将Proposal放入每个Follower对应的队列中(Leader会为每个Follower分配一个单独的队列),并以FIFO的方式发送给Follower服务器。
> - 3.Follower服务器接收到事务Proposal后,首先以事务日志的方式写入本地磁盘,并且在成功后返回Leader服务器一个ACK响应。
> - 4.Leader服务器只要收到过半Follower的ACK响应,就会广播一个Commit消息给Follower以通知其进行Proposal的提交,同时Leader自身也会完成Proposal的提交。
>
> ![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180820231547149-911185014.png)

### Leader服务器的选举流程

> 当集群中不存在Leader服务器时集群会进行Leader服务器的选举,这通常存在于两种情况:1.集群刚启动时 2.集群运行时,但Leader服务器因故退出。集群中的服务器会向其他所有的Follower服务器发送消息,这个消息可以形象化的称之为选票,选票主要由两个信息组成,所推举的Leader服务器的ID(即配置在myid文件中的数字),以及该服务器的事务ID,事务表示对服务器状态变更的操作,**一个服务器的事务ID越大,则其数据越新**。
>
> - 1.Follower服务器投出选票(SID,ZXID),第一次每个Follower都会推选自己为Leader服务器,也就是说每个Follower第一次投出的选票是**自己的服务器ID和事务ID**。
> - 2.每个Follower都会接收到来自于其他Follower的选票,它会基于如下规则重新生成一张选票:**比较收到的选票和自己的ZXID的大小,选取其中最大的**;**若ZXID一样则选取SID即服务器ID最大的**。最终每个服务器都会重新生成一张选票,并将该选票投出去。
>
> 这样经过多轮投票后,如果某一台服务器得到了**超过半数的选票,则其将当前选为Leader**。由以上分析可知,Zookeeper集群对Leader服务器的选择具有偏向性,偏向于那些ZXID更大,即数据更新的机器。
>
> ![img](https://images2018.cnblogs.com/blog/1422237/201808/1422237-20180820232822615-266765305.png)

## Zookeeper服务器故障的容错

> Zookeeper通过事务日志和数据快照来避免因为服务器故障导致的数据丢失。
>
> - 事务日志是指服务器在更新内存数据前先将事务操作以日志的方式写入磁盘,Leader和Follower服务器都会记录事务日志。
> - 数据快照是指周期性通过深度遍历的方式将内存中的树形结构数据转入外存快照中。但要注意这种快照是"模糊"的,因为可能在做快照时内存数据发生了变化。但是因为Zookeeper本身对事务操作进行了幂等性保证,故在将快照加载进内存后会通过执行事务日志的方式来讲数据恢复到最新状态。

## [Zookeeper实现分布式锁](https://www.cnblogs.com/ysw-go/p/11444993.html)

> 其实如果有客户端C、客户端D等N个客户端争抢一个zk分布式锁，原理都是类似的。
>
> - 大家都是上来直接创建一个锁节点下的一个接一个的临时顺序节点
> - 如果自己不是第一个节点，就对自己上一个节点加监听器
> - 只要上一个节点释放锁，自己就排到前面去了，相当于是一个排队机制。
>
> 而且用临时顺序节点的另外一个用意就是，如果某个客户端创建临时顺序节点之后，不小心自己宕机了也没关系，zk感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁，或者是自动取消自己的排队。
>
> ![img](https://user-gold-cdn.xitu.io/2018/11/30/1676531f71973f37?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



# Spring笔记

## 自动装配

### 自动装配的两种方式

#### byName 

> 通过bean的id和set方法中的后缀匹配进行自动装配
>
> 例如：setAddress方法 能匹配bean配置文件中id为address的bean

#### byType

> 根据bean的类型
>
> 但是如果IOC容器中有一个以上的类型匹配则会报异常

### 自动装配缺点

> 所有属性都要自动装配 不够灵活、
>
> byType和byName不能混用



## bean的关系

### bean的继承

> 使用parent属性指定继承哪个bean
>
> 父类bean可以设置为abstract类似于抽象类使得其作为模板不可以被实例化
>
> 若某一个bean的class属性没有指定，则该bean一定是一个抽象bean

### bean的依赖关系

> depends-on 表示bean之间的依赖



## bean的作用域 scope

### 单例的singleton

> 在整个声明周期内只创建这一个bean

### 原型的prototype

> 容器创建时，不创建bean的实例，每次请求时创建一个新的Bean

### Session

### Request



## SpEL动态进行赋值

> 通过#{}的形式可以进行对属性赋值 包括别的bean 字面值 别的bean的属性值 方法返回值



## IOC容器中的Bean的生命周期

> 通过构造器或工厂方法创建Bean实例				**构造方法**
>
> 为Bean的属性设置 值和其他Bean的引用			**set方法**
>
> 调用bean后置处理器的前置方法 				**postBeforeInitialization方法**     
>
> ​																		参数一 Object bean 参数二 String beanName
>
> 调用Bean的初始化方法（指定init-method）	**指定的init方法**
>
> 调用bean后置处理器的后置方法 				**postAfterInitialization方法**     实现BeanPostProcessor接口
>
> Bean投入使用 
>
> 容器关闭时 调用Bean的销毁方法（指定destroy-method）		**指定的destroy方法**



## Bean的配置

### 反射 通过全类名

### 工厂方法

#### 	静态工厂

> 直接调用某个类的静态方法就可以返回Bean的实例
>
> 不用创建工厂实例 通过静态方法获取bean实例
>
> ```java
> public class StaticCarFactory{
> 	private static Map<String,Car> cars=new HashMap<String,Car>();
>  static{
>      cars.put("audi", new Car("audi",300));
>  }
>  public static Car getCar(String name){
>      return cars.get(name);
>  }
> }
> ```
>
> 在配置bean时只需要配置bean 尤其是其中的class为静态工厂方法 

#### 	实例工厂

> 通过创建工厂实例来进行生成Bean实例 
>
> 在配置时需要先配置工厂的bean 其中factory-bean为实例工厂

#### 通过FactoryBean

> 自定一的FactoryBean需要实现FactoryBean<>接口
>
> 通过类代码实现FactotyBean
>
> xml配置文件中bean的class指定为对应的FactoryBean的全类名



### 基于注解配置bean

#### 配置简单bean

> ##### 组件扫描
>
> Spring能够从classpath下自动扫描，侦测和实例化具有特定注解的组件 包括：
>
> @Component		 基本注解 标识了一个受Spring管理的组件
>
> @Respository		 标识持久层组件
>
> @Service				 标识服务层 业务层组件
>
> @Controller			标识表现层组件
>
> 使用组件后，还要在配置中声明 context:component-scan 指定IOC容器扫描的包
>
> resource-pattern  仅希望扫描特定的类而非基包下面的所有类
>
> include-filter   	   子节点标识要包含的目标类
>
> exclude-filter		  子节点表示要排除在外的目标类
>
> ​		其中存在五种方式进行指定 通过注解类型 通过bean名字

#### bean的关联关系的导入

> \<context:component-scan>元素自动注册AutowiredAnnotationBeanPostProcessor实例，可以指定装配具有@Autowired 和 @Resource @Inject注解的属性
>
> autowired可以自动装配类型兼容的bean
>
> 如果多个类型兼容 则需要通过名字进行装配（通过@Qualifier进行名字的设定）



### 泛型依赖注入

> 建立了依赖的两个父类，其子类也会建立依赖关系
>
> <img src="C:\Users\11346\AppData\Roaming\Typora\typora-user-images\image-20200421233205346.png" alt="image-20200421233205346" style="zoom:67%;" />



## AOP面向切面编程

### 为什么需要AOP

> 例如 有一个接口定义四则运算的操作，而一个类对他进行实现
>
> 现在有两个需求：1在每个运算前 输出日志 2进行数值的整型判断
>
> 如果不是用AOP技术，则需要每个方法前后都进行print。其中日志的输出方法是重复的，维护麻烦
>
> **问题1**代码混乱 原有的业务方法急剧膨胀 每个方法在处理核心逻辑时需要兼顾多个其他关注点
>
> **问题2**代码分散，多个模块重复实现重复代码，如果需求变更，需要改变多个模块的实现

### 动态代理实现AOP

> #### 代理模式
>
> 代理类和被代理类实现共同的接口（或继承），代理类中存有指向被代理类的索引，实际执行时通过调用代理类的方法、实际执行的是被代理类的方法。
>
> #### 静态代理
>
> 由程序员创建或特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了。
>
> ```java
> public class BirdLogProxy implements Flyable {
>  private Flyable flyable;
> 
>  public BirdLogProxy(Flyable flyable) {
>      this.flyable = flyable;
>  }
> 
>  @Override
>  public void fly() {
>      System.out.println("Bird fly start...");
> 
>      flyable.fly();
> 
>      System.out.println("Bird fly end...");
>  }
> }
> ```
>
> ```java
>  public static void main(String[] args) {
>      Bird bird = new Bird();
>      BirdLogProxy p1 = new BirdLogProxy(bird);
>      BirdTimeProxy p2 = new BirdTimeProxy(p1);
> 
>      p2.fly();
>  }
> 
> ```
>
> 这就时一个代理类，通过与被代理的类实现相同接口的形式，加上聚合的形式，将需要代理的对象作为参数传入，将原有方法进行增强。但是作为静态方法，面对大量需要被代理的方法，需要同样多的静态代理类。所以需要一个代理类来代理任意对象。
>
> #### 动态代理
>
> 程序运行时，运用反射机制动态创建而成，动态代理类的字节码在程序运行时由Java反射机制动态生成，无需程序员手工编写它的源代码。
>
> ##### 动态代理的两种实现方式
>
> ##### **JDK代理**
>
> JDK动态代理主要涉及java.lang.reflect包下的Proxy类和InvocationHandler接口。 JDK代理实现的三个要点：
>
> **通过java.lang.reflect.Proxy类来动态生成代理类；**
> **代理类要实现InvocationHandler接口；**
> **JDK代理只能基于接口进行动态代理；**
>
> 每一个动态代理类都必须要实现InvocationHandler这个接口，并且每个代理类实例都关联到了一个handler，当我们通过代理对象调用一个方法的时候，这个方法的调用就会被转发为由InvocationHandler这个接口的 invoke 方法来进行调用。
>
> ```java
> Object invoke(Object proxy, Method method, Object[] args) throws Throwable
> proxy:　　 指代我们所代理的那个真实对象
> method:　　指代的是我们所要调用真实对象的某个方法的Method对象
> args:　　  指代的是调用真实对象某个方法时使用的参数
> ```
>
> Proxy这个类的作用就是用来动态创建一个代理对象的类，它提供了许多的方法，但是我们用的最多的就是 newProxyInstance 这个方法，这个方法的作用就是得到一个动态的代理对象，其接收三个参数，我们来看看这三个参数所代表的含义。
>
> ```java
> public static Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h) throws IllegalArgumentException
> loader:　　    一个ClassLoader对象，定义了由哪个ClassLoader对象来对生成的代理对象进行加载
> interfaces:　　一个Interface对象的数组，表示的是我将要给我需要代理的对象提供一组什么接口，如果我提供了一组接口给它，这样我就能调用这组接口中的方法了
> h:　　         一个InvocationHandler对象，表示的是当我这个动态代理对象在调用方法的时候，会关联到哪一个InvocationHandler对象上
> ```
>
> 

### AOP术语

> 切面：横切关注点（跨越应用程序多个模块的功能）被模块化的特殊对象
>
> 通知：且面必须完成的工作（参数验证 日志每一个方法就是一个通知）
>
> 目标：被通知的对象（原本的加减乘除方法）
>
> 代理：向目标对象应用统治之后创建的对象
>
> 连接点：程序执行的某个特定位置 是一个真实存在的物理位置（例如加法执行之前 减法执行之后的位置 **某某某方法执行前/后/抛出异常时**）
>
> 切点：AOP通过切点定位到特殊的连接点

<img src="C:\Users\11346\AppData\Roaming\Typora\typora-user-images\image-20200422004426090.png" alt="image-20200422004426090" style="zoom:67%;" />



### 使用AOP

#### AspectJ注解的形式

> ​		需要把切面的类声明为一个切面
>
> ​		将改类放入到IIOC容器中@Component 再声明为一个切面@Aspect
>
> ​		在切面的方法前面加入@Before（前置通知）声明在哪些类的哪些方法前进行执行
>
> ​		在配置文件中设置 使AspectJ起作用
>
> ​		可以在通知方法中加一个类型为JointPoint的参数，就能访问到连接细节，如方和和参数值

#### 通知的类型

> ​	前置通知：在方法开始前执行 @Before （在动态代理的invoke方法前执行）
>
> ​	后置通知：在目标方法后（无论是否发生异常）执行的通知。在后置通知中还不能访问目标方法执行的结果  @After（在动态代理的invoke方法后 catch之外执行）
>
> ​	返回通知：在方法正常结束后执行的代码 是可以访问到方法返回值的@AfterReturning
>
> ​	异常通知：可以访问到方法运行时的异常 @AfterThrowing（在invoke的catch代码块中）
>
> ​	环绕通知：需要携带ProceedingJoinPoint参数 类似动态代理的全过程。方法的形式类似于实现动态代理。process方法代替了invoke





# SpringBoot

## <u>SpringBoot在Controller中的常用注解</u>

> #### @RestController
>
> ​	等于@Controller + @ReponseBody
>
> ​	使用@RestController返回的是return里面的字符串 json



> @GetMapping
>
> ​	是@RequestMapping(method=RequestMethod.GET)缩写
>
> @PostMapping	对应post请求
>
> @PutMapping		对应put请求
>
> @DeleteMapping 对应delete请求



## <u>动态代理的两种实现区别</u>

### 	原生JDK

> ​	通过java的反射机制
>
> ​	生成类的过程中比较高效
>
> ​	目标类必须基于统一的接口
>
> ​	就是通过让target类和代理类实现同一接口，代理类持有target对象，来达到方法拦截的作用，这样通过接口的方式有两个弊端，一个是必须保证target类有接口，第二个是如果想要对target类的方法进行代理拦截，那么就要保证这些方法都要在接口中声明，实现上略微有点限制。

### 	CGLIB

> ​	通过asm来实现
>
> ​	生成类后的相关执行过程比较高效
>
> ​	它的底层使用ASM在内存中动态的生成被代理类的子类，使用CGLIB即使代理类没有实现任何接口也可以实现动态代理功能。CGLIB具有简单易用，它的运行速度要远远快于JDK的Proxy动态代理：
>
> cglib有两种可选方式，继承和引用。第一种是基于继承实现的动态代理，所以可以直接通过super调用target方法，但是这种方式在spring中是不支持的，因为这样的话，这个target对象就不能被spring所管理，所以cglib还是才用类似jdk的方式，通过持有target对象来达到拦截方法的效果。

## <u>Spring和SpringMVC的理解</u>

### 	MVC概述

> ​	在早期 Java Web 的开发中，统一把显示层、控制层、数据层的操作全部交给 JSP 或者 JavaBean 来进行处理，我们称之为 **Model1：**
>
> ![img](https://upload-images.jianshu.io/upload_images/7896890-7b3f9cd59394b017.png?imageMogr2/auto-orient/strip|imageView2/2/w/963/format/webp)**出现的弊端：**
>
> JSP 和 Java Bean 之间严重耦合，Java 代码和 HTML 代码也耦合在了一起
>
> 要求开发者不仅要掌握 Java ，还要有高超的前端水平
>
> 前端和后端相互依赖，前端需要等待后端完成，后端也依赖前端完成，才能进行有效的测试
>
> 代码难以复用
>
> 
>
> 正因为上面的种种弊端，所以很快这种方式就被 Servlet + JSP + Java Bean 所替代了，早期的 MVC 模型**（Model2）**就像下图这样：
>
> ![img](https://upload-images.jianshu.io/upload_images/7896890-403a273b08fec826.png?imageMogr2/auto-orient/strip|imageView2/2/w/985/format/webp)
>
> 首先用户的请求会到达 Servlet，然后根据请求调用相应的 Java Bean，并把所有的显示结果交给 JSP 去完成，这样的模式我们就称为 MVC 模式。
>
> **M 代表 模型（Model）**
> 模型是什么呢？ 模型就是数据，就是 dao,bean
>
> **V 代表 视图（View）**
> 视图是什么呢？ 就是网页, JSP，用来展示模型中的数据
>
> **C 代表 控制器（controller)**
> 控制器是什么？ 控制器的作用就是把不同的数据(Model)，显示在不同的视图(View)上，Servlet 扮演的就是这样的角色。

### 	SpringMVC

> ![img](https://upload-images.jianshu.io/upload_images/7896890-a25782fb05f315de.png?imageMogr2/auto-orient/strip|imageView2/2/w/1176/format/webp)
>
> **传统的模型层被拆分为了业务层(Service)和数据访问层（DAO,Data Access Object）。** 在 Service 下可以通过 Spring 的声明式事务操作数据访问层，而在业务层上还允许我们访问 NoSQL ，这样就能够满足异军突起的 NoSQL 的使用了，它可以大大提高互联网系统的性能。
>
> **特点：**
> 结构松散，几乎可以在 Spring MVC 中使用各类视图
> 松耦合，各个模块分离
> 与 Spring 无缝集成

### 	springMVC的请求过程

> ![img](https://upload-images.jianshu.io/upload_images/7896890-65ef874ad7da59a2.png?imageMogr2/auto-orient/strip|imageView2/2/w/784/format/webp)
>
> 第一站到达的就是 **DispatcherServlet**，DispatcherServlet 会拦截所有的请求，并且将这些请求发送给 Spring MVC 控制器。
>
> **DispatcherServlet 的任务就是拦截请求发送给 Spring MVC 控制器。**
>
> 第二站**处理器映射（HandlerMapping）** DispatcherServlet 会查询一个或多个处理器映射来确定请求的下一站在哪里，处理器映射会**根据请求所携带的 URL 信息来进行决策**
>
> 第三站**控制器**一旦选择了合适的控制器， DispatcherServlet 会将请求发送给选中的控制器，到了控制器，请求会卸下其负载（用户提交的请求）等待控制器处理完这些信息
>
> 第四站 **返回 DispatcherServlet**当控制器在完成逻辑处理后，通常会产生一些信息，这些信息就是需要返回给用户并在浏览器上显示的信息，它们被称为**模型（Model）**仅仅返回原始的信息时不够的——这些信息需要以用户友好的方式进行格式化，一般会是 HTML，所以，信息需要发送给一个**视图（view）**，通常会是 JSP。控制器所做的最后一件事就是将模型数据打包，并且表示出用于渲染输出的视图名**（逻辑视图名）。它接下来会将请求连同模型和视图名发送回 DispatcherServlet。**
>
> 第五站**控制器** 这样就不会和特定的视图相耦合，传递给 DispatcherServlet 的视图名并不直接表示某个特定的 JSP。（实际上，它甚至不能确定视图就是 JSP）相反，**它传递的仅仅是一个逻辑名称，这个名称将会用来查找产生结果的真正视图。**DispatcherServlet 将会使用视图解析器（view resolver）来将逻辑视图名匹配为一个特定的视图实现，它可能是也可能不是 JSP
>
> 第六站**视图** 既然 DispatcherServlet 已经知道由哪个视图渲染结果了，那请求的任务基本上也就完成了。它的最后一站是视图的实现，在这里它交付模型数据，请求的任务也就完成了。视图使用模型数据渲染出结果，这个输出结果会通过响应对象传递给客户端。



## <u>@Transactional的理解</u>

> @Transactional不仅可以注解在方法上，也可以注解在类上。
>
> 当注解在类上的时候意味着此类的所有public方法都是开启事务的。
>
> 如果类级别和方法级别同时使用了@Transactional注解，则使用在类级别的注解会重载方法级别的注解



## <u>隔离级别</u>

> DEFAULT ：这是默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是： READ_COMMITTED 。
> READ_UNCOMMITTED ：该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读和不可重复读，因此很少使用该隔离级别。
> READ_COMMITTED ：该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。
> REPEATABLE_READ ：该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。即使在多次查询之间有新增的数据满足该查询，这些新增的记录也会被忽略。该级别可以防止脏读和不可重复读。
> SERIALIZABLE ：所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

> 指定方法：通过使用 isolation 属性设置，例如：
> @Transactional(isolation = Isolation.DEFAULT)

## <u>事务传播级别</u>

> **REQUIRED** ：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。**默认的spring事务传播级别**
>
> 如果上下文中已经存在事务，那么就加入到事务中执行，如果当前上下文中不存在事务，则新建事务执行。所以这个级别通常能满足处理大多数的业务场景。
>
> **SUPPORTS** ：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。
>
> **MANDATORY** ：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。配置该方式的传播级别是有效的控制上下文调用代码遗漏添加事务控制的保证手段。
>
> 比如一段代码不能单独被调用执行，但是一旦被调用，就必须有事务包含的情况，就可以使用这个传播级别。
>
> **REQUIRES_NEW** ：创建一个新的事务，如果当前存在事务，则把当前事务挂起。
>
> 举一个应用场景：现在有一个发送100个红包的操作，在发送之前，要做一些系统的初始化、验证、数据记录操作，然后发送100封红包，然后再记录发送日志，发送日志要求100%的准确，如果日志不准确，那么整个父事务逻辑需要回滚。
> 怎么处理整个业务需求呢？就是通过这个PROPAGATION_REQUIRES_NEW 级别的事务传播控制就可以完成。发送红包的子事务不会直接影响到父事务的提交和回滚。
>
> **NOT_SUPPORTED** ：以非事务方式运行，如果当前存在事务，则把当前事务挂起。
>
> 可以帮助你将事务极可能的缩小。我们知道一个事务越大，它存在的风险也就越多。所以在处理事务的过程中，要保证尽可能的缩小范围。比如一段代码，是每次逻辑操作都必须调用的，比如循环1000次的某个非核心业务逻辑操作。这样的代码如果包在事务中，势必造成事务太大，导致出现一些难以考虑周全的异常情况。所以这个事务这个级别的传播级别就派上用场了。用当前级别的事务模板抱起来就可以了。
>
> **NEVER** ：以非事务方式运行，如果当前存在事务，则抛出异常。
>
> **NESTED** ：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于 REQUIRED 。



## <u>什么是Restful API</u>

> 本质上是一种设计规范，应用于前后端分离的项目中，用于规范API设计

### 	设计原则

> 客户端-服务器：通过将用户UI与数据存储分开，我们可以简化服务器组件来提高跨多个平台的用户界面的可移植性并提高可伸缩性。 它可以比表现成前后端分离的思想。
>
> 无状态：从客户端到服务器的每个请求都必须包含理解请求所需的所有信息，并且不能利用服务器上任何存储的上下文。 这表示你应该尽可能的避免使用session，由客户端自己标识会话状态。（token）
>
> 规范接口：REST接口约束定义：资源识别; 请求动作; 响应信息; 它表示通过uri标出你要操作的`资源`，通过请求动作（http method）标识要执行的操作，通过返回的状态码来表示这次请求的执行结果。
>
> 可缓存： 缓存约束要求将对请求的响应中的数据隐式或显式标记为可缓存或不可缓存。如果响应是可缓存的，则客户端缓存有权重用该响应数据以用于以后的等效请求。 它表示get请求响应头中应该表示有是否可缓存的头（Cache-Control)

### 请求动作

> get	查询操作
>
> post  新增动作
>
> put	更新操作
>
> patch部分更新
>
> delete删除操作

### 	无状态

> 无状态通过将API部署到多个服务器，有助于将API扩展到数百万并发用户。任何服务器都可以处理任何请求，因为没有与会话相关的依赖。（集群）
>
> 无状态使得REST API不那么复杂 - 可以删除所有服务器端状态同步逻辑。（删除session，清理多余空间）
>
> 无状态API也很容易缓存。特定软件可以通过查看该一个请求来决定是否缓存HTTP请求的结果。从先前的请求中获得的状态可能会影响这个请求的可缓存性，这并不存在任何不确定性。它提高了应用程序的性能。
>
> 服务器永远不会忘记每个客户端身份”，因为客户端会在每个请求中发送所有必要的信息。（携带token）





## 单例模式和spring的单例有什么区别



## <u>如何优化减库存操作</u>

初始方法

```
query();
@transactional
set quantity=quantity-1
```

问题：在第一次进行查询时，如果不加事务的标记，则会导致超卖问题。如果加上了事务标记，则会影响并发

解决方案：不要进行query查询库存，直接用一次sql来处理，在一次sql中执行以下操作

```mysql
update set quantity=quantity-1
where good_id=1 and quantity>0
```

## <u>做登陆时有什么其他办法做用户的参数解析</u>

> 1用目前采用的方法。在请求发送到controller之前，用参数解析器，进行参数的解析。以用户信息实体的形式，传入controller
>
> 2threadlocal的形式来存放用户的相关信息。直接使用线程上下文的形式



## springboot 和 springmvc的区别



## 如何处理异常

### 全局异常 @ControllerAdvice @ExceptionHandler

> 可以通过@ControllerAdvice注解的方式 定义一个全局异常处理类
>
> 其中通过@ExceptionHandler注解可以设置处理的异常类类型

### 局部异常

> @ExceptionHandler注解修饰方法 但是会跳转刀统一的error页面